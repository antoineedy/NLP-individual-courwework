{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antoine EDY\n",
    "# Natural Language Processing (COMM061) - Coursework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import nltk\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"surrey-nlp/PLOD-CW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT2ID: {'B-O': 0, 'B-AC': 1, 'PAD': 2, 'B-LF': 3, 'I-LF': 4}\n",
      "ID2TEXT: {0: 'B-O', 1: 'B-AC', 2: 'PAD', 3: 'B-LF', 4: 'I-LF'}\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1072 entries, 0 to 1071\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tokens     1072 non-null   object\n",
      " 1   labels     1072 non-null   object\n",
      " 2   ids        1072 non-null   object\n",
      " 3   sentences  1072 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 33.6+ KB\n"
     ]
    }
   ],
   "source": [
    "TEXT2ID = {\n",
    "    \"B-O\": 0,\n",
    "    \"B-AC\": 1,\n",
    "    \"PAD\": 2,\n",
    "    \"B-LF\": 3,\n",
    "    \"I-LF\": 4,\n",
    "}\n",
    "ID2TEXT = {v: k for k, v in TEXT2ID.items()}\n",
    "\n",
    "print(f\"TEXT2ID: {TEXT2ID}\\nID2TEXT: {ID2TEXT}\\n\")\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.drop(columns=['pos_tags'])\n",
    "    df = df.rename(columns={\"ner_tags\": \"labels\"})\n",
    "    df[\"ids\"] = df[\"labels\"].apply(lambda x: [TEXT2ID[i] for i in x])\n",
    "    df[\"sentences\"] = df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_dataset = preprocess(pd.DataFrame(dataset['train']))\n",
    "test_dataset = preprocess(pd.DataFrame(dataset['test']))\n",
    "val_dataset = preprocess(pd.DataFrame(dataset['validation']))\n",
    "\n",
    "train_dataset.info()\n",
    "\n",
    "\n",
    "# Here the exploration to add at the end of the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>ids</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[For, this, purpose, the, Gothenburg, Young, P...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>For this purpose the Gothenburg Young Persons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, following, physiological, traits, were, ...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>The following physiological traits were measur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Minor, H, antigen, alloimmune, responses, rea...</td>\n",
       "      <td>[B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...</td>\n",
       "      <td>Minor H antigen alloimmune responses readily o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[EPI, =, Echo, planar, imaging, .]</td>\n",
       "      <td>[B-AC, B-O, B-LF, I-LF, I-LF, B-O]</td>\n",
       "      <td>[1, 0, 3, 4, 4, 0]</td>\n",
       "      <td>EPI = Echo planar imaging .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Furthermore, ,, eNOS, -, derived, NO, S, -, n...</td>\n",
       "      <td>[B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Furthermore , eNOS - derived NO S - nitrosylat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [For, this, purpose, the, Gothenburg, Young, P...   \n",
       "1  [The, following, physiological, traits, were, ...   \n",
       "2  [Minor, H, antigen, alloimmune, responses, rea...   \n",
       "3                 [EPI, =, Echo, planar, imaging, .]   \n",
       "4  [Furthermore, ,, eNOS, -, derived, NO, S, -, n...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...   \n",
       "1  [B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...   \n",
       "2  [B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...   \n",
       "3                 [B-AC, B-O, B-LF, I-LF, I-LF, B-O]   \n",
       "4  [B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...   \n",
       "\n",
       "                                                 ids  \\\n",
       "0      [0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...   \n",
       "3                                 [1, 0, 3, 4, 4, 0]   \n",
       "4  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           sentences  \n",
       "0  For this purpose the Gothenburg Young Persons ...  \n",
       "1  The following physiological traits were measur...  \n",
       "2  Minor H antigen alloimmune responses readily o...  \n",
       "3                        EPI = Echo planar imaging .  \n",
       "4  Furthermore , eNOS - derived NO S - nitrosylat...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072\n",
      "126\n",
      "153\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "# None for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>ids</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[For, this, purpose, the, Gothenburg, Young, P...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>For this purpose the Gothenburg Young Persons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, following, physiological, traits, were, ...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>The following physiological traits were measur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Minor, H, antigen, alloimmune, responses, rea...</td>\n",
       "      <td>[B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...</td>\n",
       "      <td>Minor H antigen alloimmune responses readily o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[EPI, =, Echo, planar, imaging, .]</td>\n",
       "      <td>[B-AC, B-O, B-LF, I-LF, I-LF, B-O]</td>\n",
       "      <td>[1, 0, 3, 4, 4, 0]</td>\n",
       "      <td>EPI = Echo planar imaging .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Furthermore, ,, eNOS, -, derived, NO, S, -, n...</td>\n",
       "      <td>[B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Furthermore , eNOS - derived NO S - nitrosylat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [For, this, purpose, the, Gothenburg, Young, P...   \n",
       "1  [The, following, physiological, traits, were, ...   \n",
       "2  [Minor, H, antigen, alloimmune, responses, rea...   \n",
       "3                 [EPI, =, Echo, planar, imaging, .]   \n",
       "4  [Furthermore, ,, eNOS, -, derived, NO, S, -, n...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...   \n",
       "1  [B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...   \n",
       "2  [B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...   \n",
       "3                 [B-AC, B-O, B-LF, I-LF, I-LF, B-O]   \n",
       "4  [B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...   \n",
       "\n",
       "                                                 ids  \\\n",
       "0      [0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...   \n",
       "3                                 [1, 0, 3, 4, 4, 0]   \n",
       "4  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           sentences  \n",
       "0  For this purpose the Gothenburg Young Persons ...  \n",
       "1  The following physiological traits were measur...  \n",
       "2  Minor H antigen alloimmune responses readily o...  \n",
       "3                        EPI = Echo planar imaging .  \n",
       "4  Furthermore , eNOS - derived NO S - nitrosylat...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': <torchtext.data.field.Field object at 0x15940f430>, 'text': <torchtext.data.field.Field object at 0x15940f490>}\n",
      "['For', 'this', 'purpose', 'the', 'Gothenburg', 'Young', 'Persons', 'Empowerment', 'Scale', '(', 'GYPES', ')', 'was', 'developed', '.']\n",
      "['B-O', 'B-O', 'B-O', 'B-O', 'B-LF', 'I-LF', 'I-LF', 'I-LF', 'I-LF', 'B-O', 'B-AC', 'B-O', 'B-O', 'B-O', 'B-O']\n",
      "Train: 1072\n",
      "Dev: 126\n",
      "Test: 153\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Field, Dataset, Example\n",
    "\n",
    "text_field = Field(sequential=True, tokenize=lambda x:x, include_lengths=True) # Default behaviour is to tokenize by splitting\n",
    "label_field = Field(sequential=True, tokenize=lambda x:x, is_target=True)\n",
    "\n",
    "fields = {\n",
    "    'sentences': ('text', text_field),\n",
    "    'ids': ('label', label_field)\n",
    "}\n",
    "\n",
    "def read_data(df):\n",
    "    examples = []\n",
    "    fields = {'sentence_labels': ('labels', label_field),\n",
    "              'sentence_tokens': ('text', text_field)}\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        tokens = df['tokens'][i]\n",
    "        labels = df['labels'][i]\n",
    "        \n",
    "        e = Example.fromdict({\"sentence_labels\": labels, \"sentence_tokens\": tokens},\n",
    "                             fields=fields)\n",
    "        examples.append(e)\n",
    "    \n",
    "    return Dataset(examples, fields=[('labels', label_field), ('text', text_field)])\n",
    "\n",
    "\n",
    "train_data = read_data(train_dataset)\n",
    "val_data = read_data(val_dataset)\n",
    "test_data = read_data(test_dataset)\n",
    "\n",
    "print(train_data.fields)\n",
    "print(train_data[0].text)\n",
    "print(train_data[0].labels)\n",
    "\n",
    "print(\"Train:\", len(train_data))\n",
    "print(\"Dev:\", len(val_data))\n",
    "print(\"Test:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 20000\n",
    "\n",
    "text_field.build_vocab(train_data, max_size=VOCAB_SIZE)\n",
    "label_field.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import BucketIterator\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_iter = BucketIterator(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                            sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "val_iter = BucketIterator(dataset=val_data, batch_size=BATCH_SIZE, \n",
    "                          sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "test_iter = BucketIterator(dataset=test_data, batch_size=BATCH_SIZE, \n",
    "                           sort_key=lambda x: len(x.text), sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "EMBEDDING_PATH = \"/Users/antoineedy/Documents/MScAI/Semester2/NLP/Coursework/code/data/cc.en.300.vec\"\n",
    "\n",
    "def load_embeddings(path):\n",
    "    \"\"\" Load the FastText embeddings from the embedding file. \"\"\"\n",
    "    print(\"Loading pre-trained embeddings\")\n",
    "    \n",
    "    embeddings = {}\n",
    "    with open(path) as i:\n",
    "        for line in i:\n",
    "            if len(line) > 2: \n",
    "                line = line.strip().split()\n",
    "                word = line[0]\n",
    "                embedding = np.array(line[1:])\n",
    "                embeddings[word] = embedding\n",
    "    \n",
    "    return embeddings\n",
    "    \n",
    "\n",
    "def initialize_embeddings(embeddings, vocabulary):\n",
    "    \"\"\" Use the pre-trained embeddings to initialize an embedding matrix. \"\"\"\n",
    "    print(\"Initializing embedding matrix\")\n",
    "    embedding_size = len(embeddings[\".\"])\n",
    "    embedding_matrix = np.zeros((len(vocabulary), embedding_size), dtype=np.float32)\n",
    "                                \n",
    "    for idx, word in enumerate(vocabulary.itos): \n",
    "        if word in embeddings:\n",
    "            embedding_matrix[idx,:] = embeddings[word]\n",
    "            \n",
    "    return embedding_matrix\n",
    "\n",
    "#embeddings = load_embeddings(EMBEDDING_PATH)\n",
    "#embedding_matrix = initialize_embeddings(embeddings, text_field.vocab)\n",
    "#embedding_matrix = torch.from_numpy(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class BiLSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, output_size, embeddings=None):\n",
    "        super(BiLSTMTagger, self).__init__()\n",
    "        \n",
    "        # 1. Embedding Layer\n",
    "        if embeddings is None:\n",
    "            self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        else:\n",
    "            self.embeddings = nn.Embedding.from_pretrained(embeddings)\n",
    "        \n",
    "        # 2. LSTM Layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, num_layers=1)\n",
    "        \n",
    "        # 3. Optional dropout layer\n",
    "        self.dropout_layer = nn.Dropout(p=0.5)\n",
    "\n",
    "        # 4. Dense Layer\n",
    "        self.hidden2tag = nn.Linear(2*hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, batch_text, batch_lengths):\n",
    "\n",
    "        embeddings = self.embeddings(batch_text)\n",
    "        \n",
    "        packed_seqs = pack_padded_sequence(embeddings, batch_lengths)\n",
    "        lstm_output, _ = self.lstm(packed_seqs)\n",
    "        lstm_output, _ = pad_packed_sequence(lstm_output)\n",
    "        lstm_output = self.dropout_layer(lstm_output)\n",
    "        \n",
    "        logits = self.hidden2tag(lstm_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 6: ['<unk>', '<pad>', 'B-O', 'I-LF', 'B-AC', 'B-LF']\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "def remove_predictions_for_masked_items(predicted_labels, correct_labels): \n",
    "\n",
    "    predicted_labels_without_mask = []\n",
    "    correct_labels_without_mask = []\n",
    "        \n",
    "    for p, c in zip(predicted_labels, correct_labels):\n",
    "        if c > 1:\n",
    "            predicted_labels_without_mask.append(p)\n",
    "            correct_labels_without_mask.append(c)\n",
    "            \n",
    "    return predicted_labels_without_mask, correct_labels_without_mask\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "NUM_CLASSES = len(label_field.vocab)\n",
    "print(f\"Number of classes: {NUM_CLASSES}: {label_field.vocab.itos}\")\n",
    "\n",
    "def train(model, train_iter, dev_iter, batch_size, max_epochs, num_batches, patience, output_path):\n",
    "    writer = SummaryWriter()\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=1)  # we mask the <pad> labels\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    train_f_score_history = []\n",
    "    dev_f_score_history = []\n",
    "    no_improvement = 0\n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        total_loss = 0\n",
    "        predictions, correct = [], []\n",
    "        for batch in tqdm(train_iter, total=num_batches, desc=f\"Epoch {epoch}\"):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            text_length, cur_batch_size = batch.text[0].shape\n",
    "            \n",
    "            pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size*text_length, NUM_CLASSES)\n",
    "            gold = batch.labels.to(device).view(cur_batch_size*text_length)\n",
    "            \n",
    "            loss = criterion(pred, gold)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, pred_indices = torch.max(pred, 1)\n",
    "            \n",
    "            predicted_labels = list(pred_indices.cpu().numpy())\n",
    "            correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "            \n",
    "            predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, \n",
    "                                                                                   correct_labels)\n",
    "            \n",
    "            predictions += predicted_labels\n",
    "            correct += correct_labels\n",
    "\n",
    "        train_scores = precision_recall_fscore_support(correct, predictions, average=\"micro\")\n",
    "        train_f_score_history.append(train_scores[2])\n",
    "            \n",
    "        print(\"Total training loss:\", total_loss)\n",
    "        print(\"Training performance:\", train_scores)\n",
    "\n",
    "        #tensorboard\n",
    "        writer.add_scalar('train/loss', total_loss, epoch)\n",
    "        writer.add_scalar('train/precision', train_scores[2], epoch)\n",
    "        \n",
    "        total_loss = 0\n",
    "        predictions, correct = [], []\n",
    "        for batch in dev_iter:\n",
    "\n",
    "            text_length, cur_batch_size = batch.text[0].shape\n",
    "\n",
    "            pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size * text_length, NUM_CLASSES)\n",
    "            gold = batch.labels.to(device).view(cur_batch_size * text_length)\n",
    "            loss = criterion(pred, gold)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, pred_indices = torch.max(pred, 1)\n",
    "            predicted_labels = list(pred_indices.cpu().numpy())\n",
    "            correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "            \n",
    "            predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, \n",
    "                                                                                   correct_labels)\n",
    "            \n",
    "            predictions += predicted_labels\n",
    "            correct += correct_labels\n",
    "\n",
    "        dev_scores = precision_recall_fscore_support(correct, predictions, average=\"micro\")\n",
    "            \n",
    "        print(\"Total development loss:\", total_loss)\n",
    "        print(\"Development performance:\", dev_scores)\n",
    "\n",
    "        writer.add_scalar('val/loss', total_loss, epoch)\n",
    "        writer.add_scalar('val/precision', dev_scores[2], epoch)\n",
    "        \n",
    "        dev_f = dev_scores[2]\n",
    "        if len(dev_f_score_history) > patience and dev_f < max(dev_f_score_history):\n",
    "            no_improvement += 1\n",
    "\n",
    "        elif len(dev_f_score_history) == 0 or dev_f > max(dev_f_score_history):\n",
    "            print(\"Saving model.\")\n",
    "            torch.save(model, output_path)\n",
    "            no_improvement = 0\n",
    "            \n",
    "        if no_improvement > patience:\n",
    "            print(\"Development F-score does not improve anymore. Stop training.\")\n",
    "            dev_f_score_history.append(dev_f)\n",
    "            break\n",
    "            \n",
    "        dev_f_score_history.append(dev_f)\n",
    "        \n",
    "    return train_f_score_history, dev_f_score_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_iter, batch_size, labels, target_names): \n",
    "    \n",
    "    total_loss = 0\n",
    "    predictions, correct = [], []\n",
    "    for batch in test_iter:\n",
    "\n",
    "        text_length, cur_batch_size = batch.text[0].shape\n",
    "\n",
    "        pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size * text_length, NUM_CLASSES)\n",
    "        gold = batch.labels.to(device).view(cur_batch_size * text_length)\n",
    "\n",
    "        _, pred_indices = torch.max(pred, 1)\n",
    "        predicted_labels = list(pred_indices.cpu().numpy())\n",
    "        correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "\n",
    "        predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, \n",
    "                                                                               correct_labels)\n",
    "\n",
    "        predictions += predicted_labels\n",
    "        correct += correct_labels\n",
    "    \n",
    "    print(classification_report(correct, predictions, labels=labels, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 6 : ['<unk>', '<pad>', 'B-O', 'I-LF', 'B-AC', 'B-LF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 34/34 [00:05<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 25.401902318000793\n",
      "Training performance: (0.792075, 0.792075, 0.792075, None)\n",
      "Total development loss: 1.6360817849636078\n",
      "Development performance: (0.8802, 0.8802, 0.8802, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 34/34 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 13.132342100143433\n",
      "Training performance: (0.8655, 0.8655, 0.8655, None)\n",
      "Total development loss: 1.3100650906562805\n",
      "Development performance: (0.8994, 0.8994, 0.8994, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 34/34 [00:05<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 10.422252416610718\n",
      "Training performance: (0.891, 0.891, 0.891, None)\n",
      "Total development loss: 1.2469894886016846\n",
      "Development performance: (0.909, 0.909, 0.909, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 34/34 [00:04<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 8.19130240380764\n",
      "Training performance: (0.90915, 0.90915, 0.90915, None)\n",
      "Total development loss: 1.122013509273529\n",
      "Development performance: (0.9148, 0.9148, 0.9148, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 34/34 [00:05<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 6.3694857731461525\n",
      "Training performance: (0.93025, 0.93025, 0.93025, None)\n",
      "Total development loss: 1.2096821963787079\n",
      "Development performance: (0.8984, 0.8984, 0.8984, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 34/34 [00:04<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 4.8317131996154785\n",
      "Training performance: (0.944825, 0.944825, 0.944825, None)\n",
      "Total development loss: 1.1180841624736786\n",
      "Development performance: (0.909, 0.909, 0.909, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 34/34 [00:05<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.519617773592472\n",
      "Training performance: (0.962, 0.962, 0.962, None)\n",
      "Total development loss: 1.2160247266292572\n",
      "Development performance: (0.897, 0.897, 0.897, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 34/34 [00:05<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.5366842690855265\n",
      "Training performance: (0.97195, 0.97195, 0.97195, None)\n",
      "Total development loss: 1.4108185172080994\n",
      "Development performance: (0.887, 0.887, 0.887, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 34/34 [00:04<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.9979442609474063\n",
      "Training performance: (0.97745, 0.97745, 0.97745, None)\n",
      "Total development loss: 1.477356195449829\n",
      "Development performance: (0.8774, 0.8774, 0.8774, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 34/34 [00:05<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.3988369181752205\n",
      "Training performance: (0.985525, 0.985525, 0.985525, None)\n",
      "Total development loss: 1.5446699857711792\n",
      "Development performance: (0.8768, 0.8768, 0.8768, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 34/34 [00:05<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.9854684434831142\n",
      "Training performance: (0.989625, 0.989625, 0.989625, None)\n",
      "Total development loss: 1.6119528412818909\n",
      "Development performance: (0.8802, 0.8802, 0.8802, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 34/34 [00:05<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.6815523998811841\n",
      "Training performance: (0.99405, 0.99405, 0.99405, None)\n",
      "Total development loss: 1.592284917831421\n",
      "Development performance: (0.8838, 0.8838, 0.8838, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 34/34 [00:05<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.48884589318186045\n",
      "Training performance: (0.996025, 0.996025, 0.996025, None)\n",
      "Total development loss: 1.6230541467666626\n",
      "Development performance: (0.8922, 0.8922, 0.8922, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 34/34 [00:04<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.3511953072156757\n",
      "Training performance: (0.997225, 0.997225, 0.997225, None)\n",
      "Total development loss: 1.7080291509628296\n",
      "Development performance: (0.8862, 0.8862, 0.8862, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 34/34 [00:05<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.2551866073627025\n",
      "Training performance: (0.99845, 0.99845, 0.99845, None)\n",
      "Total development loss: 1.803662657737732\n",
      "Development performance: (0.8842, 0.8842, 0.8842, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 34/34 [00:05<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.19628331961575896\n",
      "Training performance: (0.998825, 0.998825, 0.998825, None)\n",
      "Total development loss: 1.8997616171836853\n",
      "Development performance: (0.88, 0.88, 0.88, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 34/34 [00:05<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.15902539098169655\n",
      "Training performance: (0.99905, 0.99905, 0.99905, None)\n",
      "Total development loss: 1.8413887321949005\n",
      "Development performance: (0.8952, 0.8952, 0.8952, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 34/34 [00:05<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.13581641274504364\n",
      "Training performance: (0.99945, 0.99945, 0.99945, None)\n",
      "Total development loss: 1.9575782418251038\n",
      "Development performance: (0.8906, 0.8906, 0.8906, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 34/34 [00:05<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.11302810872439295\n",
      "Training performance: (0.99955, 0.99955, 0.99955, None)\n",
      "Total development loss: 2.1319859623908997\n",
      "Development performance: (0.8824, 0.8824, 0.8824, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 34/34 [00:05<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.08663544000592083\n",
      "Training performance: (0.9997, 0.9997, 0.9997, None)\n",
      "Total development loss: 1.9833576381206512\n",
      "Development performance: (0.8932, 0.8932, 0.8932, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 34/34 [00:05<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.07432446378516033\n",
      "Training performance: (0.999775, 0.999775, 0.999775, None)\n",
      "Total development loss: 2.092358708381653\n",
      "Development performance: (0.885, 0.885, 0.885, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 34/34 [00:04<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.06506842689123005\n",
      "Training performance: (0.999825, 0.999825, 0.999825, None)\n",
      "Total development loss: 2.044197827577591\n",
      "Development performance: (0.8946, 0.8946, 0.8946, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 34/34 [00:05<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.05358525161864236\n",
      "Training performance: (0.999875, 0.999875, 0.999875, None)\n",
      "Total development loss: 2.145233064889908\n",
      "Development performance: (0.8884, 0.8884, 0.8884, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 34/34 [00:05<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.04541582358069718\n",
      "Training performance: (0.999825, 0.999825, 0.999825, None)\n",
      "Total development loss: 2.1386914551258087\n",
      "Development performance: (0.8878, 0.8878, 0.8878, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 34/34 [00:05<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.03554203693056479\n",
      "Training performance: (1.0, 1.0, 1.0, None)\n",
      "Total development loss: 2.1840579509735107\n",
      "Development performance: (0.8862, 0.8862, 0.8862, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 34/34 [00:05<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.031019956280943006\n",
      "Training performance: (0.999975, 0.999975, 0.999975, None)\n",
      "Total development loss: 2.220282018184662\n",
      "Development performance: (0.8878, 0.8878, 0.8878, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 34/34 [00:05<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.029322637914447114\n",
      "Training performance: (0.999975, 0.999975, 0.999975, None)\n",
      "Total development loss: 2.28093758225441\n",
      "Development performance: (0.885, 0.885, 0.885, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 34/34 [00:05<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.029407157097011805\n",
      "Training performance: (0.99995, 0.99995, 0.99995, None)\n",
      "Total development loss: 2.361500918865204\n",
      "Development performance: (0.882, 0.882, 0.882, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 34/34 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.02772706386167556\n",
      "Training performance: (1.0, 1.0, 1.0, None)\n",
      "Total development loss: 2.244459092617035\n",
      "Development performance: (0.8892, 0.8892, 0.8892, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 34/34 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.024368406055145897\n",
      "Training performance: (0.99995, 0.99995, 0.99995, None)\n",
      "Total development loss: 2.3054662942886353\n",
      "Development performance: (0.8864, 0.8864, 0.8864, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 34/34 [00:04<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.023719197139143944\n",
      "Training performance: (0.99995, 0.99995, 0.99995, None)\n",
      "Total development loss: 2.3612449169158936\n",
      "Development performance: (0.8842, 0.8842, 0.8842, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 34/34 [00:05<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.020780328020919114\n",
      "Training performance: (1.0, 1.0, 1.0, None)\n",
      "Total development loss: 2.4110478162765503\n",
      "Development performance: (0.8838, 0.8838, 0.8838, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 34/34 [00:04<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.04134812251140829\n",
      "Training performance: (0.99995, 0.99995, 0.99995, None)\n",
      "Total development loss: 2.5252290964126587\n",
      "Development performance: (0.8744, 0.8744, 0.8744, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 34/34 [00:05<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.0732893252861686\n",
      "Training performance: (0.9997, 0.9997, 0.9997, None)\n",
      "Total development loss: 2.350309729576111\n",
      "Development performance: (0.8832, 0.8832, 0.8832, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 34/34 [00:05<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.069113841134822\n",
      "Training performance: (0.9996, 0.9996, 0.9996, None)\n",
      "Total development loss: 2.217114180326462\n",
      "Development performance: (0.8884, 0.8884, 0.8884, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 34/34 [00:05<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.05012212380825076\n",
      "Training performance: (0.9997, 0.9997, 0.9997, None)\n",
      "Total development loss: 2.3291540145874023\n",
      "Development performance: (0.881, 0.881, 0.881, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 34/34 [00:05<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.034384387254249305\n",
      "Training performance: (0.9999, 0.9999, 0.9999, None)\n",
      "Total development loss: 2.313207507133484\n",
      "Development performance: (0.8848, 0.8848, 0.8848, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 34/34 [00:05<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.019876459424267523\n",
      "Training performance: (0.999925, 0.999925, 0.999925, None)\n",
      "Total development loss: 2.358334481716156\n",
      "Development performance: (0.887, 0.887, 0.887, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 34/34 [00:05<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.01570441726653371\n",
      "Training performance: (0.999975, 0.999975, 0.999975, None)\n",
      "Total development loss: 2.321757733821869\n",
      "Development performance: (0.8872, 0.8872, 0.8872, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 34/34 [00:05<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.012618503940757364\n",
      "Training performance: (1.0, 1.0, 1.0, None)\n",
      "Total development loss: 2.456238806247711\n",
      "Development performance: (0.8866, 0.8866, 0.8866, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 34/34 [00:05<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.012825949990656227\n",
      "Training performance: (0.999975, 0.999975, 0.999975, None)\n",
      "Total development loss: 2.405996859073639\n",
      "Development performance: (0.8916, 0.8916, 0.8916, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 34/34 [00:05<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.024163607507944107\n",
      "Training performance: (0.99995, 0.99995, 0.99995, None)\n",
      "Total development loss: 2.499834716320038\n",
      "Development performance: (0.8892, 0.8892, 0.8892, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 34/34 [00:05<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.014394207406439818\n",
      "Training performance: (0.999975, 0.999975, 0.999975, None)\n",
      "Total development loss: 2.467872440814972\n",
      "Development performance: (0.89, 0.89, 0.89, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 34/34 [00:05<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.010023718801676296\n",
      "Training performance: (1.0, 1.0, 1.0, None)\n",
      "Total development loss: 2.606874465942383\n",
      "Development performance: (0.8864, 0.8864, 0.8864, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 34/34 [00:05<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.008984928361314815\n",
      "Training performance: (1.0, 1.0, 1.0, None)\n",
      "Total development loss: 2.618711233139038\n",
      "Development performance: (0.8834, 0.8834, 0.8834, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 34/34 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.007988506600668188\n",
      "Training performance: (1.0, 1.0, 1.0, None)\n",
      "Total development loss: 2.6437965035438538\n",
      "Development performance: (0.8834, 0.8834, 0.8834, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 34/34 [00:04<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.013509016338502988\n",
      "Training performance: (0.999975, 0.999975, 0.999975, None)\n",
      "Total development loss: 2.5359373092651367\n",
      "Development performance: (0.896, 0.896, 0.896, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 34/34 [00:05<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.35160253269714303\n",
      "Training performance: (0.995975, 0.995975, 0.995975, None)\n",
      "Total development loss: 1.8957675099372864\n",
      "Development performance: (0.9062, 0.9062, 0.9062, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 34/34 [00:05<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.4446622715331614\n",
      "Training performance: (0.9832, 0.9832, 0.9832, None)\n",
      "Total development loss: 1.7375307083129883\n",
      "Development performance: (0.8874, 0.8874, 0.8874, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 34/34 [00:05<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.46867337357252836\n",
      "Training performance: (0.9951, 0.9951, 0.9951, None)\n",
      "Total development loss: 1.78712198138237\n",
      "Development performance: (0.8924, 0.8924, 0.8924, None)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = len(label_field.vocab)\n",
    "print(f\"Number of classes: {NUM_CLASSES} : {label_field.vocab.itos}\")\n",
    "MAX_EPOCHS = 50\n",
    "PATIENCE = 50\n",
    "OUTPUT_PATH = \"model_saves/bilstmtagger\"\n",
    "num_batches = math.ceil(len(train_data) / BATCH_SIZE)\n",
    "\n",
    "#tagger = BiLSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE+2, NUM_CLASSES, embeddings=embedding_matrix)  # embeddings\n",
    "tagger = BiLSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE+2, NUM_CLASSES)  # no embeddings\n",
    "\n",
    "train_f, dev_f = train(tagger.to(device), train_iter, val_iter, BATCH_SIZE, MAX_EPOCHS, \n",
    "                       num_batches, PATIENCE, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABcl0lEQVR4nO3dd3zM9x8H8NclctnDiEQIsZUStSJGKSFGUxRV1CxKaWmoilKjJdr6xV6tmlW0NVorRew9Y9SeMZIgyJ53398f3+abHBl3l7v7XpLX8/H4PvK5732/33vfV+Te95kKQRAEEBEREZkxC7kDICIiIsoPExYiIiIye0xYiIiIyOwxYSEiIiKzx4SFiIiIzB4TFiIiIjJ7TFiIiIjI7DFhISIiIrNXQu4ADEGtVuPx48dwdHSEQqGQOxwiIiLSgiAIiI+Ph4eHByws8q5DKRIJy+PHj+Hp6Sl3GERERKSHBw8eoEKFCnkeUyQSFkdHRwDiG3ZycpI5GiIiItJGXFwcPD09pc/xvBSJhCWzGcjJyYkJCxERUSGjTXcOdrolIiIis8eEhYiIiMweExYiIiIye0xYiIiIyOwxYSEiIiKzx4SFiIiIzB4TFiIiIjJ7TFiIiIjI7DFhISIiIrOnc8Jy6NAhBAQEwMPDAwqFAlu3bs33nAMHDqBBgwawtrZGtWrVsGrVqteOWbRoEby8vGBjYwMfHx+cOnVK19CIiIioiNI5YUlMTIS3tzcWLVqk1fF3795F586d8c477yA8PBxjxozBkCFD8M8//0jHbNy4EYGBgZgyZQrOnTsHb29v+Pv748mTJ7qGR0REREWQQhAEQe+TFQps2bIFXbt2zfWYr776Cjt27MDly5elfR9++CFevnyJ0NBQAICPjw8aN26MhQsXAgDUajU8PT3x2WefYcKECfnGERcXB2dnZ8TGxnItISIiokJCl89voy9+ePz4cfj5+Wns8/f3x5gxYwAAaWlpOHv2LIKCgqTnLSws4Ofnh+PHj+d4zdTUVKSmpkqP4+LiDB84kUzS04G0NCAjQyxn/sxezsgAUlPF41JTs7ZXH2dkACrV6z9fLavV4pa9/OrjvJ7L3CwssjZLy9cfKxRi/CkpmltqquZjtVo8VptNGwqFGENu13j1feT03jKv8er7evX95efV6+b0moKQ933M/GlnB9jbi5uDQ1Y5+2ZtDZQoAVhZ5fyzRIms37tXf+de/X1LTs57S00VY8/cMt/Lq5u2v1M5nZt9y/y3zW/L698+c9Mm7ty2zOMNLb+Yy5QBxo0Devc2/GubI6MnLFFRUXBzc9PY5+bmhri4OCQnJ+PFixdQqVQ5HnPt2rUcrxkcHIxp06YZLWYiXQmC+EGblPT6lpiYVY6PB168AJ4/z31LTpb73RBRYRARAfTpA2zbBixeDLi4yB2RcRk9YTGGoKAgBAYGSo/j4uLg6ekpY0RUFKnVwM2bwJkzwOPHwMuXYrKR0/bypfgtlPRjbQ3Y2IibtbX4jVibb7bayO0bc/Z92WsxcqsZyl4zkFPtk0qlXTwKRe61Jpnl7HHnVNuTWUOWlGScb/bGklkzkN/7z69WJPM5XWo/8tuf2+vlVzvz6vOGkt/7UqmAzG6e69cDR44Aq1cD77xjuBjMjdETFnd3d0RHR2vsi46OhpOTE2xtbWFpaQlLS8scj3F3d8/xmtbW1rC2tjZazFQ8PXsGnDoFnDwJnDghll++NM1rW1sDpUsDpUqJ35Jyq8bPXra2BpRK8Wfmlv2xUpl1rKWluOVW1uYDJK8P9ewfIPk1rSiVWYmJjY342IITLOgls2YvMRFISBB/vlrOqTnx1aZGC4v8m42USsDW9vXNzi6rbG1t/A9yyrJhAzBihPh36sEDoG1bYOxY4LvvxH+LosboCYuvry927typsW/Pnj3w9fUFACiVSjRs2BBhYWFS5121Wo2wsDCMGjXK2OFRMZWSAly4ICYnmdvt27pdQ6EAnJ3FBKNkScDJSewzkNmvwM7u9c3ePisxKVlS/FmqlPjHnkhXCkVWslCmjNzRkKl9+CHQvDkwYACwf7+YwM6eDezeDaxbB7z5ptwRGpbOCUtCQgJu3bolPb579y7Cw8NRqlQpVKxYEUFBQXj06BHWrFkDABg+fDgWLlyI8ePHY/Dgwdi3bx9+//137NixQ7pGYGAgBgwYgEaNGqFJkyaYO3cuEhMTMWjQIAO8RSruVCrg+nWxxiRzu3hR/GaZl7JlAR8fcatRQ0wwsm9OTlnV90REcvD0BPbuBebMASZOFDveX7wINGoEzJoFfP55EarBFHS0f/9+AcBr24ABAwRBEIQBAwYIrVq1eu2c+vXrC0qlUqhSpYqwcuXK1667YMECoWLFioJSqRSaNGkinDhxQuuYYmNjBQBCbGysrm+HiiCVShAOHBCEr74ShHfeEQRHx/xbum1sBKFZM0H44gtB2LBBEO7eFQS1Wu53QkSkvfBwQahTR/Nvm5+fIDx+LHdkudPl87tA87CYC87DQoIAnD0rdj7buBF49Cj3YxUK4I03gCZNgMaNxRqUevXE9noiosIsJUWsaZkzJ2tfo0ZizXJB+hLt2we8/XbWMHhD0eXzmwkLFWpXrohJyoYNQLaWSg0VKojJSebWsKHYnENEVFTt3Qv07w9ERoqPd+8G2rXT71rnzwMNGgBVqwLBwUDPnoaL06wmjiMytMePgTVrxETl4sXXn7eyAvz9xQ5p77wDeHiYPkYiIjn5+QELFgA9eoiPQ0L0T1iCg8Wft28DT58aJj59sIaFCpXNm4GBA8UJ2LJTKMTkpHdv4P33xZE3RETFmUoFVK8O3L0rPr58GahTR7drXLsG1K4tNru7uQH37onTERiKLp/fRaXvMBVxGRnA+PFA9+6ayUrTpsC8eWKflbAwYMgQJitERIA4inH06KzH2fu1aOv777MmJxw71rDJiq5Yw0JmLzpabN45cCBr34cfAjNnApUryxYWEZHZi48Xhz7HxoqTyd2/L9aUaOP+faBaNfELY8mS4mNHR8PGxxoWKjKOHRM7e2UmKyVKAPPnA7/9xmSFiCg/jo7AsGFiOTUVWLJE+3N//DFryZHPPzd8sqIr1rCQWRIEscPY2LFZ/2E8PIA//gCaNZM3NiKiwuTBA/ELnkoFuLqKNSX5za4dFQV4eYlJjr29eE7p0oaPjTUsVKglJIgrkI4enZWstG4NnDvHZIWISFeensAHH4jlp0/FafvzM2eOmKwA4npFxkhWdMWEhczKtWviRG4bNmTt++orYM8e7dtdiYhIU2BgVjkkJO9Vvp8/BxYvFsvW1prnyokJC5mNX38VZ569ckV87OQEbNkirodh6NkViYiKk0aNgJYtxfLVq8A//+R+7MKFYk03AAweDJQrZ/z4tMGEhWQXFwd89BHQr1/Wf5I33wROnwb+W8CbiIgKKHtNyf/+l/MxCQniVBGAOCz6yy+NH5e2mLCQrE6cAOrX12xTHThQ3F+jhlxREREVPQEB4vT6gDh1f04zhS9bJjYJAUDfvuY1GpMJC8lCpQJmzABatMiahdHJSZxuf+VKsVc6EREZjqUl8MUXWY9fnUguJQWYPVssKxTAhAmmi00bTFjI5B48ANq0ASZNEhMXQBz9c+GCOCEcEREZx8CB4iRwgFiznbk4IgCsWiUOZwbEJU7eeMPU0eWNCQuZ1KZNgLc3cOiQ+NjCApgyBTh4UBzzT0RExmNvD3zyiVhOT88aDZSeLk7DnykoyPSx5YcJC5lEaqo422KPHsCLF+K+ihXFRGXqVI4CIiIylVGjsv7mLlkCJCWJU0ncuyfu69ABaNhQtvByxYSFTOKzz4Cff8563LMnEB4u9mEhIiLTKV8+q/k9JgZYvRoIDs56fuJEeeLKDxMWMrqtW7OSFRsb4JdfgI0bs9pRiYjItLJ3vh03TpybBRDnasmcr8XcMGEho4qMBIYMyXq8cKE4EZFCIV9MRETFXYMG4pIngNgklMlca1cAJixkRIIADBokVjkC4iRwgwfLGhIREf3n1Sn3GzQA/P3liUUbTFjIaBYuzJr+uVw5sVmINStEROahc2fNCTonTjTvv9FMWMgo/v0XGD8+6/HKlUCZMvLFQ0REmiwsxFFC5coBffoA3brJHVHeOJiUDC41VZzSOSVFfPz55+ZdzUhEVFy1aQM8fix3FNphDQsZ3OTJ4qy1AFCnjrjaMhERUUEwYSGD2r8/ay0KpVKc+tnWVt6YiIio8GPCQgbz4gXQv784OggAZs4Up+EnIiIqKCYsZBCCAAwfDjx8KD5u00ZzYiIiIqKCYMJCBvHrr8Dvv4vlkiXFqZ4t+NtFREQGwo8UKrB794CRI7MeL1sGVKggWzhERFQEMWGhAnn8GOjUCYiPFx/37y8ubEhERGRInIeF9BYRAbRtC9y6JT6uUgVYsEDemIiIqGhiwkJ6uXNH7Fh7/7742MsL2LsXcHKSNSwiIiqi2CREOrt+HXj77axkpXp14NAhoHJleeMiIqKiiwkL6eTyZaBVK+DRI/Fx7drAwYOAp6e8cRERUdHGhIW0dv480Lo1EB0tPq5fHzhwQFw4i4iIyJiYsJBWTp4U+6zExIiPGzcG9u0DXF3ljYuIiIoHJiyUryNHgHbtgJcvxcfNm4sdbEuWlDUsIiIqRpiwUJ727wf8/bPmWXnnHSA0lKOBiIjItJiwUK6ePwd69ACSksTHHToAO3YADg7yxkVERMUP52GhXE2bJiYtgJisbN0KWFvLGhIRERVTrGGhHF29CixaJJbt7IDly5msEBGRfJiwUI7GjgVUKrE8YQJQvry88RARUfHGhIVes2uXuAHihHBjx8obDxERERMW0pCeDgQGZj3+4QexSYiIiEhOTFhIw5IlwLVrYrlZM6BXL3njISIiApiwUDYxMcDUqVmP584FFAq5oiEiIsrChIUkU6cCL16I5f79xen3iYiIzAETFgIAXLkiNgcBYp+V4GB54yEiIsqOCQtBEMSOtpnDmIOCAA8PeWMiIiLKjgkLYdcu4J9/xHLFihzGTERE5ocJSzGX0zBmW1v54iEiIsoJE5ZibvFi4Pp1sdyiBfDBB/LGQ0RElBMmLMVY9mHMCgWHMRMRkfliwlKMTZkCvHwplgcMABo2lDUcIiKiXDFhKaYePgSWLhXL9vbAzJnyxkNERJQXJizF1J9/Zg1jHjMGKFdO1nCIiIjyxISlmPrjj6zyRx/JFwcREZE2mLAUQw8fAseOieU33wRq1ZI3HiIiovwwYSmGNm3KKvfsKV8cRERE2mLCUgxlbw7q0UO+OIiIiLTFhKWYefQIOHpULNeuLW5ERETmjglLMbN5c1aZzUFERFRYMGEpZrI3BzFhISKiwoIJSzESGQkcOSKW33gDqFNH3niIiIi0xYSlGNm0CRAEsczaFSIiKkyYsBQjbA4iIqLCiglLMREZCRw+LJZr1WJzEBERFS5MWIqJzZuzmoN69AAUCnnjISIi0gUTlmKCzUFERFSYMWEpBqKigEOHxHKNGkDduvLGQ0REpCu9EpZFixbBy8sLNjY28PHxwalTp3I9Nj09HdOnT0fVqlVhY2MDb29vhIaGahwzdepUKBQKja0WV+QzmC1bNEcHsTmIiIgKG50Tlo0bNyIwMBBTpkzBuXPn4O3tDX9/fzx58iTH4ydNmoRly5ZhwYIFuHLlCoYPH45u3brh/PnzGsfVqVMHkZGR0nYkc8IQKjA2BxERUWGnEITM797a8fHxQePGjbFw4UIAgFqthqenJz777DNMmDDhteM9PDzw9ddfY+TIkdK+7t27w9bWFr/++isAsYZl69atCA8P1+tNxMXFwdnZGbGxsXByctLrGkXVkydAuXKAWg1Urw5cv84aFiIiMg+6fH7rVMOSlpaGs2fPws/PL+sCFhbw8/PD8ePHczwnNTUVNjY2GvtsbW1fq0G5efMmPDw8UKVKFfTt2xcRERG5xpGamoq4uDiNjXK2ebOYrABsDiIiosJLp4Tl2bNnUKlUcHNz09jv5uaGqKioHM/x9/dHSEgIbt68CbVajT179mDz5s2IjIyUjvHx8cGqVasQGhqKJUuW4O7du2jZsiXi4+NzvGZwcDCcnZ2lzdPTU5e3Uaxkbw7q0UO+OIiIiArC6KOE5s2bh+rVq6NWrVpQKpUYNWoUBg0aBAuLrJfu2LEjevbsiXr16sHf3x87d+7Ey5cv8fvvv+d4zaCgIMTGxkrbgwcPjP02CqUnT4ADB8Ry1apA/fpyRkNERKQ/nRKWMmXKwNLSEtHR0Rr7o6Oj4e7unuM5rq6u2Lp1KxITE3H//n1cu3YNDg4OqFKlSq6v4+Ligho1auDWrVs5Pm9tbQ0nJyeNjV63ZQubg4iIqGjQKWFRKpVo2LAhwsLCpH1qtRphYWHw9fXN81wbGxuUL18eGRkZ2LRpE7p06ZLrsQkJCbh9+zbKlSunS3j0Co4OIiKiokLnJqHAwED8/PPPWL16Na5evYoRI0YgMTERgwYNAgD0798fQUFB0vEnT57E5s2bcefOHRw+fBgdOnSAWq3G+PHjpWPGjRuHgwcP4t69ezh27Bi6desGS0tL9O7d2wBvsXh6+hTYv18sV6kCvPWWvPEQEREVRAldT+jVqxeePn2Kb775BlFRUahfvz5CQ0OljrgREREa/VNSUlIwadIk3LlzBw4ODujUqRPWrl0LFxcX6ZiHDx+id+/eiImJgaurK1q0aIETJ07A1dW14O+wmNq6lc1BRERUdOg8D4s54jwsr2vfHtizRyyfOQM0bChvPERERK8y2jwsVDg8ewbs2yeWvbyABg1kDYeIiKjAmLAUQX/8AahUYpnNQUREVBQwYSmCli/PKvftK18cREREhsKEpYg5d07cAKBxY8DbW954iIiIDIEJSxHzyy9Z5SFD5IuDiIjIkJiwFCFJScC6dWLZzg748EN54yEiIjIUJixFyKZNQGysWO7VC+AIbyIiKiqYsBQh2TvbsjmIiIiKEiYsRcSNG8ChQ2L5jTeAfJZ2IiIiKlSYsBQRr3a25dwrRERUlDBhKQLS04FVq8SylRXQr5+s4RARERkcE5YiYPt24MkTsdy1K8A1I4mIqKhhwlIEsLMtEREVdUxYCrkHD4DQULFcqRLg5ydvPERERMbAhKWQW7UKUKvF8uDBgAX/RYmIqAjix1shplZnjQ5SKIBBg+SNh4iIyFiYsBRiYWHA/ftiuUMHwNNT3niIiIiMhQlLIcbOtkREVFwwYSmknj0DtmwRy2XLAu++K288RERExsSEpZBas0acMA4ABgwAlEp54yEiIjImJiyFkCBoNgd9/LF8sRAREZkCE5ZC6Phx4OpVsdyyJVCzprzxEBERGRsTlkKInW2JiKi4YcJSyMTFARs3imUnJ6BHD3njISIiMgUmLIXMxo1AUpJY7tsXsLOTNx4iIiJTYMJSyPz9d1aZM9sSEVFxwYSlEElLAw4cEMtubkDDhrKGQ0REZDJMWAqREyeAhASx7OfHhQ6JiKj44EdeIbJnT1a5XTv54iAiIjI1JiyFSPaExc9PvjiIiIhMjQlLIfHiBXD6tFiuXRsoX17eeIiIiEyJCUshsX8/oFaLZTYHERFRccOEpZBg/xUiIirOmLAUEpkJi5UV0KqVvLEQERGZGhOWQuDuXeD2bbHs6ws4OMgbDxERkakxYSkE2BxERETFHROWQiB7wtK+vXxxEBERyYUJi5lTqYCwMLFcsiSn4yciouKJCYuZO3tWnIMFANq0ASwt5Y2HiIhIDkxYzBz7rxARETFhMXtMWIiIiJiwmLWEBODYMbFcpYq4ERERFUdMWMzYoUNAerpYZu0KEREVZ0xYzBibg4iIiERMWMxYZsJiYSGOECIiIiqumLCYqcePgX//FcuNGolzsBARERVXTFjM1N69WWXObktERMUdExYzxf4rREREWZiwmJlbz28hNSNNSljs7YGmTeWNiYiISG5MWMxEhjoDfTb1QfUF1dF8aTtERwsAgNatAaVS3tiIiIjkxoTFDGSoM9BvSz+sv7weAHA25hBQ/hQANgcREREBTFhkp1KrMOivQdhweYPmE3XF5IUJCxERERMWWakFNYZsG4JfL/4KALCysIKVhZX4ZJ2NKFdehTfekDFAIiIiM8GERSZqQY1Ptn2CVeGrAAAlLErg956/o7FLR/EAxyjUffcQFAr5YiQiIjIXTFhkIAgCRu0cheXnlwMALBWW2NB9A7rW6ooyUb2l49JrrpcrRCIiIrPChMXEBEHA6NDRWHJmCQDAQmGBde+vQ/fa3QEAEXsDgDQ7AMD51D+RpkqTLVYiIiJzwYTFhARBwNjdY7Hg1AIAgAIKrOm6Br3e7AUAiIkBLpy2B653AQC8TH2B3bd3yxYvERGRuWDCYiKCIGDC3gmYc2IOADFZWdllJfrW6ysdExYGCAKAS1nNQplDnYmIiIozJiwm8u2hb/HDsR+kxz8H/IwB9QdoHCNNx3/bHw6W4mqHf137C0npSTq9VkJaAj7a/BF6/tETL1NeFiRsIiIis8CExQTORZ7D1ANTpcdLOy/Fxw0+1jhGrQZ27BDL1iWU6FFH7NOSmJ6Ibde36fR63x78FusurcOfV/7E9IPTCxQ7ERGROWDCYmSCIOCzXZ9BgDjV/rTW0/BJo09eO+70aSAyUiy3bw/0q69fs9DDuIeYf2q+9Pinsz8hJilGz+iJiIjMAxMWI/v14q849uAYAKBG6RqY0GJCjsdt2ZJV7toVaFWpFco5lAMA7Lq1S+umnakHpiIlI0V6nJieKHXyJSIiKqyYsBhRXGocvtzzpfR4QccFUFrmvJLh1q3iTwsLICAAsLSwxAd1PgAApKnSsOXqlhzPy+7q06tYGb4SAOCodEQJixIAgPkn5yM+Nb4A74SIiAqbdFU6jkQcQUJagtyhGAQTFiOadmAaohOjAQDdanVD+6rtczzu2jXg+nWx3Lw54Ooqlj9880PpGG2ahSbumwi1oAYABLUIQp+6fQAAL1Je4KezP+n7NoiIqJARBAFdNnRBy5Ut0WdTH7nDMQgmLEby75N/Me/kPACATQkbhPiH5Hps9uagbt2yyj7lfVDZpTIAIOxuGKITonO9xvEHx7H12lYAQDmHchjddDQmNJ8ABcS5/f93/H9IzUjV890QEVFhsuXaFuy6tQsAsO3GNjyMeyhzRAXHhMUIBEHA56GfQyWoAAATmk+Al4tXrsdnNgcBQJcuWWWFQiHVsqgFNf648keur/fV3q+kx1NbT4WdlR3ecH0DXWt1BQBEJkRi9YXVer0fIiIqPNJUaRqfCQB0Hm1qjpiwGMGfV/7Evrv7AABeLl4Y33x8rsc+egScOiWW69UDqlTRfL73m/mPFtp5cycORxwGIHbsHfzWYOm5oBZBUvn7o98jQ52h03shIqLCZfHpxbj1/JbGvr9v/C1TNIbDhMXAEtMSEbg7UHo8138ubK1scz3+72y/Q9mbgzLVdauLOq51AADHHhzD/Zf3NZ5XqVWYEJY18mhmm5lSZ1sAaFy+Mfyq+AEA7ry4gz/+zbmWhoiICr/nyc+l+bcUUMDFxgUAsO/uvkLf+ZYJi4EFHwmW2go7VOuA92q+l+fxrw5nzkn2WpYNlzdoPLfu0jpcfnIZANCkfBO8/8b7r50/scVEjfgEQcgzJiIiKpy+O/QdXqS8AAD08+4nfX6kqdIK/dp0TFgM6NbzW/jx2I8AACsLK8zrMA8KhSLX41++BPbvF8uVKgHe3jkfl9tooZSMFEzeP1l6/L3f9zm+Xmuv1vAp7wMAuPTkEnbc3KHtWyIiokLi1vNbWHhqIQBxsMeMNjM0vjRvu1G4+7HolbAsWrQIXl5esLGxgY+PD05ldsLIQXp6OqZPn46qVavCxsYG3t7eCA0NLdA1zdWY0DFIU6UBAAJ9A1GjdI08j9+5E8j4r0tJt25AbrlN1VJV0aR8EwDAhegLuPr0KgBgyekliIiNAAB0rNYRrb1a53i+QqHAxJZZtSwzD89kLQsRUREzYe8EpKvTAQBjfceiglMFtPZqDXsrewDA9hvboVKr5AyxQHROWDZu3IjAwEBMmTIF586dg7e3N/z9/fHkyZMcj580aRKWLVuGBQsW4MqVKxg+fDi6deuG8+fP631Nc7T9xnap5sLD0QOT3p6U7znaNAdlerXzbWxKLL47/B0AsZ0yuG1wnue/W+NdqS/M8YfHcej+oXzjIyKiwuFIxBFsuroJAOBm74avmoujhGxK2MC/mj8A4FnSM5x8dFK2GAtK54QlJCQEQ4cOxaBBg1C7dm0sXboUdnZ2WLFiRY7Hr127FhMnTkSnTp1QpUoVjBgxAp06dcL//vc/va9pblIyUjA6dLT0+H/t/wcHpUPe56QAu8Qh8ihdWpwwLi8f1PlAmlNlw+UN+OHoD3ie/BwA0LdeX3i759Ke9B8LhYXGiKGZR2bm/YJERFQoCIKAsbvHSo+nvzMdjtaO0uOAGgFS+e/rhXe0kE4JS1paGs6ePQs/P7+sC1hYwM/PD8ePH8/xnNTUVNjY2Gjss7W1xZEjRwp0zbi4OI1NTrOPzcadF3cAiGsA9arTK99zwsKAxESx/N57QIkSeR/v4eiBVl6tAAA3n9/ED8d+ACD2lZneWrsVmXu92UuaiG737d04+/isVucREZH52vjvRpx6JHajqONaR2NqCwDoXL2z9IW3MPdj0SlhefbsGVQqFdzc3DT2u7m5ISoqKsdz/P39ERISgps3b0KtVmPPnj3YvHkzIv9bmlifawYHB8PZ2VnaPD09dXkbBhWTFIOZh8XaCkuFJRZ0XJBnR9tMujQHZcreLJQ5n8qnjT9F5ZKVtTq/hEUJjTlhZh2dpd0LExGRWUrJSMGEvVlTW8xuP1tjagsAcLV3ha+nLwDgytMrr83RUlgYfZTQvHnzUL16ddSqVQtKpRKjRo3CoEGDYGGh/0sHBQUhNjZW2h48eGDAiHWz4+YOJGckAwCGNhiKum518z1Hpcqaf8XODmjXTrvX6v5Gd41fREelI75u+bVO8Q6sPxDuDu4AgE1XNuHas2s6nU9EROZj/sn5uB8rzs/Vvmp7dKjWIcfj3quRbbRQIZ31VqesoUyZMrC0tER0tOaaNtHR0XB3d8/xHFdXV2zduhWJiYm4f/8+rl27BgcHB1T5b0pXfa5pbW0NJycnjU0u229sl8qZiw3m5/hx4OlTsezvD9jmPq+chtJ2peFf1V96/GWzL+Fq76p1rIDYASuwqTixnQABPxz9QafziYjIPDxNfIoZh2cAEPspzm43O9djA2pm9WMprM1COiUsSqUSDRs2RFhYmLRPrVYjLCwMvr6+eZ5rY2OD8uXLIyMjA5s2bUKX/xbNKcg15ZamSsM/t/8BAJS0KSlVueUnt8UOtTH9nelws3dDa6/W+ML3C91O/s/wRsOl2Q/XXlwrDY0mIqLCY9rBaYhLFftwDq4/OM8a/jfKvIGqJasCAA7dP4QXyS9MEqMh6dwuExgYiJ9//hmrV6/G1atXMWLECCQmJmLQoEEAgP79+yMoKGs0ysmTJ7F582bcuXMHhw8fRocOHaBWqzF+/Hitr2mujkQckX5ZOlbv+Fq7YU4EIWuxQ0tLoHNn3V6zQbkGiBoXhf0D9uc7Eik3jtaO+KzJZwDEvjCZfXCIiKhwuPbsGpaeWQoAsLeyx/R38h58oVAopNFCKkGF0Fuvz4dm7nROWHr16oXZs2fjm2++Qf369REeHo7Q0FCp02xERITUoRYAUlJSMGnSJNSuXRvdunVD+fLlceTIEbi4uGh9TXOVvTno3ervanXO5cvAHXFAEVq1AkqVMkZk+fvc53Mp4fn53M/S9P5ERGT+xu8ZD5UgTgI3vvl4lHMsl+852We9LYyLISqEIjDlaVxcHJydnREbG2vS/iw1FtTAzec3YamwxJMvn6CUbf7Zx/TpwJQpYnnBAmDUKCMHmYdZR2YhKEysDfOr4ofdH+3WaoQT6efAvQM4/eg0Br81GKXtSssdDhEVUucjz6PBTw0AiFNe3Bh1A/ZK+3zPS1elw/VHV8SmxsLZ2hlPv3wKK0srY4ebJ10+v7mWkJ5uxNzAzec3AQDNKzbXKlkBspqDAOC/bjyyGdN0DLxcvAAAe+/s5RpDRvQg9gE6/NoB4/eOR6OfG+FC1AW5Q9Lantt78O3BbxGTFCN3KEQE4H/HsyZe/brl11olKwBgZWmFTtU7AQBiU2NxOOKwUeIzFiYsetpxI+vDXdvmoPv3gcwVCRo2BGScPgaAOGLoB7+sUUJjd4+V1kIiw1pzYQ1SVakAgHsv78H3F19svLxR5qjyFx4Vjo7rOuKbA9+gzZo2eJnyUu6QiIq1B7EPsOHyBgBAadvSGFh/oE7nayyGWMiGNzNh0dP2m9n6r9TQLmHJXrui6+ggY+lRuwdaVGwBQKw1WnJ6icwRFT2CIGDVhVUa+5IzkvHhpg8RtDfIaIuRhUeFF2gEmCAIGLVzlNROfjH6IgLWByApPclQIRKRjuafnC/9nxzZeCTsrOx0Or9DtQ7SAJG/rv9VqBbCZcKih9iUWGnxwColq6BWmVpanZc9YdF2dltjUygUmOs/V5q2eerBqaz6N7BjD45JM0u+XeltDPAeID036+gsBKwPMHjNxerw1Xhr2Vuos7gOwqPC9brGukvrcPTBUY19RyKOoNefvZCuSjdAlESki9iUWCw7uwwAYG1pjZFNRup8DRcbF7xd6W0AwN2Xd3Hl6RWtzrsYfRHnIs/p/HqGxIRFD7tv75amxn+3+rtadVSNiQEO/bdAcrVqQO3axoxQNw09GqK/d38AwMuUl5h6YKq8ARnA7tu70W9LPxx/kPN6VKa0KnyVVB7aYChWdlmJuf5zYamwBADsurULPst9cPXpVYO8XmJaIr7aK67UmpCWgH5b+iElI0Wna8SlxuHLPV9Kj2e1nSWNKtt+YzuGbBsCtaA2SLxEpJ3l55YjPi0eANDfuz/K2pfV6zrZF0PUZhK5Pbf3oMWKFuj8W2fce3lPr9c0BCYsetCnOWj7dkD939/3rl0BcxuMM7PtTKlqccmZJVpn3ebo2rNr6LKhC369+CvarmmLIxFHZIslKT0JG/8V+6o4Kh3RrVY3KBQKjG46Grv77UZpW3G00I2YG/BZ7mOQNuX5J+cjOjFr5ujLTy5j0r5JOl1j+sHpiEoQ1/LqWqsrvmrxFf768C8oLZUAxD45X+7+slBVJ1PxkrnGTv8t/bH79u5Cn2Cnq9Ix9+Rc6XGgb6De19Jl9ebV4avR6bdOiE+LR1RCFL7Z/43er1tQTFh0pFKrsPPmTgCAg9JBqlrLT0FmtzUFD0cPBLUQhzirBBXG7R4nc0T6yVBnYMDWAVKNQnJGMjr/1lm2lam3XN0ifSP6oM4HGr3521Rug9NDT6OeWz0AQHxaPLps6ILvDn2n9x/XF8kvpJW8LRQWUoIRcjwE++/u1+oaV55ewbyT8wCIHbND2odI8a7vvh4WCvHPRsiJEHx/9Hu94iQypufJz9FubTt8f/R7rL24Fv6/+uONRW9g/sn5iE2JlTs8vfxx5Q88jHsIQEw4tO2KkJOqpaqitqtYzX/i4Qk8SXzy2jGCIODbg99i4F8DpRaF92q+h6XvLtX7dQuKCYuOTj06hWdJzwCIC01Zl7DO95z0dGDPHrHs5gb4+BgzQv2N9R0LTydx6NKuW7uw6+YumSPS3Y9Hf5SWWc/slxOXGgf/X/3x75N/TR5P9s622fuuZKpcsjKODT6GD+p8AEBc32ny/skYtVO/CXp+PPaj1B9mgPcABLcNlq47YOuAfP9YC4KAz3d9Lv2BmtB8gsZq4O+/8T6Wds76gxUUFoTl55brFSuRMdx9cRfNfmn2Ws3qjZgbGB06GuVDyuPTHZ/q9PcgOT05xw91UxEEAbOPZa0TNNZ3bIGvmbkYogBBY9QrINbmDN02FN8cyKpNGdl4JDZ/sFnnTr6GxIRFR/rMbnvhApD038CKNm3EKfnNka2VLX5opznMuTB1rrwYfRFTDoiz8lkoLLC3/160rNgSABCTHAO/tX4mXVY9IjYCYXfENbKqlKwijcZ6lb3SHhu6b0Bw22ApyVpyZgm2Xtuq0+tFJURJNSNKSyWmtp6KMU3H4B2vdwAAD+Ie4PPQz/O8xqarmxB2V4zZy8UL45uPf+2YoQ2HYmabrOUcPtn+CTZf3axTrETGcObxGTT9pSmux1wHALjZu2Fxp8XS/wEASExPxJIzS/Dmkjfxzup3sOnKJmSoMxCfGo/wqHD8eeVPfH/kewz9eyjeWf0OPOd4wm6mHdxmu8H3F19cir5k8ve1/95+nI8S58Ro5NFI65r9vOS2GGJ8ajze2/Aefjn/i7Tvx3Y/YkHHBbC0kPfDiwmLjrL3X8mcgCc/x7P1+zTz9RzRq04v+FYQg7z67KrUI93cpanSMGDrAKSrxQTry2Zfok3lNtjeZzsaeTQCIH6g+63xw4PYByaJae2FtRAg9vEY6D0wz87ZCoUCE1pMwE8BP0n7hm4biuiE6FzPedV3h76ThhyPaDQCFZ0rwkJhgVVdV8HJWpxBcs2FNfjzyp85np+YlojAf7Laxef6z4WtVc5LiU9oMUFa9VstqNF7U2+tm5wKm8P3D6PlypYYtm2YSRNe0s32G9vRalUrqSakVplaODHkBEY0HoF9A/bh8ojLGNFoBOytspplD9w7gB5/9IBTsBOcZjnhrWVvoecfPTEhbAKWn1+OA/cOSM0wgNh80uCnBpgYNhHJ6ckme2/ZJ4ob5zvOIDOS+5T3gaudKwDgn9v/ICUjBZHxkWi1qpW0zpDSUokN3TdgXDPDvGZBMWHRQURsBC5GXwQANCnfBG4O2q11VJgSFoVCgTn+c6THUw5MKRSren536Dtp+G4d1zqY1noaAMDJ2gmhfUPxZtk3AQD3Y+/Db62fTomAPl6deyVzFFZ+Pn7rY3St1RUA8CzpGYZsG6JVx9a7L+7ip7NismNvZY+JLSdKz1V0roiFHRdKjz/Z/gki4yNfu8asI7PwIE5M5vyr+mtMMPUqhUKBH9v/KL2vNFUaumzoghmHZmDNhTUIuxOGa8+uIT41Pv83bcZuPb+FgPUBOBJxBD+f+xk1F9ZEvy39cO3ZNblDM4jk9GTMOT4H6y+tL9QdqJedWYYuG7pICXvLii1xdPBRaSZvAKhTtg4Wd16MR4GPMK/DPNQoXUN6Ljkj9+SjjF0ZNK3QVFrpOEOdgeAjwai7pK5Ug2pM/z75V+o3Wcm5ErrX7m6Q61paWKJzDXH13aT0JCw6tQhNf2kq1eS42LhgT7896PVmL4O8niFwLSEdLD2zFCN2jAAATG89HZNbTdbqvMqVgXv3AFtbIDYWsJJ36Qat9NvSD79e/BUAMMZnDOZ0mJPPGfI58/gMmi5vCpWgQgmLEjg55CQalGugcUxUQhRarmwpfUOu51YP+wfs13pJBV0djTiKFivFJqA2ldsgrL/2f9ieJj7Fm0velL4p/vTuTxjacGie5/Tf0h9rL64FAEx+e/JrK7cKgoAP/vxAql3pWK0jdvTZIX1ruvX8FuosroM0VRqsLKxwacQl1CxTM99Y01XpeP/39zWaSl/lqHREeafyKO9YHuWdyqOxR2N0qNYB1UpVy/f6r1KpVTgbeRZ77+yFlYUV+nn3g7uDu87X0UZiWiKa/tI0x4VBFVCg15u9MKnlJNQpW8cor29sL1NeSskYACx7dxmGNRwmc1S6UQtqTNo3CcFHgqV9H9T5AKu7roZNCZt8z917Zy8Wn16MC9EXUMGpAqqVqoZqJauJP0tVQ9VSVeFi4wJAHHUUfDgYwUeCpZpcQOwrNrv9bJSxK2OU9/jxXx9jRfgKAMAc/zkY03SMwa695eoWvP/7+6/tr+RcCbv67sIbrm8Y7LVyo8vnNxMWHbz727vSejvnhp3DW+XeyvecyEjAw0Msv/02cPCg0cIzqIdxD1FjQQ0kZySjhEUJXB5xWasPMFNLyUhBg2UNcPWZOIfJ1FZTMaX1lByPvf/yPlqubCnVIjQp3wR7++2Fo7WjweMa+vdQLD8vdkZd03UN+nn30+n87Te2I2C92MZsb2WPC8MvoGqpqjkee/nJZdRbUg8CBJSyLYU7n9+Bs43za8fFJMWg7pK6iEwQa1eWdF6C4Y2GAwAC1gdIScdXzb/CLL9ZWseanJ6M9za8h7139ur0HquWrIoO1TqgQ7UOeMfrnVzXQ4lKiMI/t/5B6O1Q7L69G8+Tn0vP2ZSwwbAGwzC++XiUdyqv0+vnRRAE9N7UWxqSXqtMLfSt2xdzTszReH0A6P5Gd0x+ezK83b0N9vrGFhkfCf9f/XHpSVZ/DKWlEscGH0NDj4ZGe92XKS9xNOIo4tPikZyejOSMZCSlJ0nlzJ+pqlSUtCkpJbmZPz0cPaREJE2VhsF/Dca6S+uk63/Z7EvM8psljWQzhitPr+CT7Z9odOotY1cGc/znoG/dvgZtOolKiEKluZWQpkqDs7UzHnzxwKB/rxLSElD6h9IaS7I0KNcA23tv12r1Z0NgwmIESelJKP1DaaRkpMDD0QMPv3io1S/m5s1A9/9q8L76Cpil/eeA7KYdmIapB6cCADpX74ztfXL/Fi2X8XvG48djPwIQ/6Od+PhEnquP3oy5iZYrW0rzlLT2ao2dfXbm2ldDH0npSXCf7Y74tHg4KB0QNTZK68XJshu2bRh+PvczAMC3gi8ODTokTamdXdcNXfHX9b8AiJ3jxjXLfUh66K1QdFzXEQBgZ2WH85+cx42YG1Jy5OHogeujrkuTxGlLEAScizyHey/v4VH8IzyKeyT+zFbOa0p/paUSLSu2RIdqHdC+anu8SH6B0FuhCL0dqtVMvUpLJYa8NQRftfgKFZ0r6hR7TkKOh2DsbnEkhqPSEaeGnkKtMrUQnxqPJWeWYPax2Xia9FTjnC41u2Biy4lo7NHYLNr7c3Mz5iba/9pemgDMUmEpTfXu5eKFs8POGrTmUS2ocfDeQfxy/hdsurpJ50kMX1XatjTKO5VHmipNappTQIEFHRfoNfOrPtSCGsvPLcf4PeMRm5o18q5dlXZY3HmxXrWHOZm0bxJmHJ4BQPcvEtrq/FtnqcmpY7WO+L3n7zr//y8IJixGkP0b77AGw7AsQLvOqF9+Ccz+bzTa1q3yr9Csi6T0JNRcWFPqdLat9zatJ8ozhaMRR9FyZUsIEKC0VOLcsHNaVc9fir6E1qtbS9+U67jWweC3BqNXnV4G+Za+7uI6fLTlIwDA4PqD8UuXX/I5I2cJaQnwXuqNOy/uAABmtJmh0TcFEDsB+v4idowq71geNz+7mW/y9emOT7HkjLhmVJPyTRCTFIPbL24DANZ3X48P3/xQr3jzIggCYlNjcev5LYTdCUPo7VAciTgiDZ/WlpO1E9pVaQf/qv64EXMDi88s1kiErCysMKj+IAS1DNLov6CL/Xf3o93adtKH+JZeW6R+RZkS0xKx7Owy/HjsR2mCvUz13Orh47c+Rt+6fVHarrReMRjLuchz6PBrBynZ8nLxwvbe4szFJx6eACB+Ofm7998FrqV4FPcIq8JXYUX4Cul32BhsS9hifff16FLL9H9cI+MjMTp0NP648oe0z8rCCsMaDsPXLb8uUC1FYloiPOd44kXKC5SwKIF7o+8ZtBYx05WnVzAmdAyaVmiKb1p9k+OXImNiwmIEw7cPl0bM/PXhX3l2SMyuRQvg6H/LsURHA2X1m0lZNhsvb8SHm8QPsKolq+Lyp5fzbRs2hcS0RNRfVl/qk/K93/c5DsHNzelHp9F2TVtpUjdA/JbWyqsV+rzZB91rd9f7W2b7te2x54448c6hgYfQslJLva4DiOsQtVzZEmpB/Vr/HEEQ0HZNW+y/J47O0bYPQmJaIt5a9hZuPr+psb9VpVbYP2C/yWoH4lPjse/uPqkmJbcpvxt5NIJ/VX90qNYBPuV9NGrQniY+RcjxECw8vRAJaQnS/hIWJdC/Xn8EtQzS6dvug9gHaPBTA2mupa9bfo3v2nyX6/HJ6clYfm45Zh2dhcfxjzWeU1oq0a1WN3z81sdoW6WtUZsptLHv7j503dBV+p1/s+yb+Oejf+Dh6PHa+84pOdZGmioN229sxy/nf0HordDXJkAsaVMSfer2QbVS1WBnZQfbErawtbJ97afSUomYpJhca+sexz9GmioN7g7u2NprK3wqyDu51fYb2/Hpjk+l5mZATKRG+4zG+ObjUdK2pM7XXHRqEUbtEudj6u/dH6u7rjZYvOaECYuBCYIAzzmeeBT/CNaW1ogZH6NVFX9aGuDkBKSmAlWqALdvGzw0oxMEAW3WtMGBewcAAN+98x2+fvtreYMC8NnOz7DwtDjyxbeCLw4POqzzHAEnH57EZ7s+w+nHp197zsrCCh2rd0SfN/sgoGaA1pMlPYh9gEpzK0GAgColq+DWZ7cKnAB8HfY1Zh4R5z2p7VobZ4aega2VLfbc3oP2v7YHAFQrVQ1XPr2SZ3NYdicfnkTzFc2lWgRLhSXOfXJOmnXX1ARBwM3nNxF6KxQH7h2Ag9IB/lX90a5qO63WS4lJisHcE3Mx/9R8xKXGSfstFZYY4D0AU1pPybepKCUjBW+vfFv6ffCv6o8dfXZo9XuVkpGCdRfXYfn55VJNRXYVnStiUP1BGFR/ECq5VMr3eob255U/0XdzX6mvQnPP5tjWe5vGB+me23vg/6s/BAiwUFhg90e70bZKW62un6ZKww9Hf8D8k/NfayoDAL8qftIIOEN84REEATHJMXBUOmo1eacpJKQl4IejPyDkeAgS0xOl/S42LhjfbDw+9/lc66ZhlVqFGgtrSDVTF4ZfkO3/prExYTGw8KhwvLVM7GDbsVpH7Oy7U6vzTp3KmtX2o4+AtWsNHppJXIq+hLeWvQWVoIJtCVtcG3XNIP0E9LXv7j60XSP+IbUtYYvw4eEaQxR1dSPmBtZfWo/fLv+GGzE3Xnve3soe/b3743u/7/Pt8Dbz8Ex8vU9M6Ka1noZvWhV83Y00VRqaLs8abjjGZwxC/EPQZHkTnHl8BoB+TTlTD0zFtIPi8O/Pm3yOeR3nFThWub1IfoH5J+dj7sm5GitgKy2V+LTRp5jYciJc7V1fO08QBAzdNlSaLKuyS2WcGXZGr1q2f5/8i1/O/4K1F9dKNRaZFFCgcfnGcHdwRynbUihtWxqlbEu9tlVwqqD3wnavWnpmKT7d8ak0J9C7Nd7Fxh4bc0zCpx+cLk2+6GrnivOfnM+3GeJ85HkM/GugNOVDJk8nTzFJe2uQ3s1zhdGTxCeYeXgmlpxZotGZ1d3BHZNaTsLQhkOlJTNys+nKJvT4owcAsV/M7n67jRqznJiwGNh3h77D5P3iEOZFnRbh08afanXe3LnAF1+I5UWLgE+1O80sjQkdI82i2rN2T/ze83dZ4thxYweGbBsi9RuY12EePvfJe/ZWbWV2HP3t0m/Y8O+G16r4q5eqjo09NuY6OkwQBNRcWFNqark7+q7B/lBfeXoFDZY1QKoqFQDwWZPPsODUAgCAt5s3zn1yTucmhwx1Br4/8j3iUuMwtfVUg3Y8lltsSiwWnFqA2cdma3SKdFA6ILBpIAJ9AzVGUv109id8sv0TAGISfPzj4wUe9ZOmSsO269vwy/lf8M/tf3ReH2pp56X4pNEner++IAj49tC3UgICAAPrD8TPAT/n2k9BLajR+bfO0sRhzTyb4cCAAznW3KWp0jDj0AzMPDJT6otkqbDE+2+8jyENhqBt5bayz4wqp/sv72PawWlYfWG1xr99ZZfK+KjeR7CyyL02dOO/G/HvU3HpgH8++gftq7Y3erxyYcJiYE2XN8XJRycBAPdG39O6SrdXL+D3/z7Xz50D3sp/FLTZepnyEjUX1pTmBtnbb6/W1cWGEJUQhdGho/H7v1mJUmuv1gjrH2aUvgEqtQqH7h/C+svrsf7yeql/hNJSidntZmNUk1GvNfUce3AMzVc0BwC84/UO9g3YZ9CY5p6Yiy/++eK1/dt7b5cmgCJNL5Jf4IejP2DeyXkak4OVsi2FoBZBGNl4JC5EX8DbK9+W5tb4tduv6Fuvr0HjeBj3EKvCV2FV+Cqpg3N+7K3scW3UNVRwqqDXawYfDsbEfVn9UL5s9iW+9/s+3ybKmKQYNPipASJiIwDkPA9TeFQ4Bm4diAvRF6R99dzqYVWXVVpN91CcXH16FZP3T8amq5t0Prdu2bq4MPyCWY86KygmLAb0JPEJ3Ge7Q4CAumXr4uKIi/mf9J+KFYEHDwB7e+DlS6CEaTtfG9yq8FUY9NcgAMAbZd7AheEXtO4zoS+1oMYv537Bl3u+1Pim7FfFD792+1Xr2YYL4vbz2/hw04dS8wsgDmFd0WWFRpNB9mHIq7uu1np2W22pBTXarW2HfXezEqHmns1xeNDhIv0HzRAi4yPx3aHv8NO5nzRGJnk4ekAtqKUau9E+ozG3w1yjxpKSkYIXyS/wPPl5jtvRB0dx8L44YZO+tZmXn1xGg2UNpCTsB78f8GXzL7U+/9SjU2ixooV0/u89fkfPOj2RpkrDzMMzMePwDI1alYktJ2LS25Pybeoozs48PoOv932N3be1b97Z/MFmdHujmxGjkh8TFgNaHb4aA/8aCAAIahGEmW1n5n3Cfx49Air898WodWtgfxFYZkUtqNF8RXOpU+H/2v8Pgb6B+Zylv6tPr+KT7Z/gcMRhaV8ZuzIIaR+Cj+p9ZNIP6TRVGoL2BiHkRIi0z9PJE791/w0tKrZAUnoSyv2vHOJS4wo090p+HsQ+QN0ldaXkraCjkIqbOy/uYMqBKVh3cZ3UpyPT25Xext5+e42ehOfnRfIL1FxYU+q8qmuTgEqtQrMVzaRVyyc0n4Bgv+B8znrd4tOLMXKnOK+Jg9IBq7qswreHvtWoValbti5WdV312szSlLtL0Zc0RhPlpqJzRWlJkaKMCYsB9fyjpzSd+dHBR9HMs5lW5/35J9Czp1gOCgJmapfnmL2zj8+i8c+NIUCAo9IR10ddN/iMiKkZqQg+Ik6Bnb3TmrGnwNbGjhs7MGDrAMQkxwAQv11Oaz0NFZ0rov9WsUZlUP1BWNFlhdFi2HN7D8bvHY8uNbtgauupRnudouxS9CVM3j9ZmnCvvGN5nB121iQ1dtrIXptZvVR1XBpxSevRMHOOz0HgbvGLRM3SNRE+PFyvkTmCIOCjLR/ht0u/vfYca1XIUJiwGEiaKg1lfiiD+LR4lLYtjehx0Vp3Ihs7Fgj578v4tm3Au+Yz31qBfbLtE/x0Tlxor1+9fljTbY3Brn3o/iF8sv0TjcXlqpasimXvLjNpn5m8PIx7iL6b++LQ/UPSPqWlUkquDg48aJDl38n4Tj48iYP3D6L3m73h6ewpdzgStaDG2yvfxtEH4iRO2k4ncOfFHdRdUleaTO/woMNoUbGF3nEkpiWiyfImuPL0irSPtSpkSLp8fnO15jwcvn9YmmSpU/VOOvV4P3Ysq9y0qaEjk9eMtjNQ0kacv2HtxbU4GnG0wNeMSohC/y390WpVKylZKWFRAkEtgnBpxCWzSVYAoIJTBezrvw9TWk2BAmKzVGayUqVklQJ9QJBp+VTwwfjm480qWQEAC4UFFndeDEuF+DdnxuEZuU6sl0kQBAzbNkxKVkY2Hlng30V7pT02fbAJFZwqwMrCCpNaTsKZYWeYrJAsmLDkIfsKtLpMSZ+aKo4KAoDq1YEy8rVgGEUZuzKY0WaG9HjUrlFQqVV6XStDnYG5J+ai5sKa0mrDAOBT3gfnhp3DzLYzzXK4raWFJaa2nop9A/ahnENWk9gA7wGyz2hKRUM9t3r4rMlnAIDkjGSMDh2d5/Erw1ci7K64KrinkyeC2+rebyUntcrUwvVR1xE7IRbftvmWTUAkGzYJ5eFp4lOE3grF9pvbsezdZdIy4/k5fhxo9l9Xl/79gdVFcEZllVqFRj83khamW9xpMUY0HqHTNQ7eO4hRu0bh8pPL0r6SNiUxo80MDGs4rNDM4fA08Skm75+M5IxkLO602Cidbal4ikuNQ62FtaQVtv/+8G8E1Ax47bjI+EjUXlxbmixvR58d6FS9kylDJdIL+7DILCRE7MMCAEuWAMOHyxuPsRyNOIoWK8Uq55I2JXHjsxtadYh9HP8YX+75UqMznwIKfPzWx5jZdmaOM5ESFVcbLm9A7029AYiLFf776b+vzVLb/ffu2Hx1MwDgo3ofYW23QjqtNhU7unx+F/KZQczT8eNZZV9f+eIwtuYVm6NfvX5Ye3EtXqS8QLu17dCoXCOUdyqP8o7lNX6Wti2NDHUG5p+cj6kHp2osVNfIoxEWdVqEJuWbyPhuiMxTrzq98PO5n7Hv7j7ce3kPwYeD8W2bb6XnN13ZJCUrZezKYI7/nNwuRVSosYbFwARBnH/l8WPAwUGcMM6ycLRs6CUyPhI1F9bUWPU4J0pLJeyt7PEi5YW0r5RtKQS3DcbHb31caJp/iORw7dk11FtSD+nqdCgtlbg84jKql66OF8kv8MaiNxCdGA1AvzWliOTEUUIyevBATFYAceHDopysAEA5x3JY0nkJHJV5LwqYpkqTkhUFFBjecDhujLpRqPqqEMmlVplaGOsrtjOnqdIwatcoCIKAsbvHSslKQI0A9KrTS84wiYyKTUIGVlyag7LrW68vetftjZikGDyKf4RHcY80f/5Xjk6MRj23eghuG4xGHo3kDpuoUJn09iT8dvk3RMRGYPft3fh81+dYGb4SAOCodMTizou5RAMVaUxYDKw4JiyAOG+Eq70rXO1dUd+9vtzhEBU59kp7zPWfi/d/fx8AsPD0Qum5H9v9qPciiUSFBZuEDCx7wlLUJowjInl1rdUVHat11NjXqlIrDG04VKaIiEyHCYsBpaQA58+L5Zo1gVKl8j6eiEgXCoUCCzougLWluK6QTQkb/BzwMycrpGKBv+UGdPYskC6uxi5NHEdEZEhVS1XFuvfX4e1Kb2N99/WoXrq63CERmQT7sBhQ9vWDilP/FSIyre61u6N77e5yh0FkUqxhMaDi2uGWiIjI2JiwGIggZCUsTk5A7dryxkNERFSUMGExkPv3gagosezjA1jwzhIRERkMP1YNhM1BRERExsOExUCyJywcIURERGRYTFgMJPsIIR8f+eIgIiIqipiwGEBSEnDhgliuXRtwcZE1HCIioiKHCYsBnDkDZGSIZfZfISIiMjwmLAbADrdERETGxYTFAJiwEBERGRcTlgLKPmGciwtQq5as4RARERVJTFgKKCICePJELDdtygnjiIiIjIEfrwX06FFWuWZN+eIgIiIqypiwFNCzZ1llV1f54iAiIirKmLAUUPaEpXRp+eIgIiIqypiwFFD2hKVMGfniICIiKsqYsBRQTExWmQkLERGRcTBhKSDWsBARERkfE5YCYsJCRERkfExYCoidbomIiIyPCUsBZSYszs6AlZW8sRARERVVTFgKKDNhYe0KERGR8TBhKQCVCnjxQiyz/woREZHxMGEpgBcvxMUPASYsRERExsSEpQA4QoiIiMg0mLAUABMWIiIi02DCUgBMWIiIiEyDCUsBMGEhIiIyDSYsBcBJ44iIiEyDCUsBsIaFiIjINJiwFABXaiYiIjINJiwFwBoWIiIi02DCUgDZE5ZSpeSLg4iIqKjTK2FZtGgRvLy8YGNjAx8fH5w6dSrP4+fOnYuaNWvC1tYWnp6e+OKLL5CSkiI9P3XqVCgUCo2tVq1a+oRmUpkJS8mSQIkS8sZCRERUlOn8Mbtx40YEBgZi6dKl8PHxwdy5c+Hv74/r16+jbNmyrx3/22+/YcKECVixYgWaNWuGGzduYODAgVAoFAgJCZGOq1OnDvbu3ZsVWCHIALjwIRERkWnoXMMSEhKCoUOHYtCgQahduzaWLl0KOzs7rFixIsfjjx07hubNm6NPnz7w8vJC+/bt0bt379dqZUqUKAF3d3dpK2PmnULS04GXL8WymYdKRERU6OmUsKSlpeHs2bPw8/PLuoCFBfz8/HD8+PEcz2nWrBnOnj0rJSh37tzBzp070alTJ43jbt68CQ8PD1SpUgV9+/ZFRERErnGkpqYiLi5OYzO158+zykxYiIiIjEundpdnz55BpVLBzc1NY7+bmxuuXbuW4zl9+vTBs2fP0KJFCwiCgIyMDAwfPhwTJ06UjvHx8cGqVatQs2ZNREZGYtq0aWjZsiUuX74MR0fH164ZHByMadOm6RK6wXFIMxERkekYfZTQgQMHMHPmTCxevBjnzp3D5s2bsWPHDnz77bfSMR07dkTPnj1Rr149+Pv7Y+fOnXj58iV+//33HK8ZFBSE2NhYaXvw4IGx38ZrOKSZiIjIdHSqYSlTpgwsLS0RHR2tsT86Ohru7u45njN58mT069cPQ4YMAQDUrVsXiYmJGDZsGL7++mtYWLyeM7m4uKBGjRq4detWjte0traGtbW1LqEbHBMWIiIi09GphkWpVKJhw4YICwuT9qnVaoSFhcHX1zfHc5KSkl5LSiwtLQEAgiDkeE5CQgJu376NcuXK6RKeSTFhISIiMh2dxw4HBgZiwIABaNSoEZo0aYK5c+ciMTERgwYNAgD0798f5cuXR3BwMAAgICAAISEheOutt+Dj44Nbt25h8uTJCAgIkBKXcePGISAgAJUqVcLjx48xZcoUWFpaonfv3gZ8q4bFhQ+JiIhMR+eEpVevXnj69Cm++eYbREVFoX79+ggNDZU64kZERGjUqEyaNAkKhQKTJk3Co0eP4OrqioCAAMyYMUM65uHDh+jduzdiYmLg6uqKFi1a4MSJE3B1dTXAWzQO1rAQERGZjkLIrV2mEImLi4OzszNiY2Ph5ORkktfs3x9Yu1YsX70KFIKJeYmIiMyKLp/fXEtITxzWTEREZDpMWPSU2SSkUIhrCREREZHxMGHRU2bCUqoU8F/fYSIiIjISJix6ykxY2BxERERkfExY9JCWBmQuX8QhzURERMbHhEUP7HBLRERkWkxY9MCEhYiIyLSYsOiBk8YRERGZFhMWPTBhISIiMi0mLHpgwkJERGRaTFj0wISFiIjItJiw6IErNRMREZkWExY9sIaFiIjItJiw6IHDmomIiEyLCYseMmtYLCwAFxdZQyEiIioWmLDoITNhKV1aTFqIiIjIuPhxqwcufEhERGRaTFh0lJICJCSIZY4QIiIiMg0mLDpih1siIiLTY8KiIw5pJiIiMj0mLDpiDQsREZHpMWHREWtYiIiITI8Ji46YsBAREZkeExYdMWEhIiIyPSYsOuLCh0RERKbHhEVHrGEhIiIyPSYsOmLCQkREZHpMWHSUOazZ0hJwdpY3FiIiouKCCYuOsq8jpFDIGwsREVFxwYRFR1z4kIiIyPSYsOggKUncACYsREREpsSERQfZp+XnkGYiIiLTYcKiA44QIiIikgcTFh1w4UMiIiJ5MGHRAWtYiIiI5MGERQdMWIiIiOTBhEUHTFiIiIjkwYRFB0xYiIiI5MGERQdcqZmIiEgeTFh0wBoWIiIieTBh0UHmsGYrK8DRUd5YiIiIihMmLDrgwodERETyYMKiJUHgwodERERyYcKipaQkICVFLDNhISIiMi0mLFriCCEiIiL5MGHREkcIERERyYcJi5aYsBAREcmHCYuWuFIzERGRfJiwaIk1LERERPIpIXcAhQUTFiKiokOlUiE9PV3uMIoFKysrWFpaFvg6TFi0xISFiKjwEwQBUVFRePnypdyhFCsuLi5wd3eHogCzrjJh0RKHNRMRFX6ZyUrZsmVhZ2dXoA9Qyp8gCEhKSsKTJ08AAOXKldP7WkxYtMQaFiKiwk2lUknJSml+8zQZW1tbAMCTJ09QtmxZvZuH2OlWS5kJi7U1YG8vbyxERKS7zD4rdnZ2MkdS/GTe84L0G2LCoqXMYc1c+JCIqHBjM5DpGeKeM2HRAhc+JCIikhcTFi0kJABpaWKZCQsRERVmXl5emDt3rsGud/ToUdStWxdWVlbo2rWrwa77Kna61QI73BIRkZxat26N+vXrGyTROH36NOwN2BkzMDAQ9evXx65du+Dg4GCw676KNSxa4JBmIiIyZ4IgICMjQ6tjXV1dDdrx+Pbt22jTpg0qVKgAFxcXg133VUxYtMAaFiIiksvAgQNx8OBBzJs3DwqFAgqFAqtWrYJCocCuXbvQsGFDWFtb48iRI7h9+za6dOkCNzc3ODg4oHHjxti7d6/G9V5tElIoFFi+fDm6desGOzs7VK9eHX///Xe+cd27dw8KhQIxMTEYPHiwFJexMGHRAhMWIiKSy7x58+Dr64uhQ4ciMjISkZGR8PT0BABMmDABs2bNwtWrV1GvXj0kJCSgU6dOCAsLw/nz59GhQwcEBAQgIiIiz9eYNm0aPvjgA1y8eBGdOnVC37598fz58zzP8fT0RGRkJJycnDB37lxERkaiV69eBnvfr2IfFi1wpWYioqKrUSMgKsq0r+nuDpw5o92xzs7OUCqVsLOzg7u7OwDg2rVrAIDp06ejXbt20rGlSpWCt7e39Pjbb7/Fli1b8Pfff2PUqFG5vsbAgQPRu3dvAMDMmTMxf/58nDp1Ch06dMj1HEtLS2m6fWdnZyk2Y2HCogXWsBARFV1RUcCjR3JHoZ9GjRppPE5ISMDUqVOxY8cOREZGIiMjA8nJyfnWsNSrV08q29vbw8nJSZpO31wwYdECExYioqLLyBUDRn3NV0f7jBs3Dnv27MHs2bNRrVo12NraokePHkjLnJsjF1ZWVhqPFQoF1Gq1YYI0ECYsWmDCQkRUdGnbNCMnpVIJlUqV73FHjx7FwIED0a1bNwBijcu9e/eMHJ1psNOtFjismYiI5OTl5YWTJ0/i3r17ePbsWa61H9WrV8fmzZsRHh6OCxcuoE+fPmZXU6IvJixayExYbG0BrplFRESmNm7cOFhaWqJ27dpwdXXNtU9KSEgISpYsiWbNmiEgIAD+/v5o0KCBiaM1DoUgCILcQRRUXFwcnJ2dERsbCycnJ4Nfv1w5sVOWpyeQT78lIiIyUykpKbh79y4qV64MGxsbucMpVnK797p8frOGJR9c+JCIiEh+eiUsixYtgpeXF2xsbODj44NTp07lefzcuXNRs2ZN2NrawtPTE1988QVSUlIKdE1TiYsDMmc7ZsJCRETFyfDhw+Hg4JDjNnz4cJPGovMooY0bNyIwMBBLly6Fj48P5s6dC39/f1y/fh1ly5Z97fjffvsNEyZMwIoVK9CsWTPcuHEDAwcOhEKhQEhIiF7XNCWOECIiouJq+vTpGDduXI7PGaMLRl50rmEJCQnB0KFDMWjQINSuXRtLly6FnZ0dVqxYkePxx44dQ/PmzdGnTx94eXmhffv26N27t0YNiq7XNCWOECIiouKqbNmyqFatWo6bqSsUdEpY0tLScPbsWfj5+WVdwMICfn5+OH78eI7nNGvWDGfPnpUSlDt37mDnzp3o1KmT3tc0JdawEBERyU+nJqFnz55BpVLBzc1NY7+bm5u0rsGr+vTpg2fPnqFFixbS8tfDhw/HxIkT9b5mamoqUlNTpcdxcXG6vA2dMGEhIiKSn9FHCR04cAAzZ87E4sWLce7cOWzevBk7duzAt99+q/c1g4OD4ezsLG2Zq1YaAxc+JCIikp9ONSxlypSBpaUloqOjNfZHR0fnukrj5MmT0a9fPwwZMgQAULduXSQmJmLYsGH4+uuv9bpmUFAQAgMDpcdxcXFGS1pYw0JERCQ/nWpYlEolGjZsiLCwMGmfWq1GWFgYfH19czwnKSkJFhaaL2NpaQkAEARBr2taW1vDyclJYzMWJixERETy07lJKDAwED///DNWr16Nq1evYsSIEUhMTMSgQYMAAP3790dQUJB0fEBAAJYsWYINGzbg7t272LNnDyZPnoyAgAApccnvmnJiwkJERIWdl5cX5s6dq9WxUVFRaNeuHezt7eHi4mLUuHSh8zwsvXr1wtOnT/HNN98gKioK9evXR2hoqNRpNiIiQqNGZdKkSVAoFJg0aRIePXoEV1dXBAQEYMaMGVpfU04c1kxERMXJnDlzEBkZifDwcDg7O8sdjoRrCeWjdm3g6lXA3h5ISDDopYmIyISK81pCXl5eGDNmDMaMGZPvsT169IC9vT1Wr15tsNfnWkImwHWEiIhITj/99BM8PDygVqs19nfp0gWDBw/G7du30aVLF7i5ucHBwQGNGzfG3r179XotLy8vbNq0CWvWrIFCocDAgQMN8A4MgwlLHtRq4PlzscyEhYiI5NCzZ0/ExMRg//790r7nz58jNDQUffv2RUJCAjp16oSwsDCcP38eHTp0QEBAACIiInR+rdOnT6NDhw744IMPEBkZiXnz5hnyrRSIzn1YipPYWEClEstMWIiIiqZGPzVCVEKUSV/T3cEdZ4ad0erYkiVLomPHjvjtt9/Qtm1bAMCff/6JMmXK4J133oGFhQW8vb2l47/99lts2bIFf//9N0aNGqVTXK6urrC2toatrW2uU4vIhQlLHjhCiIio6ItKiMKj+Edyh5Gnvn37YujQoVi8eDGsra2xbt06fPjhh7CwsEBCQgKmTp2KHTt2IDIyEhkZGUhOTtarhsWcMWHJAxMWIqKiz93B9DUJur5mQEAABEHAjh070LhxYxw+fBhz5swBAIwbNw579uzB7NmzUa1aNdja2qJHjx5IS0szRuiyYcKSBw5pJiIq+rRtmpGTjY0N3n//faxbtw63bt1CzZo10aBBAwDA0aNHMXDgQHTr1g0AkJCQgHv37skYrXEwYckDa1iIiMhc9O3bF++++y7+/fdffPTRR9L+6tWrY/PmzQgICIBCocDkyZNfG1FUFHCUUB5sbIA6dQA3N3EjIiKSS5s2bVCqVClcv34dffr0kfaHhISgZMmSaNasGQICAuDv7y/VvhQlnDiOiIiKheI8cZzcOHEcERERFQtMWIiIiIqJdevWwcHBIcetTp06coeXJ3a6JSIiKibee+89+Pj45PiclZWViaPRDRMWIiKiYsLR0RGOjo5yh6EXNgkRERGR2WPCQkRExUpRnKPE3BninrNJiIiIigWlUgkLCws8fvwYrq6uUCqVUCgUcodVpAmCgLS0NDx9+hQWFhZQKpV6X4sJCxERFQsWFhaoXLkyIiMj8fjxY7nDKVbs7OxQsWJFWFjo37DDhIWIiIoNpVKJihUrIiMjAyqVSu5wigVLS0uUKFGiwLVZTFiIiKhYUSgUsLKyMvthvKSJnW6JiIjI7DFhISIiIrPHhIWIiIjMXpHow5K54HRcXJzMkRAREZG2Mj+3Mz/H81IkEpb4+HgAgKenp8yREBERka7i4+Ph7Oyc5zEKQZu0xsyp1Wo8fvwYjo6OBp8EKC4uDp6ennjw4AGcnJwMem16He+3afF+mxbvt2nxfpuWPvdbEATEx8fDw8Mj3zlaikQNi4WFBSpUqGDU13BycuIvvAnxfpsW77dp8X6bFu+3ael6v/OrWcnETrdERERk9piwEBERkdljwpIPa2trTJkyBdbW1nKHUizwfpsW77dp8X6bFu+3aRn7fheJTrdERERUtLGGhYiIiMweExYiIiIye0xYiIiIyOwxYSEiIiKzx4QlH4sWLYKXlxdsbGzg4+ODU6dOyR1SkXDo0CEEBATAw8MDCoUCW7du1XheEAR88803KFeuHGxtbeHn54ebN2/KE2whFxwcjMaNG8PR0RFly5ZF165dcf36dY1jUlJSMHLkSJQuXRoODg7o3r07oqOjZYq4cFuyZAnq1asnTZ7l6+uLXbt2Sc/zXhvXrFmzoFAoMGbMGGkf77nhTJ06FQqFQmOrVauW9Lwx7zUTljxs3LgRgYGBmDJlCs6dOwdvb2/4+/vjyZMncodW6CUmJsLb2xuLFi3K8fkffvgB8+fPx9KlS3Hy5EnY29vD398fKSkpJo608Dt48CBGjhyJEydOYM+ePUhPT0f79u2RmJgoHfPFF19g27Zt+OOPP3Dw4EE8fvwY77//voxRF14VKlTArFmzcPbsWZw5cwZt2rRBly5d8O+//wLgvTam06dPY9myZahXr57Gft5zw6pTpw4iIyOl7ciRI9JzRr3XAuWqSZMmwsiRI6XHKpVK8PDwEIKDg2WMqugBIGzZskV6rFarBXd3d+HHH3+U9r18+VKwtrYW1q9fL0OERcuTJ08EAMLBgwcFQRDvrZWVlfDHH39Ix1y9elUAIBw/flyuMIuUkiVLCsuXL+e9NqL4+HihevXqwp49e4RWrVoJo0ePFgSBv9+GNmXKFMHb2zvH54x9r1nDkou0tDScPXsWfn5+0j4LCwv4+fnh+PHjMkZW9N29exdRUVEa997Z2Rk+Pj689wYQGxsLAChVqhQA4OzZs0hPT9e437Vq1ULFihV5vwtIpVJhw4YNSExMhK+vL++1EY0cORKdO3fWuLcAf7+N4ebNm/Dw8ECVKlXQt29fREREADD+vS4Six8aw7Nnz6BSqeDm5qax383NDdeuXZMpquIhKioKAHK895nPkX7UajXGjBmD5s2b48033wQg3m+lUgkXFxeNY3m/9Xfp0iX4+voiJSUFDg4O2LJlC2rXro3w8HDeayPYsGEDzp07h9OnT7/2HH+/DcvHxwerVq1CzZo1ERkZiWnTpqFly5a4fPmy0e81ExaiYmTkyJG4fPmyRpszGV7NmjURHh6O2NhY/PnnnxgwYAAOHjwod1hF0oMHDzB69Gjs2bMHNjY2codT5HXs2FEq16tXDz4+PqhUqRJ+//132NraGvW12SSUizJlysDS0vK13s3R0dFwd3eXKariIfP+8t4b1qhRo7B9+3bs378fFSpUkPa7u7sjLS0NL1++1Die91t/SqUS1apVQ8OGDREcHAxvb2/MmzeP99oIzp49iydPnqBBgwYoUaIESpQogYMHD2L+/PkoUaIE3NzceM+NyMXFBTVq1MCtW7eM/vvNhCUXSqUSDRs2RFhYmLRPrVYjLCwMvr6+MkZW9FWuXBnu7u4a9z4uLg4nT57kvdeDIAgYNWoUtmzZgn379qFy5coazzds2BBWVlYa9/v69euIiIjg/TYQtVqN1NRU3msjaNu2LS5duoTw8HBpa9SoEfr27SuVec+NJyEhAbdv30a5cuWM//td4G67RdiGDRsEa2trYdWqVcKVK1eEYcOGCS4uLkJUVJTcoRV68fHxwvnz54Xz588LAISQkBDh/Pnzwv379wVBEIRZs2YJLi4uwl9//SVcvHhR6NKli1C5cmUhOTlZ5sgLnxEjRgjOzs7CgQMHhMjISGlLSkqSjhk+fLhQsWJFYd++fcKZM2cEX19fwdfXV8aoC68JEyYIBw8eFO7evStcvHhRmDBhgqBQKITdu3cLgsB7bQrZRwkJAu+5IY0dO1Y4cOCAcPfuXeHo0aOCn5+fUKZMGeHJkyeCIBj3XjNhyceCBQuEihUrCkqlUmjSpIlw4sQJuUMqEvbv3y8AeG0bMGCAIAji0ObJkycLbm5ugrW1tdC2bVvh+vXr8gZdSOV0nwEIK1eulI5JTk4WPv30U6FkyZKCnZ2d0K1bNyEyMlK+oAuxwYMHC5UqVRKUSqXg6uoqtG3bVkpWBIH32hReTVh4zw2nV69eQrly5QSlUimUL19e6NWrl3Dr1i3peWPea4UgCELB62mIiIiIjId9WIiIiMjsMWEhIiIis8eEhYiIiMweExYiIiIye0xYiIiIyOwxYSEiIiKzx4SFiIiIzB4TFiIiIjJ7TFiIiIjI7DFhISIiIrPHhIWIiIjMHhMWIiIiMnv/ByYm3vY7gGJHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "df = pd.DataFrame({'epochs': range(0,len(train_f)), \n",
    "                  'train_f': train_f, \n",
    "                   'val_f': dev_f})\n",
    " \n",
    "# multiple line plot\n",
    "plt.plot('epochs', 'train_f', data=df, color='blue', linewidth=2)\n",
    "plt.plot('epochs', 'val_f', data=df, color='green', linewidth=2)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMTagger(\n",
       "  (embeddings): Embedding(20002, 300)\n",
       "  (lstm): LSTM(300, 256, bidirectional=True)\n",
       "  (dropout_layer): Dropout(p=0.5, inplace=False)\n",
       "  (hidden2tag): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = torch.load(OUTPUT_PATH)\n",
    "tagger.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-AC       0.67      0.50      0.57       270\n",
      "        I-LF       0.67      0.67      0.67       288\n",
      "        B-LF       0.46      0.51      0.49       150\n",
      "         B-O       0.94      0.96      0.95      4292\n",
      "\n",
      "    accuracy                           0.90      5000\n",
      "   macro avg       0.69      0.66      0.67      5000\n",
      "weighted avg       0.90      0.90      0.90      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = label_field.vocab.itos[2:]\n",
    "labels = sorted(labels, key=lambda x: x.split(\"-\")[-1])\n",
    "label_idxs = [label_field.vocab.stoi[l] for l in labels]\n",
    "\n",
    "test(tagger, test_iter, BATCH_SIZE, labels = label_idxs, target_names = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Back, Style\n",
    "\n",
    "def vizu(words, output, truth):\n",
    "    if isinstance(output, torch.Tensor):\n",
    "        output = output.squeeze().tolist()\n",
    "    col = {0: Back.BLACK, 1: Back.RED, 2: Back.GREEN, 3: Back.BLUE, 4: Back.MAGENTA}\n",
    "    colors1 = [col[i] for i in output]\n",
    "    colors2 = [col[i] for i in truth]\n",
    "    words = [word.replace(\"Ġ\", \"\") for word in words]\n",
    "    print(Style.RESET_ALL + \"Output:\")\n",
    "    for i, word in enumerate(words):\n",
    "        print(colors1[i] + word, end=\" \")\n",
    "    print(Style.RESET_ALL + \"\\nTruth:\")\n",
    "    for i, word in enumerate(words):\n",
    "        print(colors2[i] + word, end=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
