{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antoine EDY\n",
    "# Natural Language Processing (COMM061) - Coursework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import nltk\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"surrey-nlp/PLOD-CW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT2ID: {'B-O': 0, 'B-AC': 1, 'PAD': 2, 'B-LF': 3, 'I-LF': 4}\n",
      "ID2TEXT: {0: 'B-O', 1: 'B-AC', 2: 'PAD', 3: 'B-LF', 4: 'I-LF'}\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1072 entries, 0 to 1071\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tokens     1072 non-null   object\n",
      " 1   labels     1072 non-null   object\n",
      " 2   ids        1072 non-null   object\n",
      " 3   sentences  1072 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 33.6+ KB\n"
     ]
    }
   ],
   "source": [
    "TEXT2ID = {\n",
    "    \"B-O\": 0,\n",
    "    \"B-AC\": 1,\n",
    "    \"PAD\": 2,\n",
    "    \"B-LF\": 3,\n",
    "    \"I-LF\": 4,\n",
    "}\n",
    "ID2TEXT = {v: k for k, v in TEXT2ID.items()}\n",
    "\n",
    "print(f\"TEXT2ID: {TEXT2ID}\\nID2TEXT: {ID2TEXT}\\n\")\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.drop(columns=['pos_tags'])\n",
    "    df = df.rename(columns={\"ner_tags\": \"labels\"})\n",
    "    df[\"ids\"] = df[\"labels\"].apply(lambda x: [TEXT2ID[i] for i in x])\n",
    "    df[\"sentences\"] = df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_dataset = preprocess(pd.DataFrame(dataset['train']))\n",
    "test_dataset = preprocess(pd.DataFrame(dataset['test']))\n",
    "val_dataset = preprocess(pd.DataFrame(dataset['validation']))\n",
    "\n",
    "train_dataset.info()\n",
    "\n",
    "\n",
    "# Here the exploration to add at the end of the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>ids</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[For, this, purpose, the, Gothenburg, Young, P...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>For this purpose the Gothenburg Young Persons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, following, physiological, traits, were, ...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>The following physiological traits were measur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Minor, H, antigen, alloimmune, responses, rea...</td>\n",
       "      <td>[B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...</td>\n",
       "      <td>Minor H antigen alloimmune responses readily o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[EPI, =, Echo, planar, imaging, .]</td>\n",
       "      <td>[B-AC, B-O, B-LF, I-LF, I-LF, B-O]</td>\n",
       "      <td>[1, 0, 3, 4, 4, 0]</td>\n",
       "      <td>EPI = Echo planar imaging .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Furthermore, ,, eNOS, -, derived, NO, S, -, n...</td>\n",
       "      <td>[B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Furthermore , eNOS - derived NO S - nitrosylat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [For, this, purpose, the, Gothenburg, Young, P...   \n",
       "1  [The, following, physiological, traits, were, ...   \n",
       "2  [Minor, H, antigen, alloimmune, responses, rea...   \n",
       "3                 [EPI, =, Echo, planar, imaging, .]   \n",
       "4  [Furthermore, ,, eNOS, -, derived, NO, S, -, n...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...   \n",
       "1  [B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...   \n",
       "2  [B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...   \n",
       "3                 [B-AC, B-O, B-LF, I-LF, I-LF, B-O]   \n",
       "4  [B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...   \n",
       "\n",
       "                                                 ids  \\\n",
       "0      [0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...   \n",
       "3                                 [1, 0, 3, 4, 4, 0]   \n",
       "4  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           sentences  \n",
       "0  For this purpose the Gothenburg Young Persons ...  \n",
       "1  The following physiological traits were measur...  \n",
       "2  Minor H antigen alloimmune responses readily o...  \n",
       "3                        EPI = Echo planar imaging .  \n",
       "4  Furthermore , eNOS - derived NO S - nitrosylat...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072\n",
      "126\n",
      "153\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>ids</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[For, this, purpose, the, Gothenburg, Young, P...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>For this purpose the Gothenburg Young Persons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, following, physiological, traits, were, ...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>The following physiological traits were measur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Minor, H, antigen, alloimmune, responses, rea...</td>\n",
       "      <td>[B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...</td>\n",
       "      <td>Minor H antigen alloimmune responses readily o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[EPI, =, Echo, planar, imaging, .]</td>\n",
       "      <td>[B-AC, B-O, B-LF, I-LF, I-LF, B-O]</td>\n",
       "      <td>[1, 0, 3, 4, 4, 0]</td>\n",
       "      <td>EPI = Echo planar imaging .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Furthermore, ,, eNOS, -, derived, NO, S, -, n...</td>\n",
       "      <td>[B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Furthermore , eNOS - derived NO S - nitrosylat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [For, this, purpose, the, Gothenburg, Young, P...   \n",
       "1  [The, following, physiological, traits, were, ...   \n",
       "2  [Minor, H, antigen, alloimmune, responses, rea...   \n",
       "3                 [EPI, =, Echo, planar, imaging, .]   \n",
       "4  [Furthermore, ,, eNOS, -, derived, NO, S, -, n...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...   \n",
       "1  [B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...   \n",
       "2  [B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...   \n",
       "3                 [B-AC, B-O, B-LF, I-LF, I-LF, B-O]   \n",
       "4  [B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...   \n",
       "\n",
       "                                                 ids  \\\n",
       "0      [0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...   \n",
       "3                                 [1, 0, 3, 4, 4, 0]   \n",
       "4  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           sentences  \n",
       "0  For this purpose the Gothenburg Young Persons ...  \n",
       "1  The following physiological traits were measur...  \n",
       "2  Minor H antigen alloimmune responses readily o...  \n",
       "3                        EPI = Echo planar imaging .  \n",
       "4  Furthermore , eNOS - derived NO S - nitrosylat...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': <torchtext.data.field.Field object at 0x105407370>, 'text': <torchtext.data.field.Field object at 0x30d19bdc0>}\n",
      "['For', 'this', 'purpose', 'the', 'Gothenburg', 'Young', 'Persons', 'Empowerment', 'Scale', '(', 'GYPES', ')', 'was', 'developed', '.']\n",
      "['B-O', 'B-O', 'B-O', 'B-O', 'B-LF', 'I-LF', 'I-LF', 'I-LF', 'I-LF', 'B-O', 'B-AC', 'B-O', 'B-O', 'B-O', 'B-O']\n",
      "Train: 1072\n",
      "Dev: 126\n",
      "Test: 153\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Field, Dataset, Example\n",
    "\n",
    "text_field = Field(sequential=True, tokenize=lambda x:x, include_lengths=True) # Default behaviour is to tokenize by splitting\n",
    "label_field = Field(sequential=True, tokenize=lambda x:x, is_target=True)\n",
    "\n",
    "fields = {\n",
    "    'sentences': ('text', text_field),\n",
    "    'ids': ('label', label_field)\n",
    "}\n",
    "\n",
    "def read_data(df):\n",
    "    examples = []\n",
    "    fields = {'sentence_labels': ('labels', label_field),\n",
    "              'sentence_tokens': ('text', text_field)}\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        tokens = df['tokens'][i]\n",
    "        labels = df['labels'][i]\n",
    "        \n",
    "        e = Example.fromdict({\"sentence_labels\": labels, \"sentence_tokens\": tokens},\n",
    "                             fields=fields)\n",
    "        examples.append(e)\n",
    "    \n",
    "    return Dataset(examples, fields=[('labels', label_field), ('text', text_field)])\n",
    "\n",
    "\n",
    "train_data = read_data(train_dataset)\n",
    "val_data = read_data(val_dataset)\n",
    "test_data = read_data(test_dataset)\n",
    "\n",
    "print(train_data.fields)\n",
    "print(train_data[0].text)\n",
    "print(train_data[0].labels)\n",
    "\n",
    "print(\"Train:\", len(train_data))\n",
    "print(\"Dev:\", len(val_data))\n",
    "print(\"Test:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 20000\n",
    "\n",
    "text_field.build_vocab(train_data, max_size=VOCAB_SIZE)\n",
    "label_field.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import BucketIterator\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_iter = BucketIterator(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                            sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "val_iter = BucketIterator(dataset=val_data, batch_size=BATCH_SIZE, \n",
    "                          sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "test_iter = BucketIterator(dataset=test_data, batch_size=BATCH_SIZE, \n",
    "                           sort_key=lambda x: len(x.text), sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained embeddings\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m             embedding_matrix[idx,:] \u001b[38;5;241m=\u001b[39m embeddings[word]\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embedding_matrix\n\u001b[0;32m---> 35\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mload_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEMBEDDING_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m embedding_matrix \u001b[38;5;241m=\u001b[39m initialize_embeddings(embeddings, text_field\u001b[38;5;241m.\u001b[39mvocab)\n\u001b[1;32m     37\u001b[0m embedding_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(embedding_matrix)\n",
      "Cell \u001b[0;32mIn[18], line 15\u001b[0m, in \u001b[0;36mload_embeddings\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m i:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m: \n\u001b[0;32m---> 15\u001b[0m         line \u001b[38;5;241m=\u001b[39m \u001b[43mline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m         word \u001b[38;5;241m=\u001b[39m line[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m         embedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(line[\u001b[38;5;241m1\u001b[39m:])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "EMBEDDING_PATH = \"/Users/antoineedy/Documents/MScAI/Semester2/NLP/Coursework/code/data/cc.en.300.vec\"\n",
    "\n",
    "def load_embeddings(path):\n",
    "    \"\"\" Load the FastText embeddings from the embedding file. \"\"\"\n",
    "    print(\"Loading pre-trained embeddings\")\n",
    "    \n",
    "    embeddings = {}\n",
    "    with open(path) as i:\n",
    "        for line in i:\n",
    "            if len(line) > 2: \n",
    "                line = line.strip().split()\n",
    "                word = line[0]\n",
    "                embedding = np.array(line[1:])\n",
    "                embeddings[word] = embedding\n",
    "    \n",
    "    return embeddings\n",
    "    \n",
    "\n",
    "def initialize_embeddings(embeddings, vocabulary):\n",
    "    \"\"\" Use the pre-trained embeddings to initialize an embedding matrix. \"\"\"\n",
    "    print(\"Initializing embedding matrix\")\n",
    "    embedding_size = len(embeddings[\".\"])\n",
    "    embedding_matrix = np.zeros((len(vocabulary), embedding_size), dtype=np.float32)\n",
    "                                \n",
    "    for idx, word in enumerate(vocabulary.itos): \n",
    "        if word in embeddings:\n",
    "            embedding_matrix[idx,:] = embeddings[word]\n",
    "            \n",
    "    return embedding_matrix\n",
    "\n",
    "embeddings = load_embeddings(EMBEDDING_PATH)\n",
    "embedding_matrix = initialize_embeddings(embeddings, text_field.vocab)\n",
    "embedding_matrix = torch.from_numpy(embedding_matrix)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class BiLSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, output_size, embeddings=None):\n",
    "        super(BiLSTMTagger, self).__init__()\n",
    "        \n",
    "        # 1. Embedding Layer\n",
    "        if embeddings is None:\n",
    "            self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        else:\n",
    "            self.embeddings = nn.Embedding.from_pretrained(embeddings)\n",
    "        \n",
    "        # 2. LSTM Layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, num_layers=1)\n",
    "        \n",
    "        # 3. Optional dropout layer\n",
    "        self.dropout_layer = nn.Dropout(p=0.5)\n",
    "\n",
    "        # 4. Dense Layer\n",
    "        self.hidden2tag = nn.Linear(2*hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, batch_text, batch_lengths):\n",
    "\n",
    "        embeddings = self.embeddings(batch_text)\n",
    "        \n",
    "        packed_seqs = pack_padded_sequence(embeddings, batch_lengths)\n",
    "        lstm_output, _ = self.lstm(packed_seqs)\n",
    "        lstm_output, _ = pad_packed_sequence(lstm_output)\n",
    "        lstm_output = self.dropout_layer(lstm_output)\n",
    "        \n",
    "        logits = self.hidden2tag(lstm_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 6: ['<unk>', '<pad>', 'B-O', 'I-LF', 'B-AC', 'B-LF']\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "def remove_predictions_for_masked_items(predicted_labels, correct_labels): \n",
    "\n",
    "    predicted_labels_without_mask = []\n",
    "    correct_labels_without_mask = []\n",
    "        \n",
    "    for p, c in zip(predicted_labels, correct_labels):\n",
    "        if c > 1:\n",
    "            predicted_labels_without_mask.append(p)\n",
    "            correct_labels_without_mask.append(c)\n",
    "            \n",
    "    return predicted_labels_without_mask, correct_labels_without_mask\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "NUM_CLASSES = len(label_field.vocab)\n",
    "print(f\"Number of classes: {NUM_CLASSES}: {label_field.vocab.itos}\")\n",
    "\n",
    "def train(model, train_iter, dev_iter, batch_size, max_epochs, num_batches, patience, output_path):\n",
    "    writer = SummaryWriter()\n",
    "    # add weight to indexes 3, 4, 5\n",
    "    class_weights = torch.tensor([0.1, 0.1, 0.1, 10, 10, 10]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight = class_weights, ignore_index=1)  # we mask the <pad> labels\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    train_f_score_history = []\n",
    "    dev_f_score_history = []\n",
    "    no_improvement = 0\n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        total_loss = 0\n",
    "        predictions, correct = [], []\n",
    "        for batch in tqdm(train_iter, total=num_batches, desc=f\"Epoch {epoch}\"):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            text_length, cur_batch_size = batch.text[0].shape\n",
    "            \n",
    "            pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size*text_length, NUM_CLASSES)\n",
    "            gold = batch.labels.to(device).view(cur_batch_size*text_length)\n",
    "            \n",
    "            loss = criterion(pred, gold)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, pred_indices = torch.max(pred, 1)\n",
    "            \n",
    "            predicted_labels = list(pred_indices.cpu().numpy())\n",
    "            correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "            \n",
    "            predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, \n",
    "                                                                                   correct_labels)\n",
    "            \n",
    "            predictions += predicted_labels\n",
    "            correct += correct_labels\n",
    "\n",
    "        train_scores = precision_recall_fscore_support(correct, predictions, average=\"micro\")\n",
    "        train_f_score_history.append(train_scores[2])\n",
    "            \n",
    "        print(\"Total training loss:\", total_loss)\n",
    "        print(\"Training performance:\", train_scores)\n",
    "\n",
    "        #tensorboard\n",
    "        writer.add_scalar('train/loss', total_loss, epoch)\n",
    "        writer.add_scalar('train/precision', train_scores[2], epoch)\n",
    "        \n",
    "        total_loss = 0\n",
    "        predictions, correct = [], []\n",
    "        for batch in dev_iter:\n",
    "\n",
    "            text_length, cur_batch_size = batch.text[0].shape\n",
    "\n",
    "            pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size * text_length, NUM_CLASSES)\n",
    "            gold = batch.labels.to(device).view(cur_batch_size * text_length)\n",
    "            loss = criterion(pred, gold)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, pred_indices = torch.max(pred, 1)\n",
    "            predicted_labels = list(pred_indices.cpu().numpy())\n",
    "            correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "            \n",
    "            predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, \n",
    "                                                                                   correct_labels)\n",
    "            \n",
    "            predictions += predicted_labels\n",
    "            correct += correct_labels\n",
    "\n",
    "        dev_scores = precision_recall_fscore_support(correct, predictions, average=\"micro\")\n",
    "            \n",
    "        print(\"Total development loss:\", total_loss)\n",
    "        print(\"Development performance:\", dev_scores)\n",
    "\n",
    "        writer.add_scalar('val/loss', total_loss, epoch)\n",
    "        writer.add_scalar('val/precision', dev_scores[2], epoch)\n",
    "        \n",
    "        dev_f = dev_scores[2]\n",
    "        if len(dev_f_score_history) > patience and dev_f < max(dev_f_score_history):\n",
    "            no_improvement += 1\n",
    "\n",
    "        elif len(dev_f_score_history) == 0 or dev_f > max(dev_f_score_history):\n",
    "            print(\"Saving model.\")\n",
    "            torch.save(model, output_path)\n",
    "            no_improvement = 0\n",
    "            \n",
    "        if no_improvement > patience:\n",
    "            print(\"Development F-score does not improve anymore. Stop training.\")\n",
    "            dev_f_score_history.append(dev_f)\n",
    "            break\n",
    "            \n",
    "        dev_f_score_history.append(dev_f)\n",
    "        \n",
    "    return train_f_score_history, dev_f_score_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_iter, batch_size, labels, target_names): \n",
    "    \n",
    "    total_loss = 0\n",
    "    predictions, correct = [], []\n",
    "    for batch in test_iter:\n",
    "\n",
    "        text_length, cur_batch_size = batch.text[0].shape\n",
    "\n",
    "        pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size * text_length, NUM_CLASSES)\n",
    "        gold = batch.labels.to(device).view(cur_batch_size * text_length)\n",
    "\n",
    "        _, pred_indices = torch.max(pred, 1)\n",
    "        predicted_labels = list(pred_indices.cpu().numpy())\n",
    "        correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "\n",
    "        predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, correct_labels)\n",
    "\n",
    "        predictions += predicted_labels\n",
    "        correct += correct_labels\n",
    "    \n",
    "    print(classification_report(correct, predictions, labels=labels, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 6 : ['<unk>', '<pad>', 'B-O', 'I-LF', 'B-AC', 'B-LF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 34/34 [00:04<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 37.89864158630371\n",
      "Training performance: (0.111475, 0.111475, 0.111475, None)\n",
      "Total development loss: 3.3198620080947876\n",
      "Development performance: (0.105, 0.105, 0.105, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 34/34 [00:04<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 19.424923837184906\n",
      "Training performance: (0.152025, 0.152025, 0.152025, None)\n",
      "Total development loss: 2.4111848771572113\n",
      "Development performance: (0.1552, 0.1552, 0.1552, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 34/34 [00:04<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 14.37157741189003\n",
      "Training performance: (0.25965, 0.25965, 0.25965, None)\n",
      "Total development loss: 2.0647644698619843\n",
      "Development performance: (0.2302, 0.2302, 0.2302, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 34/34 [00:04<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 11.638599812984467\n",
      "Training performance: (0.39085, 0.39085, 0.39085, None)\n",
      "Total development loss: 1.945059597492218\n",
      "Development performance: (0.4954, 0.4954, 0.4954, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 34/34 [00:04<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 10.671359077095985\n",
      "Training performance: (0.50455, 0.50455, 0.50455, None)\n",
      "Total development loss: 2.0363087356090546\n",
      "Development performance: (0.4628, 0.4628, 0.4628, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 34/34 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 9.441414892673492\n",
      "Training performance: (0.54015, 0.54015, 0.54015, None)\n",
      "Total development loss: 1.7924821376800537\n",
      "Development performance: (0.5994, 0.5994, 0.5994, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 34/34 [00:04<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 8.50402445346117\n",
      "Training performance: (0.5814, 0.5814, 0.5814, None)\n",
      "Total development loss: 1.7166893184185028\n",
      "Development performance: (0.5786, 0.5786, 0.5786, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 34/34 [00:04<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 7.718092530965805\n",
      "Training performance: (0.625725, 0.625725, 0.625725, None)\n",
      "Total development loss: 1.7581197917461395\n",
      "Development performance: (0.5928, 0.5928, 0.5928, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 34/34 [00:04<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 7.42845556885004\n",
      "Training performance: (0.62795, 0.62795, 0.62795, None)\n",
      "Total development loss: 1.7872651517391205\n",
      "Development performance: (0.521, 0.521, 0.521, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 34/34 [00:04<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 6.934548959136009\n",
      "Training performance: (0.634, 0.634, 0.634, None)\n",
      "Total development loss: 1.5733880400657654\n",
      "Development performance: (0.6148, 0.6148, 0.6148, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 34/34 [00:04<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 6.196093998849392\n",
      "Training performance: (0.676625, 0.676625, 0.676625, None)\n",
      "Total development loss: 1.6690851151943207\n",
      "Development performance: (0.6188, 0.6188, 0.6188, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 34/34 [00:04<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 5.596218533813953\n",
      "Training performance: (0.678275, 0.678275, 0.678275, None)\n",
      "Total development loss: 1.7377298176288605\n",
      "Development performance: (0.6916, 0.6916, 0.6916, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 34/34 [00:04<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 5.184142615646124\n",
      "Training performance: (0.700325, 0.700325, 0.700325, None)\n",
      "Total development loss: 1.682310312986374\n",
      "Development performance: (0.6256, 0.6256, 0.6256, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 34/34 [00:04<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 4.7446021772921085\n",
      "Training performance: (0.71555, 0.71555, 0.71555, None)\n",
      "Total development loss: 1.9013200998306274\n",
      "Development performance: (0.6472, 0.6472, 0.6472, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 34/34 [00:04<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 4.458271216601133\n",
      "Training performance: (0.72575, 0.72575, 0.72575, None)\n",
      "Total development loss: 1.6703733503818512\n",
      "Development performance: (0.7208, 0.7208, 0.7208, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 34/34 [00:04<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.74505128711462\n",
      "Training performance: (0.751825, 0.751825, 0.751825, None)\n",
      "Total development loss: 1.8000884354114532\n",
      "Development performance: (0.7494, 0.7494, 0.7494, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 34/34 [00:04<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.401693642139435\n",
      "Training performance: (0.757475, 0.757475, 0.757475, None)\n",
      "Total development loss: 1.8476988971233368\n",
      "Development performance: (0.71, 0.71, 0.71, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 34/34 [00:04<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.27924445271492\n",
      "Training performance: (0.7678, 0.7678, 0.7678, None)\n",
      "Total development loss: 1.8075959086418152\n",
      "Development performance: (0.7216, 0.7216, 0.7216, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 34/34 [00:04<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.377419300377369\n",
      "Training performance: (0.757325, 0.757325, 0.757325, None)\n",
      "Total development loss: 1.8388145565986633\n",
      "Development performance: (0.7728, 0.7728, 0.7728, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 34/34 [00:04<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.6931056454777718\n",
      "Training performance: (0.79125, 0.79125, 0.79125, None)\n",
      "Total development loss: 1.952783316373825\n",
      "Development performance: (0.781, 0.781, 0.781, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 34/34 [00:04<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.452858544886112\n",
      "Training performance: (0.807775, 0.807775, 0.807775, None)\n",
      "Total development loss: 1.8900398313999176\n",
      "Development performance: (0.732, 0.732, 0.732, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 34/34 [00:04<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.1488195471465588\n",
      "Training performance: (0.80935, 0.80935, 0.80935, None)\n",
      "Total development loss: 1.981124758720398\n",
      "Development performance: (0.7496, 0.7496, 0.7496, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 34/34 [00:04<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.974088802933693\n",
      "Training performance: (0.818675, 0.818675, 0.818675, None)\n",
      "Total development loss: 1.9600939750671387\n",
      "Development performance: (0.787, 0.787, 0.787, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 34/34 [00:04<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.9963283501565456\n",
      "Training performance: (0.822275, 0.822275, 0.822275, None)\n",
      "Total development loss: 1.9161732196807861\n",
      "Development performance: (0.7648, 0.7648, 0.7648, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 34/34 [00:04<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.8181090224534273\n",
      "Training performance: (0.82995, 0.82995, 0.82995, None)\n",
      "Total development loss: 2.0384330451488495\n",
      "Development performance: (0.772, 0.772, 0.772, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 34/34 [00:04<00:00,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.7119745146483183\n",
      "Training performance: (0.846175, 0.846175, 0.846175, None)\n",
      "Total development loss: 1.883811891078949\n",
      "Development performance: (0.7498, 0.7498, 0.7498, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 34/34 [00:04<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.642645312473178\n",
      "Training performance: (0.843325, 0.843325, 0.843325, None)\n",
      "Total development loss: 2.270417422056198\n",
      "Development performance: (0.7848, 0.7848, 0.7848, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 34/34 [00:04<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.4392091780900955\n",
      "Training performance: (0.8567, 0.8567, 0.8567, None)\n",
      "Total development loss: 2.0147793292999268\n",
      "Development performance: (0.8064, 0.8064, 0.8064, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 34/34 [00:04<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.410303944721818\n",
      "Training performance: (0.8571, 0.8571, 0.8571, None)\n",
      "Total development loss: 2.0133930146694183\n",
      "Development performance: (0.8168, 0.8168, 0.8168, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 34/34 [00:04<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.2819326110184193\n",
      "Training performance: (0.868625, 0.868625, 0.868625, None)\n",
      "Total development loss: 2.569935828447342\n",
      "Development performance: (0.863, 0.863, 0.863, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 34/34 [00:04<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.203815296292305\n",
      "Training performance: (0.882, 0.882, 0.882, None)\n",
      "Total development loss: 2.55602890253067\n",
      "Development performance: (0.8622, 0.8622, 0.8622, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 34/34 [00:04<00:00,  7.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.107925383374095\n",
      "Training performance: (0.884775, 0.884775, 0.884775, None)\n",
      "Total development loss: 2.704352021217346\n",
      "Development performance: (0.8534, 0.8534, 0.8534, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 34/34 [00:04<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.1193226389586926\n",
      "Training performance: (0.884625, 0.884625, 0.884625, None)\n",
      "Total development loss: 2.587106615304947\n",
      "Development performance: (0.8196, 0.8196, 0.8196, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 34/34 [00:04<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.0977586479857564\n",
      "Training performance: (0.893025, 0.893025, 0.893025, None)\n",
      "Total development loss: 2.6838788390159607\n",
      "Development performance: (0.8396, 0.8396, 0.8396, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 34/34 [00:04<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.9899188512936234\n",
      "Training performance: (0.898025, 0.898025, 0.898025, None)\n",
      "Total development loss: 2.799472063779831\n",
      "Development performance: (0.8374, 0.8374, 0.8374, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 34/34 [00:04<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.9858812671154737\n",
      "Training performance: (0.897975, 0.897975, 0.897975, None)\n",
      "Total development loss: 2.95394030213356\n",
      "Development performance: (0.8654, 0.8654, 0.8654, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 34/34 [00:05<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.1096350774168968\n",
      "Training performance: (0.89255, 0.89255, 0.89255, None)\n",
      "Total development loss: 2.8154089748859406\n",
      "Development performance: (0.8702, 0.8702, 0.8702, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 34/34 [00:05<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.223453463986516\n",
      "Training performance: (0.884775, 0.884775, 0.884775, None)\n",
      "Total development loss: 2.5448668003082275\n",
      "Development performance: (0.8104, 0.8104, 0.8104, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 34/34 [00:05<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.1645307894796133\n",
      "Training performance: (0.887825, 0.887825, 0.887825, None)\n",
      "Total development loss: 2.418997824192047\n",
      "Development performance: (0.8472, 0.8472, 0.8472, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 34/34 [00:05<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.055691208690405\n",
      "Training performance: (0.895025, 0.895025, 0.895025, None)\n",
      "Total development loss: 2.8220819532871246\n",
      "Development performance: (0.8638, 0.8638, 0.8638, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 34/34 [00:04<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.930551397614181\n",
      "Training performance: (0.9081, 0.9081, 0.9081, None)\n",
      "Total development loss: 2.8343432545661926\n",
      "Development performance: (0.865, 0.865, 0.865, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 34/34 [00:04<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.7979092448949814\n",
      "Training performance: (0.917475, 0.917475, 0.917475, None)\n",
      "Total development loss: 2.9075569212436676\n",
      "Development performance: (0.867, 0.867, 0.867, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 34/34 [00:04<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.7223014123737812\n",
      "Training performance: (0.92365, 0.92365, 0.92365, None)\n",
      "Total development loss: 3.0502824187278748\n",
      "Development performance: (0.8668, 0.8668, 0.8668, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 34/34 [00:04<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.7599328458309174\n",
      "Training performance: (0.92025, 0.92025, 0.92025, None)\n",
      "Total development loss: 3.0756571292877197\n",
      "Development performance: (0.8642, 0.8642, 0.8642, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 34/34 [00:04<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.7021239884197712\n",
      "Training performance: (0.927, 0.927, 0.927, None)\n",
      "Total development loss: 3.234999716281891\n",
      "Development performance: (0.8774, 0.8774, 0.8774, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 34/34 [00:04<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.8648550165817142\n",
      "Training performance: (0.912375, 0.912375, 0.912375, None)\n",
      "Total development loss: 2.837198555469513\n",
      "Development performance: (0.8332, 0.8332, 0.8332, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 34/34 [00:04<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.0179530773311853\n",
      "Training performance: (0.89775, 0.89775, 0.89775, None)\n",
      "Total development loss: 2.500457674264908\n",
      "Development performance: (0.856, 0.856, 0.856, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 34/34 [00:05<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.753060407936573\n",
      "Training performance: (0.919075, 0.919075, 0.919075, None)\n",
      "Total development loss: 2.894624024629593\n",
      "Development performance: (0.8668, 0.8668, 0.8668, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 34/34 [00:04<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.6088777193799615\n",
      "Training performance: (0.933025, 0.933025, 0.933025, None)\n",
      "Total development loss: 3.7654323279857635\n",
      "Development performance: (0.8914, 0.8914, 0.8914, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 34/34 [00:04<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.5436634514480829\n",
      "Training performance: (0.941075, 0.941075, 0.941075, None)\n",
      "Total development loss: 3.857880711555481\n",
      "Development performance: (0.8952, 0.8952, 0.8952, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = len(label_field.vocab)\n",
    "print(f\"Number of classes: {NUM_CLASSES} : {label_field.vocab.itos}\")\n",
    "MAX_EPOCHS = 50\n",
    "PATIENCE = 50\n",
    "OUTPUT_PATH = \"model_saves/bilstmtagger\"\n",
    "num_batches = math.ceil(len(train_data) / BATCH_SIZE)\n",
    "\n",
    "tagger = BiLSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE+2, NUM_CLASSES, embeddings=embedding_matrix)  # embeddings\n",
    "# tagger = BiLSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE+2, NUM_CLASSES)  # no embeddings\n",
    "\n",
    "train_f, dev_f = train(tagger.to(device), train_iter, val_iter, BATCH_SIZE, MAX_EPOCHS, \n",
    "                       num_batches, PATIENCE, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "df = pd.DataFrame({'epochs': range(0,len(train_f)), \n",
    "                  'train_f': train_f, \n",
    "                   'val_f': dev_f})\n",
    " \n",
    "# multiple line plot\n",
    "plt.plot('epochs', 'train_f', data=df, color='blue', linewidth=2)\n",
    "plt.plot('epochs', 'val_f', data=df, color='green', linewidth=2)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = \"model_saves/bilstmtagger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMTagger(\n",
       "  (embeddings): Embedding(9135, 300)\n",
       "  (lstm): LSTM(300, 256, bidirectional=True)\n",
       "  (dropout_layer): Dropout(p=0.5, inplace=False)\n",
       "  (hidden2tag): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = torch.load(OUTPUT_PATH)\n",
    "tagger.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-AC       0.49      0.73      0.58       270\n",
      "        I-LF       0.58      0.80      0.67       288\n",
      "        B-LF       0.50      0.63      0.56       150\n",
      "         B-O       0.97      0.90      0.94      4292\n",
      "\n",
      "    accuracy                           0.88      5000\n",
      "   macro avg       0.63      0.77      0.69      5000\n",
      "weighted avg       0.91      0.88      0.89      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = label_field.vocab.itos[2:]\n",
    "labels = sorted(labels, key=lambda x: x.split(\"-\")[-1])\n",
    "label_idxs = [label_field.vocab.stoi[l] for l in labels]\n",
    "\n",
    "test(tagger, test_iter, BATCH_SIZE, labels = label_idxs, target_names = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Back, Style\n",
    "\n",
    "def vizu(words, output, truth):\n",
    "    if isinstance(output, torch.Tensor):\n",
    "        output = output.squeeze().tolist()\n",
    "    col = {0: Back.GREEN, 1: Back.RED, 2: Back.BLACK, 3: Back.BLUE, 4: Back.MAGENTA}\n",
    "    colors1 = [col[i] for i in output]\n",
    "    colors2 = [col[i] for i in truth]\n",
    "    words = [word.replace(\"Ġ\", \"\") for word in words]\n",
    "    print(Style.RESET_ALL + \"Output:\")\n",
    "    for i, word in enumerate(words):\n",
    "        print(colors1[i] + word, end=\" \")\n",
    "    print(Style.RESET_ALL + \"\\nTruth:\")\n",
    "    for i, word in enumerate(words):\n",
    "        print(colors2[i] + word, end=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
