{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antoine EDY\n",
    "# Natural Language Processing (COMM061) - Coursework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import nltk\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"surrey-nlp/PLOD-CW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT2ID: {'B-O': 0, 'B-AC': 1, 'PAD': 2, 'B-LF': 3, 'I-LF': 4}\n",
      "ID2TEXT: {0: 'B-O', 1: 'B-AC', 2: 'PAD', 3: 'B-LF', 4: 'I-LF'}\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1072 entries, 0 to 1071\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tokens     1072 non-null   object\n",
      " 1   labels     1072 non-null   object\n",
      " 2   ids        1072 non-null   object\n",
      " 3   sentences  1072 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 33.6+ KB\n"
     ]
    }
   ],
   "source": [
    "TEXT2ID = {\n",
    "    \"B-O\": 0,\n",
    "    \"B-AC\": 1,\n",
    "    \"PAD\": 2,\n",
    "    \"B-LF\": 3,\n",
    "    \"I-LF\": 4,\n",
    "}\n",
    "ID2TEXT = {v: k for k, v in TEXT2ID.items()}\n",
    "\n",
    "print(f\"TEXT2ID: {TEXT2ID}\\nID2TEXT: {ID2TEXT}\\n\")\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.drop(columns=['pos_tags'])\n",
    "    df = df.rename(columns={\"ner_tags\": \"labels\"})\n",
    "    df[\"ids\"] = df[\"labels\"].apply(lambda x: [TEXT2ID[i] for i in x])\n",
    "    df[\"sentences\"] = df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_dataset = preprocess(pd.DataFrame(dataset['train']))\n",
    "test_dataset = preprocess(pd.DataFrame(dataset['test']))\n",
    "val_dataset = preprocess(pd.DataFrame(dataset['validation']))\n",
    "\n",
    "train_dataset.info()\n",
    "\n",
    "\n",
    "# Here the exploration to add at the end of the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>ids</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[For, this, purpose, the, Gothenburg, Young, P...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>For this purpose the Gothenburg Young Persons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, following, physiological, traits, were, ...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>The following physiological traits were measur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Minor, H, antigen, alloimmune, responses, rea...</td>\n",
       "      <td>[B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...</td>\n",
       "      <td>Minor H antigen alloimmune responses readily o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[EPI, =, Echo, planar, imaging, .]</td>\n",
       "      <td>[B-AC, B-O, B-LF, I-LF, I-LF, B-O]</td>\n",
       "      <td>[1, 0, 3, 4, 4, 0]</td>\n",
       "      <td>EPI = Echo planar imaging .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Furthermore, ,, eNOS, -, derived, NO, S, -, n...</td>\n",
       "      <td>[B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Furthermore , eNOS - derived NO S - nitrosylat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [For, this, purpose, the, Gothenburg, Young, P...   \n",
       "1  [The, following, physiological, traits, were, ...   \n",
       "2  [Minor, H, antigen, alloimmune, responses, rea...   \n",
       "3                 [EPI, =, Echo, planar, imaging, .]   \n",
       "4  [Furthermore, ,, eNOS, -, derived, NO, S, -, n...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...   \n",
       "1  [B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...   \n",
       "2  [B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...   \n",
       "3                 [B-AC, B-O, B-LF, I-LF, I-LF, B-O]   \n",
       "4  [B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...   \n",
       "\n",
       "                                                 ids  \\\n",
       "0      [0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...   \n",
       "3                                 [1, 0, 3, 4, 4, 0]   \n",
       "4  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           sentences  \n",
       "0  For this purpose the Gothenburg Young Persons ...  \n",
       "1  The following physiological traits were measur...  \n",
       "2  Minor H antigen alloimmune responses readily o...  \n",
       "3                        EPI = Echo planar imaging .  \n",
       "4  Furthermore , eNOS - derived NO S - nitrosylat...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072\n",
      "126\n",
      "153\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>ids</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[For, this, purpose, the, Gothenburg, Young, P...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>For this purpose the Gothenburg Young Persons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, following, physiological, traits, were, ...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>The following physiological traits were measur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Minor, H, antigen, alloimmune, responses, rea...</td>\n",
       "      <td>[B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...</td>\n",
       "      <td>Minor H antigen alloimmune responses readily o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[EPI, =, Echo, planar, imaging, .]</td>\n",
       "      <td>[B-AC, B-O, B-LF, I-LF, I-LF, B-O]</td>\n",
       "      <td>[1, 0, 3, 4, 4, 0]</td>\n",
       "      <td>EPI = Echo planar imaging .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Furthermore, ,, eNOS, -, derived, NO, S, -, n...</td>\n",
       "      <td>[B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Furthermore , eNOS - derived NO S - nitrosylat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [For, this, purpose, the, Gothenburg, Young, P...   \n",
       "1  [The, following, physiological, traits, were, ...   \n",
       "2  [Minor, H, antigen, alloimmune, responses, rea...   \n",
       "3                 [EPI, =, Echo, planar, imaging, .]   \n",
       "4  [Furthermore, ,, eNOS, -, derived, NO, S, -, n...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...   \n",
       "1  [B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...   \n",
       "2  [B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...   \n",
       "3                 [B-AC, B-O, B-LF, I-LF, I-LF, B-O]   \n",
       "4  [B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...   \n",
       "\n",
       "                                                 ids  \\\n",
       "0      [0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...   \n",
       "3                                 [1, 0, 3, 4, 4, 0]   \n",
       "4  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           sentences  \n",
       "0  For this purpose the Gothenburg Young Persons ...  \n",
       "1  The following physiological traits were measur...  \n",
       "2  Minor H antigen alloimmune responses readily o...  \n",
       "3                        EPI = Echo planar imaging .  \n",
       "4  Furthermore , eNOS - derived NO S - nitrosylat...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': <torchtext.data.field.Field object at 0x1079d3400>, 'text': <torchtext.data.field.Field object at 0x16c8f28f0>}\n",
      "['For', 'this', 'purpose', 'the', 'Gothenburg', 'Young', 'Persons', 'Empowerment', 'Scale', '(', 'GYPES', ')', 'was', 'developed', '.']\n",
      "['B-O', 'B-O', 'B-O', 'B-O', 'B-LF', 'I-LF', 'I-LF', 'I-LF', 'I-LF', 'B-O', 'B-AC', 'B-O', 'B-O', 'B-O', 'B-O']\n",
      "Train: 1072\n",
      "Dev: 126\n",
      "Test: 153\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Field, Dataset, Example\n",
    "\n",
    "text_field = Field(sequential=True, tokenize=lambda x:x, include_lengths=True) # Default behaviour is to tokenize by splitting\n",
    "label_field = Field(sequential=True, tokenize=lambda x:x, is_target=True)\n",
    "\n",
    "fields = {\n",
    "    'sentences': ('text', text_field),\n",
    "    'ids': ('label', label_field)\n",
    "}\n",
    "\n",
    "def read_data(df):\n",
    "    examples = []\n",
    "    fields = {'sentence_labels': ('labels', label_field),\n",
    "              'sentence_tokens': ('text', text_field)}\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        tokens = df['tokens'][i]\n",
    "        labels = df['labels'][i]\n",
    "        \n",
    "        e = Example.fromdict({\"sentence_labels\": labels, \"sentence_tokens\": tokens},\n",
    "                             fields=fields)\n",
    "        examples.append(e)\n",
    "    \n",
    "    return Dataset(examples, fields=[('labels', label_field), ('text', text_field)])\n",
    "\n",
    "\n",
    "train_data = read_data(train_dataset)\n",
    "val_data = read_data(val_dataset)\n",
    "test_data = read_data(test_dataset)\n",
    "\n",
    "print(train_data.fields)\n",
    "print(train_data[0].text)\n",
    "print(train_data[0].labels)\n",
    "\n",
    "print(\"Train:\", len(train_data))\n",
    "print(\"Dev:\", len(val_data))\n",
    "print(\"Test:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 20000\n",
    "\n",
    "text_field.build_vocab(train_data, max_size=VOCAB_SIZE)\n",
    "label_field.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import BucketIterator\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_iter = BucketIterator(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                            sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "val_iter = BucketIterator(dataset=val_data, batch_size=BATCH_SIZE, \n",
    "                          sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "test_iter = BucketIterator(dataset=test_data, batch_size=BATCH_SIZE, \n",
    "                           sort_key=lambda x: len(x.text), sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9135, 300])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "emb = 'word2vec'\n",
    "\n",
    "if emb == 'fasttext':\n",
    "\n",
    "    EMBEDDING_PATH = \"/Users/antoineedy/Documents/MScAI/Semester2/NLP/Coursework/code/data/cc.en.300.vec\"\n",
    "\n",
    "    def load_embeddings(path):\n",
    "        \"\"\" Load the FastText embeddings from the embedding file. \"\"\"\n",
    "        print(\"Loading pre-trained embeddings\")\n",
    "        \n",
    "        embeddings = {}\n",
    "        with open(path) as i:\n",
    "            for line in i:\n",
    "                if len(line) > 2: \n",
    "                    line = line.strip().split()\n",
    "                    word = line[0]\n",
    "                    embedding = np.array(line[1:])\n",
    "                    embeddings[word] = embedding\n",
    "        \n",
    "        return embeddings\n",
    "        \n",
    "\n",
    "    def initialize_embeddings(embeddings, vocabulary):\n",
    "        \"\"\" Use the pre-trained embeddings to initialize an embedding matrix. \"\"\"\n",
    "        print(\"Initializing embedding matrix\")\n",
    "        embedding_size = len(embeddings[\".\"])\n",
    "        embedding_matrix = np.zeros((len(vocabulary), embedding_size), dtype=np.float32)\n",
    "                                    \n",
    "        for idx, word in enumerate(vocabulary.itos): \n",
    "            if word in embeddings:\n",
    "                embedding_matrix[idx,:] = embeddings[word]\n",
    "                \n",
    "        return embedding_matrix\n",
    "\n",
    "    embeddings = load_embeddings(EMBEDDING_PATH)\n",
    "    embedding_matrix = initialize_embeddings(embeddings, text_field.vocab)\n",
    "    embedding_matrix = torch.from_numpy(embedding_matrix)\n",
    "    print(embedding_matrix.shape)\n",
    "\n",
    "if emb == 'word2vec':\n",
    "    import gensim\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "    em = []\n",
    "    for word in text_field.vocab.itos:\n",
    "        if word in model:\n",
    "            em.append(model.get_vector(word))\n",
    "        else:\n",
    "            em.append(np.zeros(300))\n",
    "    em = np.array(em)\n",
    "    embedding_matrix = torch.tensor(em, dtype=torch.float32)\n",
    "    print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class BiLSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, output_size, embeddings=None):\n",
    "        super(BiLSTMTagger, self).__init__()\n",
    "        \n",
    "        # 1. Embedding Layer\n",
    "        if embeddings is None:\n",
    "            self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        else:\n",
    "            self.embeddings = nn.Embedding.from_pretrained(embeddings)\n",
    "        \n",
    "        # 2. LSTM Layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, num_layers=1)\n",
    "        \n",
    "        # 3. Optional dropout layer\n",
    "        self.dropout_layer = nn.Dropout(p=0.5)\n",
    "\n",
    "        # 4. Dense Layer\n",
    "        self.hidden2tag = nn.Linear(2*hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, batch_text, batch_lengths):\n",
    "\n",
    "        embeddings = self.embeddings(batch_text)\n",
    "        \n",
    "        packed_seqs = pack_padded_sequence(embeddings, batch_lengths)\n",
    "        lstm_output, _ = self.lstm(packed_seqs)\n",
    "        lstm_output, _ = pad_packed_sequence(lstm_output)\n",
    "        lstm_output = self.dropout_layer(lstm_output)\n",
    "        \n",
    "        logits = self.hidden2tag(lstm_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 6: ['<unk>', '<pad>', 'B-O', 'I-LF', 'B-AC', 'B-LF']\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "def remove_predictions_for_masked_items(predicted_labels, correct_labels): \n",
    "\n",
    "    predicted_labels_without_mask = []\n",
    "    correct_labels_without_mask = []\n",
    "        \n",
    "    for p, c in zip(predicted_labels, correct_labels):\n",
    "        if c > 1:\n",
    "            predicted_labels_without_mask.append(p)\n",
    "            correct_labels_without_mask.append(c)\n",
    "            \n",
    "    return predicted_labels_without_mask, correct_labels_without_mask\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "NUM_CLASSES = len(label_field.vocab)\n",
    "print(f\"Number of classes: {NUM_CLASSES}: {label_field.vocab.itos}\")\n",
    "\n",
    "def train(model, train_iter, dev_iter, batch_size, max_epochs, num_batches, patience, output_path):\n",
    "    writer = SummaryWriter()\n",
    "    # add weight to indexes 3, 4, 5\n",
    "    w = [0, 0, 0.0443, 0.6259, 1.0000, 0.4525]\n",
    "    class_weights = torch.tensor(w).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight = class_weights, ignore_index=1)  # we mask the <pad> labels\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    train_f_score_history = []\n",
    "    dev_f_score_history = []\n",
    "    no_improvement = 0\n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        total_loss = 0\n",
    "        predictions, correct = [], []\n",
    "        for batch in tqdm(train_iter, total=num_batches, desc=f\"Epoch {epoch}\"):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            text_length, cur_batch_size = batch.text[0].shape\n",
    "            \n",
    "            pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size*text_length, NUM_CLASSES)\n",
    "            gold = batch.labels.to(device).view(cur_batch_size*text_length)\n",
    "            \n",
    "            loss = criterion(pred, gold)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, pred_indices = torch.max(pred, 1)\n",
    "            \n",
    "            predicted_labels = list(pred_indices.cpu().numpy())\n",
    "            correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "            \n",
    "            predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, \n",
    "                                                                                   correct_labels)\n",
    "            \n",
    "            predictions += predicted_labels\n",
    "            correct += correct_labels\n",
    "\n",
    "        train_scores = precision_recall_fscore_support(correct, predictions, average=\"micro\")\n",
    "        train_f_score_history.append(train_scores[2])\n",
    "            \n",
    "        print(\"Total training loss:\", total_loss)\n",
    "        print(\"Training performance:\", train_scores)\n",
    "\n",
    "        #tensorboard\n",
    "        writer.add_scalar('train/loss', total_loss, epoch)\n",
    "        writer.add_scalar('train/precision', train_scores[2], epoch)\n",
    "\n",
    "        \n",
    "        total_loss = 0\n",
    "        predictions, correct = [], []\n",
    "        for batch in dev_iter:\n",
    "\n",
    "            text_length, cur_batch_size = batch.text[0].shape\n",
    "\n",
    "            pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size * text_length, NUM_CLASSES)\n",
    "            gold = batch.labels.to(device).view(cur_batch_size * text_length)\n",
    "            loss = criterion(pred, gold)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, pred_indices = torch.max(pred, 1)\n",
    "            predicted_labels = list(pred_indices.cpu().numpy())\n",
    "            correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "            \n",
    "            predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, \n",
    "                                                                                   correct_labels)\n",
    "            \n",
    "            predictions += predicted_labels\n",
    "            correct += correct_labels\n",
    "\n",
    "        dev_scores = precision_recall_fscore_support(correct, predictions, average=\"micro\")\n",
    "            \n",
    "        print(\"Total development loss:\", total_loss)\n",
    "        print(\"Development performance:\", dev_scores)\n",
    "\n",
    "        writer.add_scalar('val/loss', total_loss, epoch)\n",
    "        writer.add_scalar('val/precision', dev_scores[2], epoch)\n",
    "\n",
    "        labels = label_field.vocab.itos[2:]\n",
    "        labels = sorted(labels, key=lambda x: x.split(\"-\")[-1])\n",
    "        label_idxs = [label_field.vocab.stoi[l] for l in labels]\n",
    "\n",
    "        cr = classification_report(correct, predictions, labels = label_idxs, target_names=labels, output_dict=True)\n",
    "\n",
    "        out = {}\n",
    "        for key in cr.keys():\n",
    "            if key == 'accuracy':\n",
    "                out[key] = cr[key]\n",
    "            else:\n",
    "                for new_k in ['precision', 'recall', 'f1-score']:\n",
    "                    out[key+'_'+new_k] = cr[key][new_k]\n",
    "        \n",
    "        for (key, value) in out.items():\n",
    "            writer.add_scalar(f'test/{key}', value, epoch)\n",
    "        \n",
    "        dev_f = dev_scores[2]\n",
    "\n",
    "        dev_f = out['macro avg_f1-score']\n",
    "\n",
    "        if len(dev_f_score_history) > patience and dev_f < max(dev_f_score_history):\n",
    "            no_improvement += 1\n",
    "\n",
    "        elif len(dev_f_score_history) == 0 or dev_f > max(dev_f_score_history):\n",
    "            print(\"Saving model.\")\n",
    "            torch.save(model, output_path)\n",
    "            no_improvement = 0\n",
    "            \n",
    "        if no_improvement > patience:\n",
    "            print(\"Macro average F1-score does not improve anymore. Stop training.\")\n",
    "            dev_f_score_history.append(dev_f)\n",
    "            break\n",
    "            \n",
    "        dev_f_score_history.append(dev_f)\n",
    "        \n",
    "    return train_f_score_history, dev_f_score_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_iter, batch_size, labels, target_names): \n",
    "    \n",
    "    total_loss = 0\n",
    "    predictions, correct = [], []\n",
    "    for batch in test_iter:\n",
    "\n",
    "        text_length, cur_batch_size = batch.text[0].shape\n",
    "\n",
    "        pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size * text_length, NUM_CLASSES)\n",
    "        gold = batch.labels.to(device).view(cur_batch_size * text_length)\n",
    "\n",
    "        _, pred_indices = torch.max(pred, 1)\n",
    "        predicted_labels = list(pred_indices.cpu().numpy())\n",
    "        correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "\n",
    "        predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, correct_labels)\n",
    "\n",
    "        predictions += predicted_labels\n",
    "        correct += correct_labels\n",
    "    \n",
    "    print(classification_report(correct, predictions, labels=labels, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 6 : ['<unk>', '<pad>', 'B-O', 'I-LF', 'B-AC', 'B-LF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 34/34 [00:05<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 44.59322738647461\n",
      "Training performance: (0.2771, 0.2771, 0.2771, None)\n",
      "Total development loss: 4.505491495132446\n",
      "Development performance: (0.4606, 0.4606, 0.4606, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 34/34 [00:05<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 27.964872419834137\n",
      "Training performance: (0.5128, 0.5128, 0.5128, None)\n",
      "Total development loss: 3.4446346759796143\n",
      "Development performance: (0.5364, 0.5364, 0.5364, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 34/34 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 22.420595973730087\n",
      "Training performance: (0.6017, 0.6017, 0.6017, None)\n",
      "Total development loss: 3.2356045842170715\n",
      "Development performance: (0.5456, 0.5456, 0.5456, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 34/34 [00:05<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 19.454075038433075\n",
      "Training performance: (0.64565, 0.64565, 0.64565, None)\n",
      "Total development loss: 3.0161866545677185\n",
      "Development performance: (0.6566, 0.6566, 0.6566, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 34/34 [00:05<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 17.526302456855774\n",
      "Training performance: (0.6853, 0.6853, 0.6853, None)\n",
      "Total development loss: 3.064927399158478\n",
      "Development performance: (0.57, 0.57, 0.57, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 34/34 [00:05<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 16.372957080602646\n",
      "Training performance: (0.693575, 0.693575, 0.693575, None)\n",
      "Total development loss: 2.793994128704071\n",
      "Development performance: (0.6724, 0.6724, 0.6724, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 34/34 [00:05<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 15.401475489139557\n",
      "Training performance: (0.7139, 0.7139, 0.7139, None)\n",
      "Total development loss: 2.790491461753845\n",
      "Development performance: (0.7092, 0.7092, 0.7092, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 34/34 [00:04<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 13.985391303896904\n",
      "Training performance: (0.749425, 0.749425, 0.749425, None)\n",
      "Total development loss: 2.685593843460083\n",
      "Development performance: (0.7108, 0.7108, 0.7108, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 34/34 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 13.262774139642715\n",
      "Training performance: (0.74815, 0.74815, 0.74815, None)\n",
      "Total development loss: 2.650449812412262\n",
      "Development performance: (0.7126, 0.7126, 0.7126, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 34/34 [00:04<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 11.854285061359406\n",
      "Training performance: (0.771625, 0.771625, 0.771625, None)\n",
      "Total development loss: 2.6897128224372864\n",
      "Development performance: (0.7454, 0.7454, 0.7454, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 34/34 [00:04<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 11.386688724160194\n",
      "Training performance: (0.78325, 0.78325, 0.78325, None)\n",
      "Total development loss: 2.7085142731666565\n",
      "Development performance: (0.6498, 0.6498, 0.6498, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 34/34 [00:04<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 10.280376374721527\n",
      "Training performance: (0.7981, 0.7981, 0.7981, None)\n",
      "Total development loss: 2.801142990589142\n",
      "Development performance: (0.7198, 0.7198, 0.7198, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 34/34 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 9.66869705915451\n",
      "Training performance: (0.805775, 0.805775, 0.805775, None)\n",
      "Total development loss: 2.8667373061180115\n",
      "Development performance: (0.6942, 0.6942, 0.6942, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 34/34 [00:04<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 8.968911215662956\n",
      "Training performance: (0.81, 0.81, 0.81, None)\n",
      "Total development loss: 3.0652021169662476\n",
      "Development performance: (0.7938, 0.7938, 0.7938, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 34/34 [00:04<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 7.85205078125\n",
      "Training performance: (0.839025, 0.839025, 0.839025, None)\n",
      "Total development loss: 2.9323302507400513\n",
      "Development performance: (0.7592, 0.7592, 0.7592, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 34/34 [00:04<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 6.921356663107872\n",
      "Training performance: (0.851525, 0.851525, 0.851525, None)\n",
      "Total development loss: 3.322786808013916\n",
      "Development performance: (0.8098, 0.8098, 0.8098, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 34/34 [00:05<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 6.2039294093847275\n",
      "Training performance: (0.864825, 0.864825, 0.864825, None)\n",
      "Total development loss: 2.9697201251983643\n",
      "Development performance: (0.7278, 0.7278, 0.7278, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 34/34 [00:04<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 5.751390531659126\n",
      "Training performance: (0.86755, 0.86755, 0.86755, None)\n",
      "Total development loss: 3.8274325132369995\n",
      "Development performance: (0.8252, 0.8252, 0.8252, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 34/34 [00:04<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 5.4444844871759415\n",
      "Training performance: (0.882075, 0.882075, 0.882075, None)\n",
      "Total development loss: 3.2915780544281006\n",
      "Development performance: (0.7682, 0.7682, 0.7682, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 34/34 [00:04<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 4.66986982524395\n",
      "Training performance: (0.893475, 0.893475, 0.893475, None)\n",
      "Total development loss: 4.1822381019592285\n",
      "Development performance: (0.8312, 0.8312, 0.8312, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 34/34 [00:05<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 4.663622632622719\n",
      "Training performance: (0.8983, 0.8983, 0.8983, None)\n",
      "Total development loss: 3.5068647861480713\n",
      "Development performance: (0.7656, 0.7656, 0.7656, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 34/34 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 4.244549207389355\n",
      "Training performance: (0.907125, 0.907125, 0.907125, None)\n",
      "Total development loss: 3.198092520236969\n",
      "Development performance: (0.7366, 0.7366, 0.7366, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 34/34 [00:04<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.86333991214633\n",
      "Training performance: (0.90425, 0.90425, 0.90425, None)\n",
      "Total development loss: 4.365160882472992\n",
      "Development performance: (0.8142, 0.8142, 0.8142, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 34/34 [00:04<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.259633332490921\n",
      "Training performance: (0.925525, 0.925525, 0.925525, None)\n",
      "Total development loss: 4.5445809960365295\n",
      "Development performance: (0.8166, 0.8166, 0.8166, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 34/34 [00:04<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.9187543280422688\n",
      "Training performance: (0.93105, 0.93105, 0.93105, None)\n",
      "Total development loss: 4.67091429233551\n",
      "Development performance: (0.8258, 0.8258, 0.8258, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 34/34 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.7961005866527557\n",
      "Training performance: (0.933575, 0.933575, 0.933575, None)\n",
      "Total development loss: 4.906975865364075\n",
      "Development performance: (0.8186, 0.8186, 0.8186, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 34/34 [00:05<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.538127116858959\n",
      "Training performance: (0.941275, 0.941275, 0.941275, None)\n",
      "Total development loss: 4.803732335567474\n",
      "Development performance: (0.8286, 0.8286, 0.8286, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 34/34 [00:04<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.346688147634268\n",
      "Training performance: (0.94345, 0.94345, 0.94345, None)\n",
      "Total development loss: 5.343642354011536\n",
      "Development performance: (0.8326, 0.8326, 0.8326, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 34/34 [00:04<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.0514861661940813\n",
      "Training performance: (0.950825, 0.950825, 0.950825, None)\n",
      "Total development loss: 6.603135347366333\n",
      "Development performance: (0.8608, 0.8608, 0.8608, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 34/34 [00:04<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.6921414360404015\n",
      "Training performance: (0.95955, 0.95955, 0.95955, None)\n",
      "Total development loss: 5.859326362609863\n",
      "Development performance: (0.8364, 0.8364, 0.8364, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 34/34 [00:06<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.5815058257430792\n",
      "Training performance: (0.96205, 0.96205, 0.96205, None)\n",
      "Total development loss: 6.30253541469574\n",
      "Development performance: (0.8502, 0.8502, 0.8502, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 34/34 [00:05<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.6246141158044338\n",
      "Training performance: (0.961225, 0.961225, 0.961225, None)\n",
      "Total development loss: 6.49357807636261\n",
      "Development performance: (0.8542, 0.8542, 0.8542, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 34/34 [00:05<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.3002379313111305\n",
      "Training performance: (0.967225, 0.967225, 0.967225, None)\n",
      "Total development loss: 6.604887008666992\n",
      "Development performance: (0.838, 0.838, 0.838, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 34/34 [00:05<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.1914063543081284\n",
      "Training performance: (0.9716, 0.9716, 0.9716, None)\n",
      "Total development loss: 6.837285041809082\n",
      "Development performance: (0.8488, 0.8488, 0.8488, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 34/34 [00:04<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.0202168133109808\n",
      "Training performance: (0.975025, 0.975025, 0.975025, None)\n",
      "Total development loss: 7.947956681251526\n",
      "Development performance: (0.8632, 0.8632, 0.8632, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 34/34 [00:05<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.215178963728249\n",
      "Training performance: (0.9704, 0.9704, 0.9704, None)\n",
      "Total development loss: 6.410141229629517\n",
      "Development performance: (0.8204, 0.8204, 0.8204, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 34/34 [00:05<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.2054306715726852\n",
      "Training performance: (0.969475, 0.969475, 0.969475, None)\n",
      "Total development loss: 7.663728713989258\n",
      "Development performance: (0.8614, 0.8614, 0.8614, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 34/34 [00:04<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.8999510426074266\n",
      "Training performance: (0.9793, 0.9793, 0.9793, None)\n",
      "Total development loss: 6.934944272041321\n",
      "Development performance: (0.839, 0.839, 0.839, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 34/34 [00:04<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.1517537897452712\n",
      "Training performance: (0.9716, 0.9716, 0.9716, None)\n",
      "Total development loss: 7.188336253166199\n",
      "Development performance: (0.8484, 0.8484, 0.8484, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 34/34 [00:05<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.9330552788451314\n",
      "Training performance: (0.977525, 0.977525, 0.977525, None)\n",
      "Total development loss: 7.920595765113831\n",
      "Development performance: (0.852, 0.852, 0.852, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 34/34 [00:05<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.7311584446579218\n",
      "Training performance: (0.9833, 0.9833, 0.9833, None)\n",
      "Total development loss: 8.402252316474915\n",
      "Development performance: (0.8596, 0.8596, 0.8596, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 34/34 [00:05<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.7275997502729297\n",
      "Training performance: (0.98175, 0.98175, 0.98175, None)\n",
      "Total development loss: 8.709981083869934\n",
      "Development performance: (0.8678, 0.8678, 0.8678, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 34/34 [00:04<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.7094020927324891\n",
      "Training performance: (0.983275, 0.983275, 0.983275, None)\n",
      "Total development loss: 7.6988362073898315\n",
      "Development performance: (0.8554, 0.8554, 0.8554, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 34/34 [00:04<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.6860375297255814\n",
      "Training performance: (0.982925, 0.982925, 0.982925, None)\n",
      "Total development loss: 8.743533253669739\n",
      "Development performance: (0.8664, 0.8664, 0.8664, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 34/34 [00:04<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.6276568560861051\n",
      "Training performance: (0.9843, 0.9843, 0.9843, None)\n",
      "Total development loss: 8.442186832427979\n",
      "Development performance: (0.8548, 0.8548, 0.8548, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 34/34 [00:04<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.699700441211462\n",
      "Training performance: (0.983075, 0.983075, 0.983075, None)\n",
      "Total development loss: 8.829813599586487\n",
      "Development performance: (0.87, 0.87, 0.87, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 34/34 [00:04<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.5029060295782983\n",
      "Training performance: (0.9884, 0.9884, 0.9884, None)\n",
      "Total development loss: 8.908054232597351\n",
      "Development performance: (0.8666, 0.8666, 0.8666, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 34/34 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.4178056404925883\n",
      "Training performance: (0.99045, 0.99045, 0.99045, None)\n",
      "Total development loss: 9.201489210128784\n",
      "Development performance: (0.8662, 0.8662, 0.8662, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 34/34 [00:04<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.3716429134365171\n",
      "Training performance: (0.9923, 0.9923, 0.9923, None)\n",
      "Total development loss: 10.271423101425171\n",
      "Development performance: (0.8668, 0.8668, 0.8668, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 34/34 [00:04<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.2933853408321738\n",
      "Training performance: (0.993725, 0.993725, 0.993725, None)\n",
      "Total development loss: 9.631053924560547\n",
      "Development performance: (0.8604, 0.8604, 0.8604, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 34/34 [00:04<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.3220007955096662\n",
      "Training performance: (0.993525, 0.993525, 0.993525, None)\n",
      "Total development loss: 10.143798828125\n",
      "Development performance: (0.8594, 0.8594, 0.8594, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 34/34 [00:04<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.27900317194871604\n",
      "Training performance: (0.9939, 0.9939, 0.9939, None)\n",
      "Total development loss: 10.162903547286987\n",
      "Development performance: (0.8674, 0.8674, 0.8674, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 34/34 [00:04<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.2564648377010599\n",
      "Training performance: (0.994575, 0.994575, 0.994575, None)\n",
      "Total development loss: 10.001692056655884\n",
      "Development performance: (0.8626, 0.8626, 0.8626, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 34/34 [00:04<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.30159151554107666\n",
      "Training performance: (0.993575, 0.993575, 0.993575, None)\n",
      "Total development loss: 10.287713766098022\n",
      "Development performance: (0.8574, 0.8574, 0.8574, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 34/34 [00:04<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.25975288450717926\n",
      "Training performance: (0.994425, 0.994425, 0.994425, None)\n",
      "Total development loss: 10.56296706199646\n",
      "Development performance: (0.8534, 0.8534, 0.8534, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 34/34 [00:04<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.27643740247003734\n",
      "Training performance: (0.993625, 0.993625, 0.993625, None)\n",
      "Total development loss: 10.939492225646973\n",
      "Development performance: (0.8658, 0.8658, 0.8658, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 34/34 [00:04<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.322461519157514\n",
      "Training performance: (0.99245, 0.99245, 0.99245, None)\n",
      "Total development loss: 10.018348693847656\n",
      "Development performance: (0.8624, 0.8624, 0.8624, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 34/34 [00:04<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.2767133249435574\n",
      "Training performance: (0.993825, 0.993825, 0.993825, None)\n",
      "Total development loss: 10.693390369415283\n",
      "Development performance: (0.8594, 0.8594, 0.8594, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 34/34 [00:04<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.3548900946043432\n",
      "Training performance: (0.9913, 0.9913, 0.9913, None)\n",
      "Total development loss: 9.10917043685913\n",
      "Development performance: (0.8512, 0.8512, 0.8512, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 34/34 [00:04<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.45302143599838\n",
      "Training performance: (0.950375, 0.950375, 0.950375, None)\n",
      "Total development loss: 6.74078369140625\n",
      "Development performance: (0.8342, 0.8342, 0.8342, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 34/34 [00:04<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.3151553831994534\n",
      "Training performance: (0.9457, 0.9457, 0.9457, None)\n",
      "Total development loss: 5.88471519947052\n",
      "Development performance: (0.8258, 0.8258, 0.8258, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 34/34 [00:04<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.352178399451077\n",
      "Training performance: (0.96535, 0.96535, 0.96535, None)\n",
      "Total development loss: 6.581879138946533\n",
      "Development performance: (0.844, 0.844, 0.844, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 34/34 [00:04<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.665676839184016\n",
      "Training performance: (0.98215, 0.98215, 0.98215, None)\n",
      "Total development loss: 8.50543761253357\n",
      "Development performance: (0.8654, 0.8654, 0.8654, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 34/34 [00:04<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.4652990438044071\n",
      "Training performance: (0.98955, 0.98955, 0.98955, None)\n",
      "Total development loss: 8.449998378753662\n",
      "Development performance: (0.8626, 0.8626, 0.8626, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 34/34 [00:04<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.34579166769981384\n",
      "Training performance: (0.992575, 0.992575, 0.992575, None)\n",
      "Total development loss: 8.513863205909729\n",
      "Development performance: (0.848, 0.848, 0.848, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 34/34 [00:04<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.25667517026886344\n",
      "Training performance: (0.9943, 0.9943, 0.9943, None)\n",
      "Total development loss: 10.274835109710693\n",
      "Development performance: (0.8708, 0.8708, 0.8708, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 34/34 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.1909655297640711\n",
      "Training performance: (0.996325, 0.996325, 0.996325, None)\n",
      "Total development loss: 11.088401317596436\n",
      "Development performance: (0.8718, 0.8718, 0.8718, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 34/34 [00:04<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.1704226634465158\n",
      "Training performance: (0.9966, 0.9966, 0.9966, None)\n",
      "Total development loss: 10.840176820755005\n",
      "Development performance: (0.8634, 0.8634, 0.8634, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 34/34 [00:04<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.14480598364025354\n",
      "Training performance: (0.99755, 0.99755, 0.99755, None)\n",
      "Total development loss: 10.97702670097351\n",
      "Development performance: (0.863, 0.863, 0.863, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 34/34 [00:04<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.11975949094630778\n",
      "Training performance: (0.998275, 0.998275, 0.998275, None)\n",
      "Total development loss: 11.444353818893433\n",
      "Development performance: (0.8658, 0.8658, 0.8658, None)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "EMBEDDING_DIM = 300 #fasttext & word2vec\n",
    "# EMBEDDING_DIM = 768 #bert\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = len(label_field.vocab)\n",
    "print(f\"Number of classes: {NUM_CLASSES} : {label_field.vocab.itos}\")\n",
    "MAX_EPOCHS = 70\n",
    "PATIENCE = 50\n",
    "OUTPUT_PATH = \"model_saves/bilstmtagger\"\n",
    "num_batches = math.ceil(len(train_data) / BATCH_SIZE)\n",
    "\n",
    "tagger = BiLSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE+2, NUM_CLASSES, embeddings=embedding_matrix)  # embeddings\n",
    "# tagger = BiLSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE+2, NUM_CLASSES)  # no embeddings\n",
    "\n",
    "train_f, dev_f = train(tagger.to(device), train_iter, val_iter, BATCH_SIZE, MAX_EPOCHS, \n",
    "                       num_batches, PATIENCE, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "df = pd.DataFrame({'epochs': range(0,len(train_f)), \n",
    "                  'train_f': train_f, \n",
    "                   'val_f': dev_f})\n",
    " \n",
    "# multiple line plot\n",
    "plt.plot('epochs', 'train_f', data=df, color='blue', linewidth=2)\n",
    "plt.plot('epochs', 'val_f', data=df, color='green', linewidth=2)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = \"model_saves/bilstmtagger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMTagger(\n",
       "  (embeddings): Embedding(9135, 300)\n",
       "  (lstm): LSTM(300, 256, bidirectional=True)\n",
       "  (dropout_layer): Dropout(p=0.5, inplace=False)\n",
       "  (hidden2tag): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = torch.load(OUTPUT_PATH)\n",
    "tagger.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-AC       0.45      0.45      0.45       270\n",
      "        I-LF       0.56      0.44      0.49       288\n",
      "        B-LF       0.41      0.31      0.36       150\n",
      "         B-O       0.92      0.94      0.93      4292\n",
      "\n",
      "    accuracy                           0.86      5000\n",
      "   macro avg       0.58      0.53      0.56      5000\n",
      "weighted avg       0.86      0.86      0.86      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = label_field.vocab.itos[2:]\n",
    "labels = sorted(labels, key=lambda x: x.split(\"-\")[-1])\n",
    "label_idxs = [label_field.vocab.stoi[l] for l in labels]\n",
    "\n",
    "test(tagger, test_iter, BATCH_SIZE, labels = label_idxs, target_names = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Back, Style\n",
    "\n",
    "def vizu(words, output, truth):\n",
    "    if isinstance(output, torch.Tensor):\n",
    "        output = output.squeeze().tolist()\n",
    "    col = {0: Back.GREEN, 1: Back.RED, 2: Back.BLACK, 3: Back.BLUE, 4: Back.MAGENTA}\n",
    "    colors1 = [col[i] for i in output]\n",
    "    colors2 = [col[i] for i in truth]\n",
    "    words = [word.replace(\"Ġ\", \"\") for word in words]\n",
    "    print(Style.RESET_ALL + \"Output:\")\n",
    "    for i, word in enumerate(words):\n",
    "        print(colors1[i] + word, end=\" \")\n",
    "    print(Style.RESET_ALL + \"\\nTruth:\")\n",
    "    for i, word in enumerate(words):\n",
    "        print(colors2[i] + word, end=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
