{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antoine EDY\n",
    "# Natural Language Processing (COMM061) - Coursework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import nltk\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"surrey-nlp/PLOD-CW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT2ID: {'B-O': 0, 'B-AC': 1, 'PAD': 2, 'B-LF': 3, 'I-LF': 4}\n",
      "ID2TEXT: {0: 'B-O', 1: 'B-AC', 2: 'PAD', 3: 'B-LF', 4: 'I-LF'}\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1072 entries, 0 to 1071\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tokens     1072 non-null   object\n",
      " 1   labels     1072 non-null   object\n",
      " 2   ids        1072 non-null   object\n",
      " 3   sentences  1072 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 33.6+ KB\n"
     ]
    }
   ],
   "source": [
    "TEXT2ID = {\n",
    "    \"B-O\": 0,\n",
    "    \"B-AC\": 1,\n",
    "    \"PAD\": 2,\n",
    "    \"B-LF\": 3,\n",
    "    \"I-LF\": 4,\n",
    "}\n",
    "ID2TEXT = {v: k for k, v in TEXT2ID.items()}\n",
    "\n",
    "print(f\"TEXT2ID: {TEXT2ID}\\nID2TEXT: {ID2TEXT}\\n\")\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.drop(columns=['pos_tags'])\n",
    "    df = df.rename(columns={\"ner_tags\": \"labels\"})\n",
    "    df[\"ids\"] = df[\"labels\"].apply(lambda x: [TEXT2ID[i] for i in x])\n",
    "    df[\"sentences\"] = df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_dataset = preprocess(pd.DataFrame(dataset['train']))\n",
    "test_dataset = preprocess(pd.DataFrame(dataset['test']))\n",
    "val_dataset = preprocess(pd.DataFrame(dataset['validation']))\n",
    "\n",
    "train_dataset.info()\n",
    "\n",
    "\n",
    "# Here the exploration to add at the end of the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>ids</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[For, this, purpose, the, Gothenburg, Young, P...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>For this purpose the Gothenburg Young Persons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, following, physiological, traits, were, ...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>The following physiological traits were measur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Minor, H, antigen, alloimmune, responses, rea...</td>\n",
       "      <td>[B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...</td>\n",
       "      <td>Minor H antigen alloimmune responses readily o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[EPI, =, Echo, planar, imaging, .]</td>\n",
       "      <td>[B-AC, B-O, B-LF, I-LF, I-LF, B-O]</td>\n",
       "      <td>[1, 0, 3, 4, 4, 0]</td>\n",
       "      <td>EPI = Echo planar imaging .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Furthermore, ,, eNOS, -, derived, NO, S, -, n...</td>\n",
       "      <td>[B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Furthermore , eNOS - derived NO S - nitrosylat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [For, this, purpose, the, Gothenburg, Young, P...   \n",
       "1  [The, following, physiological, traits, were, ...   \n",
       "2  [Minor, H, antigen, alloimmune, responses, rea...   \n",
       "3                 [EPI, =, Echo, planar, imaging, .]   \n",
       "4  [Furthermore, ,, eNOS, -, derived, NO, S, -, n...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...   \n",
       "1  [B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...   \n",
       "2  [B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...   \n",
       "3                 [B-AC, B-O, B-LF, I-LF, I-LF, B-O]   \n",
       "4  [B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...   \n",
       "\n",
       "                                                 ids  \\\n",
       "0      [0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...   \n",
       "3                                 [1, 0, 3, 4, 4, 0]   \n",
       "4  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           sentences  \n",
       "0  For this purpose the Gothenburg Young Persons ...  \n",
       "1  The following physiological traits were measur...  \n",
       "2  Minor H antigen alloimmune responses readily o...  \n",
       "3                        EPI = Echo planar imaging .  \n",
       "4  Furthermore , eNOS - derived NO S - nitrosylat...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072\n",
      "126\n",
      "153\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>ids</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[For, this, purpose, the, Gothenburg, Young, P...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>For this purpose the Gothenburg Young Persons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, following, physiological, traits, were, ...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>The following physiological traits were measur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Minor, H, antigen, alloimmune, responses, rea...</td>\n",
       "      <td>[B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...</td>\n",
       "      <td>Minor H antigen alloimmune responses readily o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[EPI, =, Echo, planar, imaging, .]</td>\n",
       "      <td>[B-AC, B-O, B-LF, I-LF, I-LF, B-O]</td>\n",
       "      <td>[1, 0, 3, 4, 4, 0]</td>\n",
       "      <td>EPI = Echo planar imaging .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Furthermore, ,, eNOS, -, derived, NO, S, -, n...</td>\n",
       "      <td>[B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Furthermore , eNOS - derived NO S - nitrosylat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [For, this, purpose, the, Gothenburg, Young, P...   \n",
       "1  [The, following, physiological, traits, were, ...   \n",
       "2  [Minor, H, antigen, alloimmune, responses, rea...   \n",
       "3                 [EPI, =, Echo, planar, imaging, .]   \n",
       "4  [Furthermore, ,, eNOS, -, derived, NO, S, -, n...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...   \n",
       "1  [B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...   \n",
       "2  [B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...   \n",
       "3                 [B-AC, B-O, B-LF, I-LF, I-LF, B-O]   \n",
       "4  [B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...   \n",
       "\n",
       "                                                 ids  \\\n",
       "0      [0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...   \n",
       "3                                 [1, 0, 3, 4, 4, 0]   \n",
       "4  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           sentences  \n",
       "0  For this purpose the Gothenburg Young Persons ...  \n",
       "1  The following physiological traits were measur...  \n",
       "2  Minor H antigen alloimmune responses readily o...  \n",
       "3                        EPI = Echo planar imaging .  \n",
       "4  Furthermore , eNOS - derived NO S - nitrosylat...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': <torchtext.data.field.Field object at 0x16aadfeb0>, 'text': <torchtext.data.field.Field object at 0x10592ace0>}\n",
      "['For', 'this', 'purpose', 'the', 'Gothenburg', 'Young', 'Persons', 'Empowerment', 'Scale', '(', 'GYPES', ')', 'was', 'developed', '.']\n",
      "['B-O', 'B-O', 'B-O', 'B-O', 'B-LF', 'I-LF', 'I-LF', 'I-LF', 'I-LF', 'B-O', 'B-AC', 'B-O', 'B-O', 'B-O', 'B-O']\n",
      "Train: 1072\n",
      "Dev: 126\n",
      "Test: 153\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Field, Dataset, Example\n",
    "\n",
    "text_field = Field(sequential=True, tokenize=lambda x:x, include_lengths=True) # Default behaviour is to tokenize by splitting\n",
    "label_field = Field(sequential=True, tokenize=lambda x:x, is_target=True)\n",
    "\n",
    "fields = {\n",
    "    'sentences': ('text', text_field),\n",
    "    'ids': ('label', label_field)\n",
    "}\n",
    "\n",
    "def read_data(df):\n",
    "    examples = []\n",
    "    fields = {'sentence_labels': ('labels', label_field),\n",
    "              'sentence_tokens': ('text', text_field)}\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        tokens = df['tokens'][i]\n",
    "        labels = df['labels'][i]\n",
    "        \n",
    "        e = Example.fromdict({\"sentence_labels\": labels, \"sentence_tokens\": tokens},\n",
    "                             fields=fields)\n",
    "        examples.append(e)\n",
    "    \n",
    "    return Dataset(examples, fields=[('labels', label_field), ('text', text_field)])\n",
    "\n",
    "\n",
    "train_data = read_data(train_dataset)\n",
    "val_data = read_data(val_dataset)\n",
    "test_data = read_data(test_dataset)\n",
    "\n",
    "print(train_data.fields)\n",
    "print(train_data[0].text)\n",
    "print(train_data[0].labels)\n",
    "\n",
    "print(\"Train:\", len(train_data))\n",
    "print(\"Dev:\", len(val_data))\n",
    "print(\"Test:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 20000\n",
    "\n",
    "text_field.build_vocab(train_data, max_size=VOCAB_SIZE)\n",
    "label_field.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import BucketIterator\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_iter = BucketIterator(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                            sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "val_iter = BucketIterator(dataset=val_data, batch_size=BATCH_SIZE, \n",
    "                          sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "test_iter = BucketIterator(dataset=test_data, batch_size=BATCH_SIZE, \n",
    "                           sort_key=lambda x: len(x.text), sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedding matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([9135, 300])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "EMBEDDING_PATH = \"/Users/antoineedy/Documents/MScAI/Semester2/NLP/Coursework/code/data/cc.en.300.vec\"\n",
    "\n",
    "def load_embeddings(path):\n",
    "    \"\"\" Load the FastText embeddings from the embedding file. \"\"\"\n",
    "    print(\"Loading pre-trained embeddings\")\n",
    "    \n",
    "    embeddings = {}\n",
    "    with open(path) as i:\n",
    "        for line in i:\n",
    "            if len(line) > 2: \n",
    "                line = line.strip().split()\n",
    "                word = line[0]\n",
    "                embedding = np.array(line[1:])\n",
    "                embeddings[word] = embedding\n",
    "    \n",
    "    return embeddings\n",
    "    \n",
    "\n",
    "def initialize_embeddings(embeddings, vocabulary):\n",
    "    \"\"\" Use the pre-trained embeddings to initialize an embedding matrix. \"\"\"\n",
    "    print(\"Initializing embedding matrix\")\n",
    "    embedding_size = len(embeddings[\".\"])\n",
    "    embedding_matrix = np.zeros((len(vocabulary), embedding_size), dtype=np.float32)\n",
    "                                \n",
    "    for idx, word in enumerate(vocabulary.itos): \n",
    "        if word in embeddings:\n",
    "            embedding_matrix[idx,:] = embeddings[word]\n",
    "            \n",
    "    return embedding_matrix\n",
    "\n",
    "embeddings = load_embeddings(EMBEDDING_PATH)\n",
    "embedding_matrix = initialize_embeddings(embeddings, text_field.vocab)\n",
    "embedding_matrix = torch.from_numpy(embedding_matrix)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class BiLSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, output_size, embeddings=None):\n",
    "        super(BiLSTMTagger, self).__init__()\n",
    "        \n",
    "        # 1. Embedding Layer\n",
    "        if embeddings is None:\n",
    "            self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        else:\n",
    "            self.embeddings = nn.Embedding.from_pretrained(embeddings)\n",
    "        \n",
    "        # 2. LSTM Layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, num_layers=1)\n",
    "        \n",
    "        # 3. Optional dropout layer\n",
    "        self.dropout_layer = nn.Dropout(p=0.5)\n",
    "\n",
    "        # 4. Dense Layer\n",
    "        self.hidden2tag = nn.Linear(2*hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, batch_text, batch_lengths):\n",
    "\n",
    "        embeddings = self.embeddings(batch_text)\n",
    "        \n",
    "        packed_seqs = pack_padded_sequence(embeddings, batch_lengths)\n",
    "        lstm_output, _ = self.lstm(packed_seqs)\n",
    "        lstm_output, _ = pad_packed_sequence(lstm_output)\n",
    "        lstm_output = self.dropout_layer(lstm_output)\n",
    "        \n",
    "        logits = self.hidden2tag(lstm_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 6: ['<unk>', '<pad>', 'B-O', 'I-LF', 'B-AC', 'B-LF']\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "def remove_predictions_for_masked_items(predicted_labels, correct_labels): \n",
    "\n",
    "    predicted_labels_without_mask = []\n",
    "    correct_labels_without_mask = []\n",
    "        \n",
    "    for p, c in zip(predicted_labels, correct_labels):\n",
    "        if c > 1:\n",
    "            predicted_labels_without_mask.append(p)\n",
    "            correct_labels_without_mask.append(c)\n",
    "            \n",
    "    return predicted_labels_without_mask, correct_labels_without_mask\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "NUM_CLASSES = len(label_field.vocab)\n",
    "print(f\"Number of classes: {NUM_CLASSES}: {label_field.vocab.itos}\")\n",
    "\n",
    "def train(model, train_iter, dev_iter, batch_size, max_epochs, num_batches, patience, output_path):\n",
    "    writer = SummaryWriter()\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=1)  # we mask the <pad> labels\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    train_f_score_history = []\n",
    "    dev_f_score_history = []\n",
    "    no_improvement = 0\n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        total_loss = 0\n",
    "        predictions, correct = [], []\n",
    "        for batch in tqdm(train_iter, total=num_batches, desc=f\"Epoch {epoch}\"):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            text_length, cur_batch_size = batch.text[0].shape\n",
    "            \n",
    "            pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size*text_length, NUM_CLASSES)\n",
    "            gold = batch.labels.to(device).view(cur_batch_size*text_length)\n",
    "            \n",
    "            loss = criterion(pred, gold)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, pred_indices = torch.max(pred, 1)\n",
    "            \n",
    "            predicted_labels = list(pred_indices.cpu().numpy())\n",
    "            correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "            \n",
    "            predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, \n",
    "                                                                                   correct_labels)\n",
    "            \n",
    "            predictions += predicted_labels\n",
    "            correct += correct_labels\n",
    "\n",
    "        train_scores = precision_recall_fscore_support(correct, predictions, average=\"micro\")\n",
    "        train_f_score_history.append(train_scores[2])\n",
    "            \n",
    "        print(\"Total training loss:\", total_loss)\n",
    "        print(\"Training performance:\", train_scores)\n",
    "\n",
    "        #tensorboard\n",
    "        writer.add_scalar('train/loss', total_loss, epoch)\n",
    "        writer.add_scalar('train/precision', train_scores[2], epoch)\n",
    "        \n",
    "        total_loss = 0\n",
    "        predictions, correct = [], []\n",
    "        for batch in dev_iter:\n",
    "\n",
    "            text_length, cur_batch_size = batch.text[0].shape\n",
    "\n",
    "            pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size * text_length, NUM_CLASSES)\n",
    "            gold = batch.labels.to(device).view(cur_batch_size * text_length)\n",
    "            loss = criterion(pred, gold)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, pred_indices = torch.max(pred, 1)\n",
    "            predicted_labels = list(pred_indices.cpu().numpy())\n",
    "            correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "            \n",
    "            predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, \n",
    "                                                                                   correct_labels)\n",
    "            \n",
    "            predictions += predicted_labels\n",
    "            correct += correct_labels\n",
    "\n",
    "        dev_scores = precision_recall_fscore_support(correct, predictions, average=\"micro\")\n",
    "            \n",
    "        print(\"Total development loss:\", total_loss)\n",
    "        print(\"Development performance:\", dev_scores)\n",
    "\n",
    "        writer.add_scalar('val/loss', total_loss, epoch)\n",
    "        writer.add_scalar('val/precision', dev_scores[2], epoch)\n",
    "        \n",
    "        dev_f = dev_scores[2]\n",
    "        if len(dev_f_score_history) > patience and dev_f < max(dev_f_score_history):\n",
    "            no_improvement += 1\n",
    "\n",
    "        elif len(dev_f_score_history) == 0 or dev_f > max(dev_f_score_history):\n",
    "            print(\"Saving model.\")\n",
    "            torch.save(model, output_path)\n",
    "            no_improvement = 0\n",
    "            \n",
    "        if no_improvement > patience:\n",
    "            print(\"Development F-score does not improve anymore. Stop training.\")\n",
    "            dev_f_score_history.append(dev_f)\n",
    "            break\n",
    "            \n",
    "        dev_f_score_history.append(dev_f)\n",
    "        \n",
    "    return train_f_score_history, dev_f_score_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_iter, batch_size, labels, target_names): \n",
    "    \n",
    "    total_loss = 0\n",
    "    predictions, correct = [], []\n",
    "    for batch in test_iter:\n",
    "\n",
    "        text_length, cur_batch_size = batch.text[0].shape\n",
    "\n",
    "        pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size * text_length, NUM_CLASSES)\n",
    "        gold = batch.labels.to(device).view(cur_batch_size * text_length)\n",
    "\n",
    "        _, pred_indices = torch.max(pred, 1)\n",
    "        predicted_labels = list(pred_indices.cpu().numpy())\n",
    "        correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "\n",
    "        predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, correct_labels)\n",
    "\n",
    "        predictions += predicted_labels\n",
    "        correct += correct_labels\n",
    "    \n",
    "    print(classification_report(correct, predictions, labels=labels, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 6 : ['<unk>', '<pad>', 'B-O', 'I-LF', 'B-AC', 'B-LF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 34/34 [00:05<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 31.456385105848312\n",
      "Training performance: (0.76635, 0.76635, 0.76635, None)\n",
      "Total development loss: 2.2517393827438354\n",
      "Development performance: (0.8522, 0.8522, 0.8522, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 34/34 [00:06<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 17.650064826011658\n",
      "Training performance: (0.834375, 0.834375, 0.834375, None)\n",
      "Total development loss: 1.575763761997223\n",
      "Development performance: (0.8788, 0.8788, 0.8788, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 34/34 [00:05<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 12.625960052013397\n",
      "Training performance: (0.8717, 0.8717, 0.8717, None)\n",
      "Total development loss: 1.3238142430782318\n",
      "Development performance: (0.886, 0.886, 0.886, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 34/34 [00:05<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 10.660089790821075\n",
      "Training performance: (0.890375, 0.890375, 0.890375, None)\n",
      "Total development loss: 1.189495474100113\n",
      "Development performance: (0.9046, 0.9046, 0.9046, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 34/34 [00:05<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 9.579748198390007\n",
      "Training performance: (0.8971, 0.8971, 0.8971, None)\n",
      "Total development loss: 1.1703931093215942\n",
      "Development performance: (0.9146, 0.9146, 0.9146, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 34/34 [00:06<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 8.963502004742622\n",
      "Training performance: (0.905575, 0.905575, 0.905575, None)\n",
      "Total development loss: 1.1033621430397034\n",
      "Development performance: (0.9106, 0.9106, 0.9106, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 34/34 [00:05<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 8.459056571125984\n",
      "Training performance: (0.90675, 0.90675, 0.90675, None)\n",
      "Total development loss: 1.0634248703718185\n",
      "Development performance: (0.914, 0.914, 0.914, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 34/34 [00:06<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 8.155366122722626\n",
      "Training performance: (0.911425, 0.911425, 0.911425, None)\n",
      "Total development loss: 1.0239451974630356\n",
      "Development performance: (0.9184, 0.9184, 0.9184, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 34/34 [00:08<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 7.627715215086937\n",
      "Training performance: (0.914175, 0.914175, 0.914175, None)\n",
      "Total development loss: 1.0506568551063538\n",
      "Development performance: (0.9124, 0.9124, 0.9124, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 34/34 [00:08<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 7.13701519370079\n",
      "Training performance: (0.920425, 0.920425, 0.920425, None)\n",
      "Total development loss: 1.0585985332727432\n",
      "Development performance: (0.9152, 0.9152, 0.9152, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 34/34 [00:09<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 7.1483031660318375\n",
      "Training performance: (0.920375, 0.920375, 0.920375, None)\n",
      "Total development loss: 1.0455527007579803\n",
      "Development performance: (0.91, 0.91, 0.91, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 34/34 [00:10<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 6.732155218720436\n",
      "Training performance: (0.92415, 0.92415, 0.92415, None)\n",
      "Total development loss: 1.044957384467125\n",
      "Development performance: (0.9152, 0.9152, 0.9152, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 34/34 [00:08<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 6.24696284532547\n",
      "Training performance: (0.92735, 0.92735, 0.92735, None)\n",
      "Total development loss: 0.9789342880249023\n",
      "Development performance: (0.9232, 0.9232, 0.9232, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 34/34 [00:08<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 5.818923011422157\n",
      "Training performance: (0.93365, 0.93365, 0.93365, None)\n",
      "Total development loss: 1.0511650741100311\n",
      "Development performance: (0.913, 0.913, 0.913, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 34/34 [00:08<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 5.641600556671619\n",
      "Training performance: (0.9363, 0.9363, 0.9363, None)\n",
      "Total development loss: 0.9806095957756042\n",
      "Development performance: (0.9208, 0.9208, 0.9208, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 34/34 [00:08<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 5.516607157886028\n",
      "Training performance: (0.936775, 0.936775, 0.936775, None)\n",
      "Total development loss: 1.0587833225727081\n",
      "Development performance: (0.912, 0.912, 0.912, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 34/34 [00:09<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 5.418370068073273\n",
      "Training performance: (0.93735, 0.93735, 0.93735, None)\n",
      "Total development loss: 1.0029603242874146\n",
      "Development performance: (0.9214, 0.9214, 0.9214, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 34/34 [00:08<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 4.82430562376976\n",
      "Training performance: (0.944825, 0.944825, 0.944825, None)\n",
      "Total development loss: 1.0457035899162292\n",
      "Development performance: (0.9162, 0.9162, 0.9162, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 34/34 [00:09<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 4.58141827583313\n",
      "Training performance: (0.9485, 0.9485, 0.9485, None)\n",
      "Total development loss: 0.9801222085952759\n",
      "Development performance: (0.924, 0.924, 0.924, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 34/34 [00:09<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 4.4179951921105385\n",
      "Training performance: (0.95045, 0.95045, 0.95045, None)\n",
      "Total development loss: 1.0906693041324615\n",
      "Development performance: (0.9184, 0.9184, 0.9184, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 34/34 [00:10<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.933890275657177\n",
      "Training performance: (0.95625, 0.95625, 0.95625, None)\n",
      "Total development loss: 1.1668473333120346\n",
      "Development performance: (0.9116, 0.9116, 0.9116, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 34/34 [00:09<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.6132954843342304\n",
      "Training performance: (0.958975, 0.958975, 0.958975, None)\n",
      "Total development loss: 1.089528664946556\n",
      "Development performance: (0.9198, 0.9198, 0.9198, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 34/34 [00:10<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.3677052967250347\n",
      "Training performance: (0.961175, 0.961175, 0.961175, None)\n",
      "Total development loss: 1.1235020458698273\n",
      "Development performance: (0.9252, 0.9252, 0.9252, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 34/34 [00:09<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.276290498673916\n",
      "Training performance: (0.96235, 0.96235, 0.96235, None)\n",
      "Total development loss: 1.1258565336465836\n",
      "Development performance: (0.9178, 0.9178, 0.9178, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 34/34 [00:09<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.0577580854296684\n",
      "Training performance: (0.9651, 0.9651, 0.9651, None)\n",
      "Total development loss: 1.2300563752651215\n",
      "Development performance: (0.9124, 0.9124, 0.9124, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 34/34 [00:09<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.208093535155058\n",
      "Training performance: (0.961075, 0.961075, 0.961075, None)\n",
      "Total development loss: 1.0771837830543518\n",
      "Development performance: (0.922, 0.922, 0.922, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 34/34 [00:09<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.1038772836327553\n",
      "Training performance: (0.964825, 0.964825, 0.964825, None)\n",
      "Total development loss: 1.1302894949913025\n",
      "Development performance: (0.916, 0.916, 0.916, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 34/34 [00:09<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.4379729107022285\n",
      "Training performance: (0.97265, 0.97265, 0.97265, None)\n",
      "Total development loss: 1.1826680898666382\n",
      "Development performance: (0.9144, 0.9144, 0.9144, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 34/34 [00:08<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.182891670614481\n",
      "Training performance: (0.97545, 0.97545, 0.97545, None)\n",
      "Total development loss: 1.2116990983486176\n",
      "Development performance: (0.9134, 0.9134, 0.9134, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 34/34 [00:08<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.9445974696427584\n",
      "Training performance: (0.9784, 0.9784, 0.9784, None)\n",
      "Total development loss: 1.3077776432037354\n",
      "Development performance: (0.9118, 0.9118, 0.9118, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 34/34 [00:09<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.9602282252162695\n",
      "Training performance: (0.976325, 0.976325, 0.976325, None)\n",
      "Total development loss: 1.3186236023902893\n",
      "Development performance: (0.9128, 0.9128, 0.9128, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 34/34 [00:08<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.09212638810277\n",
      "Training performance: (0.975825, 0.975825, 0.975825, None)\n",
      "Total development loss: 1.3010003566741943\n",
      "Development performance: (0.9182, 0.9182, 0.9182, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 34/34 [00:09<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.872057830914855\n",
      "Training performance: (0.978725, 0.978725, 0.978725, None)\n",
      "Total development loss: 1.23270583152771\n",
      "Development performance: (0.9152, 0.9152, 0.9152, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 34/34 [00:09<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.605571584776044\n",
      "Training performance: (0.982375, 0.982375, 0.982375, None)\n",
      "Total development loss: 1.2822688668966293\n",
      "Development performance: (0.918, 0.918, 0.918, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 34/34 [00:12<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.420887891203165\n",
      "Training performance: (0.9841, 0.9841, 0.9841, None)\n",
      "Total development loss: 1.379821389913559\n",
      "Development performance: (0.9138, 0.9138, 0.9138, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 34/34 [00:09<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.2424227893352509\n",
      "Training performance: (0.98605, 0.98605, 0.98605, None)\n",
      "Total development loss: 1.5347194373607635\n",
      "Development performance: (0.9118, 0.9118, 0.9118, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 34/34 [00:09<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.2813453348353505\n",
      "Training performance: (0.985375, 0.985375, 0.985375, None)\n",
      "Total development loss: 1.4160096645355225\n",
      "Development performance: (0.911, 0.911, 0.911, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 34/34 [00:09<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.0896855480968952\n",
      "Training performance: (0.987875, 0.987875, 0.987875, None)\n",
      "Total development loss: 1.5841057896614075\n",
      "Development performance: (0.9122, 0.9122, 0.9122, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 34/34 [00:09<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.9823724292218685\n",
      "Training performance: (0.9894, 0.9894, 0.9894, None)\n",
      "Total development loss: 1.633582204580307\n",
      "Development performance: (0.9098, 0.9098, 0.9098, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 34/34 [00:09<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.034691077657044\n",
      "Training performance: (0.988, 0.988, 0.988, None)\n",
      "Total development loss: 1.5437991917133331\n",
      "Development performance: (0.9154, 0.9154, 0.9154, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 34/34 [00:10<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.2717011412605643\n",
      "Training performance: (0.9852, 0.9852, 0.9852, None)\n",
      "Total development loss: 1.5055620074272156\n",
      "Development performance: (0.9086, 0.9086, 0.9086, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 34/34 [00:09<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.9470807733014226\n",
      "Training performance: (0.9904, 0.9904, 0.9904, None)\n",
      "Total development loss: 1.5870178639888763\n",
      "Development performance: (0.9114, 0.9114, 0.9114, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 34/34 [00:07<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.811968021094799\n",
      "Training performance: (0.9917, 0.9917, 0.9917, None)\n",
      "Total development loss: 1.6938357949256897\n",
      "Development performance: (0.9106, 0.9106, 0.9106, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 34/34 [00:08<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.8812897717580199\n",
      "Training performance: (0.989875, 0.989875, 0.989875, None)\n",
      "Total development loss: 1.6521175503730774\n",
      "Development performance: (0.9076, 0.9076, 0.9076, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 34/34 [00:09<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.7525409092195332\n",
      "Training performance: (0.991525, 0.991525, 0.991525, None)\n",
      "Total development loss: 1.6679417788982391\n",
      "Development performance: (0.9042, 0.9042, 0.9042, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 34/34 [00:09<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.5914080184884369\n",
      "Training performance: (0.9933, 0.9933, 0.9933, None)\n",
      "Total development loss: 1.6875033378601074\n",
      "Development performance: (0.9102, 0.9102, 0.9102, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 34/34 [00:08<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.5906085041351616\n",
      "Training performance: (0.99385, 0.99385, 0.99385, None)\n",
      "Total development loss: 1.6921363770961761\n",
      "Development performance: (0.9126, 0.9126, 0.9126, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 34/34 [00:08<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.5247469223104417\n",
      "Training performance: (0.9944, 0.9944, 0.9944, None)\n",
      "Total development loss: 1.7683356404304504\n",
      "Development performance: (0.9056, 0.9056, 0.9056, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 34/34 [00:11<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.5075782579369843\n",
      "Training performance: (0.99465, 0.99465, 0.99465, None)\n",
      "Total development loss: 1.778069168329239\n",
      "Development performance: (0.9144, 0.9144, 0.9144, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 34/34 [00:12<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.4432279132306576\n",
      "Training performance: (0.9953, 0.9953, 0.9953, None)\n",
      "Total development loss: 1.7912384569644928\n",
      "Development performance: (0.9092, 0.9092, 0.9092, None)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = len(label_field.vocab)\n",
    "print(f\"Number of classes: {NUM_CLASSES} : {label_field.vocab.itos}\")\n",
    "MAX_EPOCHS = 50\n",
    "PATIENCE = 50\n",
    "OUTPUT_PATH = \"model_saves/bilstmtagger\"\n",
    "num_batches = math.ceil(len(train_data) / BATCH_SIZE)\n",
    "\n",
    "tagger = BiLSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE+2, NUM_CLASSES, embeddings=embedding_matrix)  # embeddings\n",
    "# tagger = BiLSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE+2, NUM_CLASSES)  # no embeddings\n",
    "\n",
    "train_f, dev_f = train(tagger.to(device), train_iter, val_iter, BATCH_SIZE, MAX_EPOCHS, \n",
    "                       num_batches, PATIENCE, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "df = pd.DataFrame({'epochs': range(0,len(train_f)), \n",
    "                  'train_f': train_f, \n",
    "                   'val_f': dev_f})\n",
    " \n",
    "# multiple line plot\n",
    "plt.plot('epochs', 'train_f', data=df, color='blue', linewidth=2)\n",
    "plt.plot('epochs', 'val_f', data=df, color='green', linewidth=2)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMTagger(\n",
       "  (embeddings): Embedding(30522, 768)\n",
       "  (lstm): LSTM(768, 256, bidirectional=True)\n",
       "  (dropout_layer): Dropout(p=0.5, inplace=False)\n",
       "  (hidden2tag): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = torch.load(OUTPUT_PATH)\n",
    "tagger.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-AC       0.78      0.29      0.43       270\n",
      "        I-LF       0.56      0.41      0.47       288\n",
      "        B-LF       0.35      0.15      0.21       150\n",
      "         B-O       0.90      0.98      0.94      4292\n",
      "\n",
      "    accuracy                           0.88      5000\n",
      "   macro avg       0.65      0.46      0.51      5000\n",
      "weighted avg       0.86      0.88      0.86      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = label_field.vocab.itos[2:]\n",
    "labels = sorted(labels, key=lambda x: x.split(\"-\")[-1])\n",
    "label_idxs = [label_field.vocab.stoi[l] for l in labels]\n",
    "\n",
    "test(tagger, test_iter, BATCH_SIZE, labels = label_idxs, target_names = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Back, Style\n",
    "\n",
    "def vizu(words, output, truth):\n",
    "    if isinstance(output, torch.Tensor):\n",
    "        output = output.squeeze().tolist()\n",
    "    col = {0: Back.BLACK, 1: Back.RED, 2: Back.GREEN, 3: Back.BLUE, 4: Back.MAGENTA}\n",
    "    colors1 = [col[i] for i in output]\n",
    "    colors2 = [col[i] for i in truth]\n",
    "    words = [word.replace(\"Ġ\", \"\") for word in words]\n",
    "    print(Style.RESET_ALL + \"Output:\")\n",
    "    for i, word in enumerate(words):\n",
    "        print(colors1[i] + word, end=\" \")\n",
    "    print(Style.RESET_ALL + \"\\nTruth:\")\n",
    "    for i, word in enumerate(words):\n",
    "        print(colors2[i] + word, end=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
