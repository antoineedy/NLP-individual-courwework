{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antoine EDY\n",
    "# Natural Language Processing (COMM061) - Coursework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import nltk\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"surrey-nlp/PLOD-CW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_preprocess(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    # make everything lowercase\n",
    "    #df[\"tokens\"] = df[\"tokens\"].apply(lambda x: [i.lower() for i in x])\n",
    "    # lematize\n",
    "    #lematizer = nltk.WordNetLemmatizer()\n",
    "    #df[\"tokens\"] = df[\"tokens\"].apply(lambda x: [lematizer.lemmatize(i) for i in x])\n",
    "    #stemming\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    df[\"tokens\"] = df[\"tokens\"].apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "\n",
    "    return df\n",
    "\n",
    "train_dataset = the_preprocess(dataset[\"train\"])\n",
    "test_dataset = the_preprocess(dataset[\"test\"])\n",
    "val_dataset = the_preprocess(dataset[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'striped', 'bat', 'are', 'hanging', 'on', 'their', 'foot', 'for', 'best']\n"
     ]
    }
   ],
   "source": [
    "lematizer = nltk.WordNetLemmatizer()\n",
    "sentence = \"The striped bats are hanging on their feet for best\"\n",
    "sentence = sentence.split()\n",
    "sentence = [lematizer.lemmatize(i) for i in sentence]\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'stripe', 'bat', 'are', 'hang', 'on', 'their', 'foot', 'for', 'best']\n"
     ]
    }
   ],
   "source": [
    "stemmer = nltk.PorterStemmer()\n",
    "sentence = \"The striped bats are hanging on their feet for best\"\n",
    "sentence = sentence.split()\n",
    "sentence = [lematizer.lemmatize(i) for i in sentence]\n",
    "sentence = [stemmer.stem(i) for i in sentence]\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT2ID: {'B-O': 0, 'B-AC': 1, 'PAD': 2, 'B-LF': 3, 'I-LF': 4}\n",
      "ID2TEXT: {0: 'B-O', 1: 'B-AC', 2: 'PAD', 3: 'B-LF', 4: 'I-LF'}\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1072 entries, 0 to 1071\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tokens     1072 non-null   object\n",
      " 1   labels     1072 non-null   object\n",
      " 2   ids        1072 non-null   object\n",
      " 3   sentences  1072 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 33.6+ KB\n"
     ]
    }
   ],
   "source": [
    "TEXT2ID = {\n",
    "    \"B-O\": 0,\n",
    "    \"B-AC\": 1,\n",
    "    \"PAD\": 2,\n",
    "    \"B-LF\": 3,\n",
    "    \"I-LF\": 4,\n",
    "}\n",
    "ID2TEXT = {v: k for k, v in TEXT2ID.items()}\n",
    "\n",
    "print(f\"TEXT2ID: {TEXT2ID}\\nID2TEXT: {ID2TEXT}\\n\")\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.drop(columns=['pos_tags'])\n",
    "    df = df.rename(columns={\"ner_tags\": \"labels\"})\n",
    "    df[\"ids\"] = df[\"labels\"].apply(lambda x: [TEXT2ID[i] for i in x])\n",
    "    df[\"sentences\"] = df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_dataset = preprocess(train_dataset)\n",
    "test_dataset = preprocess(test_dataset)\n",
    "val_dataset = preprocess(val_dataset)\n",
    "\n",
    "train_dataset.info()\n",
    "\n",
    "\n",
    "# Here the exploration to add at the end of the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>ids</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[for, thi, purpos, the, gothenburg, young, per...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>for thi purpos the gothenburg young person emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[the, follow, physiolog, trait, were, measur, ...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>the follow physiolog trait were measur : stoma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[minor, h, antigen, alloimmun, respons, readil...</td>\n",
       "      <td>[B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...</td>\n",
       "      <td>minor h antigen alloimmun respons readili occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[epi, =, echo, planar, imag, .]</td>\n",
       "      <td>[B-AC, B-O, B-LF, I-LF, I-LF, B-O]</td>\n",
       "      <td>[1, 0, 3, 4, 4, 0]</td>\n",
       "      <td>epi = echo planar imag .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[furthermor, ,, eno, -, deriv, no, s, -, nitro...</td>\n",
       "      <td>[B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>furthermor , eno - deriv no s - nitrosyl β - a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [for, thi, purpos, the, gothenburg, young, per...   \n",
       "1  [the, follow, physiolog, trait, were, measur, ...   \n",
       "2  [minor, h, antigen, alloimmun, respons, readil...   \n",
       "3                    [epi, =, echo, planar, imag, .]   \n",
       "4  [furthermor, ,, eno, -, deriv, no, s, -, nitro...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...   \n",
       "1  [B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...   \n",
       "2  [B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...   \n",
       "3                 [B-AC, B-O, B-LF, I-LF, I-LF, B-O]   \n",
       "4  [B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...   \n",
       "\n",
       "                                                 ids  \\\n",
       "0      [0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...   \n",
       "3                                 [1, 0, 3, 4, 4, 0]   \n",
       "4  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           sentences  \n",
       "0  for thi purpos the gothenburg young person emp...  \n",
       "1  the follow physiolog trait were measur : stoma...  \n",
       "2  minor h antigen alloimmun respons readili occu...  \n",
       "3                           epi = echo planar imag .  \n",
       "4  furthermor , eno - deriv no s - nitrosyl β - a...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072\n",
      "126\n",
      "153\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>ids</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[for, thi, purpos, the, gothenburg, young, per...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>for thi purpos the gothenburg young person emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[the, follow, physiolog, trait, were, measur, ...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>the follow physiolog trait were measur : stoma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[minor, h, antigen, alloimmun, respons, readil...</td>\n",
       "      <td>[B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...</td>\n",
       "      <td>minor h antigen alloimmun respons readili occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[epi, =, echo, planar, imag, .]</td>\n",
       "      <td>[B-AC, B-O, B-LF, I-LF, I-LF, B-O]</td>\n",
       "      <td>[1, 0, 3, 4, 4, 0]</td>\n",
       "      <td>epi = echo planar imag .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[furthermor, ,, eno, -, deriv, no, s, -, nitro...</td>\n",
       "      <td>[B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>furthermor , eno - deriv no s - nitrosyl β - a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [for, thi, purpos, the, gothenburg, young, per...   \n",
       "1  [the, follow, physiolog, trait, were, measur, ...   \n",
       "2  [minor, h, antigen, alloimmun, respons, readil...   \n",
       "3                    [epi, =, echo, planar, imag, .]   \n",
       "4  [furthermor, ,, eno, -, deriv, no, s, -, nitro...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...   \n",
       "1  [B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...   \n",
       "2  [B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...   \n",
       "3                 [B-AC, B-O, B-LF, I-LF, I-LF, B-O]   \n",
       "4  [B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...   \n",
       "\n",
       "                                                 ids  \\\n",
       "0      [0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...   \n",
       "3                                 [1, 0, 3, 4, 4, 0]   \n",
       "4  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           sentences  \n",
       "0  for thi purpos the gothenburg young person emp...  \n",
       "1  the follow physiolog trait were measur : stoma...  \n",
       "2  minor h antigen alloimmun respons readili occu...  \n",
       "3                           epi = echo planar imag .  \n",
       "4  furthermor , eno - deriv no s - nitrosyl β - a...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': <torchtext.data.field.Field object at 0x176264c40>, 'text': <torchtext.data.field.Field object at 0x107985e10>}\n",
      "['for', 'thi', 'purpos', 'the', 'gothenburg', 'young', 'person', 'empower', 'scale', '(', 'gype', ')', 'wa', 'develop', '.']\n",
      "['B-O', 'B-O', 'B-O', 'B-O', 'B-LF', 'I-LF', 'I-LF', 'I-LF', 'I-LF', 'B-O', 'B-AC', 'B-O', 'B-O', 'B-O', 'B-O']\n",
      "Train: 1072\n",
      "Dev: 126\n",
      "Test: 153\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Field, Dataset, Example\n",
    "\n",
    "text_field = Field(sequential=True, tokenize=lambda x:x, include_lengths=True) # Default behaviour is to tokenize by splitting\n",
    "label_field = Field(sequential=True, tokenize=lambda x:x, is_target=True)\n",
    "\n",
    "fields = {\n",
    "    'sentences': ('text', text_field),\n",
    "    'ids': ('label', label_field)\n",
    "}\n",
    "\n",
    "def read_data(df):\n",
    "    examples = []\n",
    "    fields = {'sentence_labels': ('labels', label_field),\n",
    "              'sentence_tokens': ('text', text_field)}\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        tokens = df['tokens'][i]\n",
    "        labels = df['labels'][i]\n",
    "        \n",
    "        e = Example.fromdict({\"sentence_labels\": labels, \"sentence_tokens\": tokens},\n",
    "                             fields=fields)\n",
    "        examples.append(e)\n",
    "    \n",
    "    return Dataset(examples, fields=[('labels', label_field), ('text', text_field)])\n",
    "\n",
    "\n",
    "train_data = read_data(train_dataset)\n",
    "val_data = read_data(val_dataset)\n",
    "test_data = read_data(test_dataset)\n",
    "\n",
    "print(train_data.fields)\n",
    "print(train_data[0].text)\n",
    "print(train_data[0].labels)\n",
    "\n",
    "print(\"Train:\", len(train_data))\n",
    "print(\"Dev:\", len(val_data))\n",
    "print(\"Test:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 20000\n",
    "\n",
    "text_field.build_vocab(train_data, max_size=VOCAB_SIZE)\n",
    "label_field.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import BucketIterator\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_iter = BucketIterator(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                            sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "val_iter = BucketIterator(dataset=val_data, batch_size=BATCH_SIZE, \n",
    "                          sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "test_iter = BucketIterator(dataset=test_data, batch_size=BATCH_SIZE, \n",
    "                           sort_key=lambda x: len(x.text), sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained embeddings\n",
      "Initializing embedding matrix\n",
      "torch.Size([6853, 300])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "emb = 'fasttext'\n",
    "\n",
    "if emb == 'fasttext':\n",
    "\n",
    "    EMBEDDING_PATH = \"/Users/antoineedy/Documents/MScAI/Semester2/NLP/Coursework/code/data/cc.en.300.vec\"\n",
    "\n",
    "    def load_embeddings(path):\n",
    "        \"\"\" Load the FastText embeddings from the embedding file. \"\"\"\n",
    "        print(\"Loading pre-trained embeddings\")\n",
    "        \n",
    "        embeddings = {}\n",
    "        with open(path) as i:\n",
    "            for line in i:\n",
    "                if len(line) > 2: \n",
    "                    line = line.strip().split()\n",
    "                    word = line[0]\n",
    "                    embedding = np.array(line[1:])\n",
    "                    embeddings[word] = embedding\n",
    "        \n",
    "        return embeddings\n",
    "        \n",
    "\n",
    "    def initialize_embeddings(embeddings, vocabulary):\n",
    "        \"\"\" Use the pre-trained embeddings to initialize an embedding matrix. \"\"\"\n",
    "        print(\"Initializing embedding matrix\")\n",
    "        embedding_size = len(embeddings[\".\"])\n",
    "        embedding_matrix = np.zeros((len(vocabulary), embedding_size), dtype=np.float32)\n",
    "                                    \n",
    "        for idx, word in enumerate(vocabulary.itos): \n",
    "            if word in embeddings:\n",
    "                embedding_matrix[idx,:] = embeddings[word]\n",
    "                \n",
    "        return embedding_matrix\n",
    "\n",
    "    embeddings = load_embeddings(EMBEDDING_PATH)\n",
    "    embedding_matrix = initialize_embeddings(embeddings, text_field.vocab)\n",
    "    embedding_matrix = torch.from_numpy(embedding_matrix)\n",
    "    print(embedding_matrix.shape)\n",
    "\n",
    "elif emb == 'glove':\n",
    "\n",
    "    EMBEDDING_PATH = \"data/glove.6B.300d.txt\"\n",
    "\n",
    "    def load_embeddings(path):\n",
    "        \"\"\" Load the FastText embeddings from the embedding file. \"\"\"\n",
    "        print(\"Loading pre-trained embeddings\")\n",
    "        \n",
    "        embeddings = {}\n",
    "        with open(path) as i:\n",
    "            for line in i:\n",
    "                if len(line) > 2: \n",
    "                    line = line.strip().split()\n",
    "                    word = line[0]\n",
    "                    embedding = np.array(line[1:])\n",
    "                    embeddings[word] = embedding\n",
    "        \n",
    "        return embeddings\n",
    "        \n",
    "\n",
    "    def initialize_embeddings(embeddings, vocabulary):\n",
    "        \"\"\" Use the pre-trained embeddings to initialize an embedding matrix. \"\"\"\n",
    "        print(\"Initializing embedding matrix\")\n",
    "        embedding_size = len(embeddings[\".\"])\n",
    "        embedding_matrix = np.zeros((len(vocabulary), embedding_size), dtype=np.float32)\n",
    "                                    \n",
    "        for idx, word in enumerate(vocabulary.itos): \n",
    "            if word in embeddings:\n",
    "                embedding_matrix[idx,:] = embeddings[word]\n",
    "                \n",
    "        return embedding_matrix\n",
    "\n",
    "    embeddings = load_embeddings(EMBEDDING_PATH)\n",
    "    embedding_matrix = initialize_embeddings(embeddings, text_field.vocab)\n",
    "    embedding_matrix = torch.from_numpy(embedding_matrix)\n",
    "    print(embedding_matrix.shape)\n",
    "\n",
    "\n",
    "elif emb == 'word2vec':\n",
    "    import gensim\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "    em = []\n",
    "    for word in text_field.vocab.itos:\n",
    "        if word in model:\n",
    "            em.append(model.get_vector(word))\n",
    "        else:\n",
    "            em.append(np.zeros(300))\n",
    "    em = np.array(em)\n",
    "    embedding_matrix = torch.tensor(em, dtype=torch.float32)\n",
    "    print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class BiLSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, output_size, embeddings=None):\n",
    "        super(BiLSTMTagger, self).__init__()\n",
    "        \n",
    "        # 1. Embedding Layer\n",
    "        if embeddings is None:\n",
    "            self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        else:\n",
    "            self.embeddings = nn.Embedding.from_pretrained(embeddings)\n",
    "        \n",
    "        # 2. LSTM Layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, num_layers=1)\n",
    "        \n",
    "        # 3. Optional dropout layer\n",
    "        self.dropout_layer = nn.Dropout(p=0.5)\n",
    "\n",
    "        # 4. Dense Layer\n",
    "        self.hidden2tag = nn.Linear(2*hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, batch_text, batch_lengths):\n",
    "\n",
    "        embeddings = self.embeddings(batch_text)\n",
    "        \n",
    "        packed_seqs = pack_padded_sequence(embeddings, batch_lengths)\n",
    "        lstm_output, _ = self.lstm(packed_seqs)\n",
    "        lstm_output, _ = pad_packed_sequence(lstm_output)\n",
    "        lstm_output = self.dropout_layer(lstm_output)\n",
    "        \n",
    "        logits = self.hidden2tag(lstm_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 6: ['<unk>', '<pad>', 'B-O', 'I-LF', 'B-AC', 'B-LF']\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "def remove_predictions_for_masked_items(predicted_labels, correct_labels): \n",
    "\n",
    "    predicted_labels_without_mask = []\n",
    "    correct_labels_without_mask = []\n",
    "        \n",
    "    for p, c in zip(predicted_labels, correct_labels):\n",
    "        if c > 1:\n",
    "            predicted_labels_without_mask.append(p)\n",
    "            correct_labels_without_mask.append(c)\n",
    "            \n",
    "    return predicted_labels_without_mask, correct_labels_without_mask\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "NUM_CLASSES = len(label_field.vocab)\n",
    "print(f\"Number of classes: {NUM_CLASSES}: {label_field.vocab.itos}\")\n",
    "\n",
    "def train(model, train_iter, dev_iter, batch_size, max_epochs, num_batches, patience, output_path):\n",
    "    writer = SummaryWriter()\n",
    "    # add weight to indexes 3, 4, 5\n",
    "    w = [0, 0, 0.0443, 0.6259, 1.0000, 0.4525]\n",
    "    class_weights = torch.tensor(w).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight = class_weights, ignore_index=1)  # we mask the <pad> labels\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    train_f_score_history = []\n",
    "    dev_f_score_history = []\n",
    "    no_improvement = 0\n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        total_loss = 0\n",
    "        predictions, correct = [], []\n",
    "        for batch in tqdm(train_iter, total=num_batches, desc=f\"Epoch {epoch}\"):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            text_length, cur_batch_size = batch.text[0].shape\n",
    "            \n",
    "            pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size*text_length, NUM_CLASSES)\n",
    "            gold = batch.labels.to(device).view(cur_batch_size*text_length)\n",
    "            \n",
    "            loss = criterion(pred, gold)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, pred_indices = torch.max(pred, 1)\n",
    "            \n",
    "            predicted_labels = list(pred_indices.cpu().numpy())\n",
    "            correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "            \n",
    "            predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, \n",
    "                                                                                   correct_labels)\n",
    "            \n",
    "            predictions += predicted_labels\n",
    "            correct += correct_labels\n",
    "\n",
    "        train_scores = precision_recall_fscore_support(correct, predictions, average=\"micro\")\n",
    "        train_f_score_history.append(train_scores[2])\n",
    "            \n",
    "        print(\"Total training loss:\", total_loss)\n",
    "        print(\"Training performance:\", train_scores)\n",
    "\n",
    "        #tensorboard\n",
    "        writer.add_scalar('train/loss', total_loss, epoch)\n",
    "        writer.add_scalar('train/precision', train_scores[2], epoch)\n",
    "\n",
    "        \n",
    "        total_loss = 0\n",
    "        predictions, correct = [], []\n",
    "        for batch in dev_iter:\n",
    "\n",
    "            text_length, cur_batch_size = batch.text[0].shape\n",
    "\n",
    "            pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size * text_length, NUM_CLASSES)\n",
    "            gold = batch.labels.to(device).view(cur_batch_size * text_length)\n",
    "            loss = criterion(pred, gold)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, pred_indices = torch.max(pred, 1)\n",
    "            predicted_labels = list(pred_indices.cpu().numpy())\n",
    "            correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "            \n",
    "            predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, \n",
    "                                                                                   correct_labels)\n",
    "            \n",
    "            predictions += predicted_labels\n",
    "            correct += correct_labels\n",
    "\n",
    "        dev_scores = precision_recall_fscore_support(correct, predictions, average=\"micro\")\n",
    "            \n",
    "        print(\"Total development loss:\", total_loss)\n",
    "        print(\"Development performance:\", dev_scores)\n",
    "\n",
    "        writer.add_scalar('val/loss', total_loss, epoch)\n",
    "        writer.add_scalar('val/precision', dev_scores[2], epoch)\n",
    "\n",
    "        labels = label_field.vocab.itos[2:]\n",
    "        labels = sorted(labels, key=lambda x: x.split(\"-\")[-1])\n",
    "        label_idxs = [label_field.vocab.stoi[l] for l in labels]\n",
    "\n",
    "        cr = classification_report(correct, predictions, labels = label_idxs, target_names=labels, output_dict=True)\n",
    "\n",
    "        out = {}\n",
    "        for key in cr.keys():\n",
    "            if key == 'accuracy':\n",
    "                out[key] = cr[key]\n",
    "            else:\n",
    "                for new_k in ['precision', 'recall', 'f1-score']:\n",
    "                    out[key+'_'+new_k] = cr[key][new_k]\n",
    "        \n",
    "        for (key, value) in out.items():\n",
    "            writer.add_scalar(f'test/{key}', value, epoch)\n",
    "        \n",
    "        dev_f = dev_scores[2]\n",
    "\n",
    "        dev_f = out['macro avg_f1-score']\n",
    "\n",
    "        if len(dev_f_score_history) > patience and dev_f < max(dev_f_score_history):\n",
    "            no_improvement += 1\n",
    "\n",
    "        elif len(dev_f_score_history) == 0 or dev_f > max(dev_f_score_history):\n",
    "            print(\"Saving model.\")\n",
    "            torch.save(model, output_path)\n",
    "            no_improvement = 0\n",
    "            \n",
    "        if no_improvement > patience:\n",
    "            print(\"Macro average F1-score does not improve anymore. Stop training.\")\n",
    "            dev_f_score_history.append(dev_f)\n",
    "            break\n",
    "            \n",
    "        dev_f_score_history.append(dev_f)\n",
    "        \n",
    "    return train_f_score_history, dev_f_score_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_iter, batch_size, labels, target_names): \n",
    "    \n",
    "    total_loss = 0\n",
    "    predictions, correct = [], []\n",
    "    for batch in test_iter:\n",
    "\n",
    "        text_length, cur_batch_size = batch.text[0].shape\n",
    "\n",
    "        pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size * text_length, NUM_CLASSES)\n",
    "        gold = batch.labels.to(device).view(cur_batch_size * text_length)\n",
    "\n",
    "        _, pred_indices = torch.max(pred, 1)\n",
    "        predicted_labels = list(pred_indices.cpu().numpy())\n",
    "        correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "\n",
    "        predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, correct_labels)\n",
    "\n",
    "        predictions += predicted_labels\n",
    "        correct += correct_labels\n",
    "    \n",
    "    print(classification_report(correct, predictions, labels=labels, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 6 : ['<unk>', '<pad>', 'B-O', 'I-LF', 'B-AC', 'B-LF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 34/34 [00:05<00:00,  6.43it/s]\n",
      "/Users/antoineedy/Documents/MScAI/Semester2/NLP/Coursework/code/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/antoineedy/Documents/MScAI/Semester2/NLP/Coursework/code/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/antoineedy/Documents/MScAI/Semester2/NLP/Coursework/code/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 43.544673800468445\n",
      "Training performance: (0.272925, 0.272925, 0.272925, None)\n",
      "Total development loss: 4.025841593742371\n",
      "Development performance: (0.3262, 0.3262, 0.3262, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 34/34 [00:04<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 25.28701537847519\n",
      "Training performance: (0.630125, 0.630125, 0.630125, None)\n",
      "Total development loss: 2.8286158442497253\n",
      "Development performance: (0.6796, 0.6796, 0.6796, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 34/34 [00:05<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 19.036820024251938\n",
      "Training performance: (0.73015, 0.73015, 0.73015, None)\n",
      "Total development loss: 2.380902200937271\n",
      "Development performance: (0.7276, 0.7276, 0.7276, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 34/34 [00:04<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 16.557820826768875\n",
      "Training performance: (0.7637, 0.7637, 0.7637, None)\n",
      "Total development loss: 2.18414643406868\n",
      "Development performance: (0.7396, 0.7396, 0.7396, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 34/34 [00:05<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 14.907436102628708\n",
      "Training performance: (0.772225, 0.772225, 0.772225, None)\n",
      "Total development loss: 2.007444143295288\n",
      "Development performance: (0.7914, 0.7914, 0.7914, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 34/34 [00:04<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 13.551283299922943\n",
      "Training performance: (0.786075, 0.786075, 0.786075, None)\n",
      "Total development loss: 2.0411206483840942\n",
      "Development performance: (0.8536, 0.8536, 0.8536, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 34/34 [00:05<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 13.026100680232048\n",
      "Training performance: (0.8039, 0.8039, 0.8039, None)\n",
      "Total development loss: 1.898217648267746\n",
      "Development performance: (0.759, 0.759, 0.759, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 34/34 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 12.306011110544205\n",
      "Training performance: (0.8001, 0.8001, 0.8001, None)\n",
      "Total development loss: 1.7805124521255493\n",
      "Development performance: (0.8, 0.8, 0.8, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 34/34 [00:05<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 11.050172984600067\n",
      "Training performance: (0.81525, 0.81525, 0.81525, None)\n",
      "Total development loss: 2.2343502044677734\n",
      "Development performance: (0.8774, 0.8774, 0.8774, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 34/34 [00:05<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 11.276677906513214\n",
      "Training performance: (0.81305, 0.81305, 0.81305, None)\n",
      "Total development loss: 1.7469784021377563\n",
      "Development performance: (0.8118, 0.8118, 0.8118, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 34/34 [00:05<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 9.917598575353622\n",
      "Training performance: (0.828475, 0.828475, 0.828475, None)\n",
      "Total development loss: 1.7121853530406952\n",
      "Development performance: (0.8186, 0.8186, 0.8186, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 34/34 [00:05<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 9.730658009648323\n",
      "Training performance: (0.83575, 0.83575, 0.83575, None)\n",
      "Total development loss: 1.7318670451641083\n",
      "Development performance: (0.8596, 0.8596, 0.8596, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 34/34 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 8.983672969043255\n",
      "Training performance: (0.8376, 0.8376, 0.8376, None)\n",
      "Total development loss: 1.6829150915145874\n",
      "Development performance: (0.8284, 0.8284, 0.8284, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 34/34 [00:05<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 8.563602238893509\n",
      "Training performance: (0.854225, 0.854225, 0.854225, None)\n",
      "Total development loss: 1.6135553121566772\n",
      "Development performance: (0.812, 0.812, 0.812, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 34/34 [00:04<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 7.808508947491646\n",
      "Training performance: (0.8556, 0.8556, 0.8556, None)\n",
      "Total development loss: 1.7100560367107391\n",
      "Development performance: (0.8214, 0.8214, 0.8214, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 34/34 [00:05<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 7.282718330621719\n",
      "Training performance: (0.8637, 0.8637, 0.8637, None)\n",
      "Total development loss: 1.7419190406799316\n",
      "Development performance: (0.8224, 0.8224, 0.8224, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 34/34 [00:05<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 7.048831291496754\n",
      "Training performance: (0.8693, 0.8693, 0.8693, None)\n",
      "Total development loss: 1.8299660682678223\n",
      "Development performance: (0.8524, 0.8524, 0.8524, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 34/34 [00:05<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 6.438984468579292\n",
      "Training performance: (0.8784, 0.8784, 0.8784, None)\n",
      "Total development loss: 1.7027674317359924\n",
      "Development performance: (0.849, 0.849, 0.849, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 34/34 [00:05<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 6.127263315021992\n",
      "Training performance: (0.886275, 0.886275, 0.886275, None)\n",
      "Total development loss: 1.805647999048233\n",
      "Development performance: (0.8576, 0.8576, 0.8576, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 34/34 [00:05<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 5.812493618577719\n",
      "Training performance: (0.88575, 0.88575, 0.88575, None)\n",
      "Total development loss: 1.7678218185901642\n",
      "Development performance: (0.8634, 0.8634, 0.8634, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 34/34 [00:05<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 5.398964527994394\n",
      "Training performance: (0.891225, 0.891225, 0.891225, None)\n",
      "Total development loss: 1.922515094280243\n",
      "Development performance: (0.877, 0.877, 0.877, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 34/34 [00:05<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 4.851199612021446\n",
      "Training performance: (0.903325, 0.903325, 0.903325, None)\n",
      "Total development loss: 1.775145262479782\n",
      "Development performance: (0.8268, 0.8268, 0.8268, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 34/34 [00:04<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 4.652754809707403\n",
      "Training performance: (0.902975, 0.902975, 0.902975, None)\n",
      "Total development loss: 1.9197914600372314\n",
      "Development performance: (0.8516, 0.8516, 0.8516, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 34/34 [00:04<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 4.46712227165699\n",
      "Training performance: (0.904475, 0.904475, 0.904475, None)\n",
      "Total development loss: 1.728092983365059\n",
      "Development performance: (0.8572, 0.8572, 0.8572, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 34/34 [00:04<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.984348341822624\n",
      "Training performance: (0.915575, 0.915575, 0.915575, None)\n",
      "Total development loss: 1.898751437664032\n",
      "Development performance: (0.858, 0.858, 0.858, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 34/34 [00:05<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.6048019230365753\n",
      "Training performance: (0.921675, 0.921675, 0.921675, None)\n",
      "Total development loss: 2.0324288606643677\n",
      "Development performance: (0.866, 0.866, 0.866, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 34/34 [00:04<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.6738815680146217\n",
      "Training performance: (0.9202, 0.9202, 0.9202, None)\n",
      "Total development loss: 2.0655617117881775\n",
      "Development performance: (0.8708, 0.8708, 0.8708, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 34/34 [00:05<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.604207307100296\n",
      "Training performance: (0.92425, 0.92425, 0.92425, None)\n",
      "Total development loss: 2.096924990415573\n",
      "Development performance: (0.8768, 0.8768, 0.8768, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 34/34 [00:05<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.0749464258551598\n",
      "Training performance: (0.9304, 0.9304, 0.9304, None)\n",
      "Total development loss: 2.329009085893631\n",
      "Development performance: (0.8902, 0.8902, 0.8902, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 34/34 [00:05<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.6902157552540302\n",
      "Training performance: (0.936475, 0.936475, 0.936475, None)\n",
      "Total development loss: 2.416371464729309\n",
      "Development performance: (0.8878, 0.8878, 0.8878, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 34/34 [00:04<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.363091627135873\n",
      "Training performance: (0.945075, 0.945075, 0.945075, None)\n",
      "Total development loss: 2.5371946692466736\n",
      "Development performance: (0.8886, 0.8886, 0.8886, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 34/34 [00:04<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.2593191787600517\n",
      "Training performance: (0.94655, 0.94655, 0.94655, None)\n",
      "Total development loss: 2.472989708185196\n",
      "Development performance: (0.8768, 0.8768, 0.8768, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 34/34 [00:05<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.373775612562895\n",
      "Training performance: (0.9446, 0.9446, 0.9446, None)\n",
      "Total development loss: 2.4337661266326904\n",
      "Development performance: (0.865, 0.865, 0.865, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 34/34 [00:05<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.409653566777706\n",
      "Training performance: (0.942875, 0.942875, 0.942875, None)\n",
      "Total development loss: 2.2183603942394257\n",
      "Development performance: (0.8588, 0.8588, 0.8588, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 34/34 [00:05<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.2413759157061577\n",
      "Training performance: (0.94355, 0.94355, 0.94355, None)\n",
      "Total development loss: 2.8934826850891113\n",
      "Development performance: (0.8842, 0.8842, 0.8842, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 34/34 [00:05<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.7944242749363184\n",
      "Training performance: (0.9569, 0.9569, 0.9569, None)\n",
      "Total development loss: 2.973501682281494\n",
      "Development performance: (0.8918, 0.8918, 0.8918, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 34/34 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.7563821021467447\n",
      "Training performance: (0.95625, 0.95625, 0.95625, None)\n",
      "Total development loss: 3.694940209388733\n",
      "Development performance: (0.9038, 0.9038, 0.9038, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 34/34 [00:05<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.6816520616412163\n",
      "Training performance: (0.959225, 0.959225, 0.959225, None)\n",
      "Total development loss: 2.8709213733673096\n",
      "Development performance: (0.8902, 0.8902, 0.8902, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 34/34 [00:05<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.4888974074274302\n",
      "Training performance: (0.96435, 0.96435, 0.96435, None)\n",
      "Total development loss: 3.2661532759666443\n",
      "Development performance: (0.889, 0.889, 0.889, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 34/34 [00:04<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.40477408003062\n",
      "Training performance: (0.9652, 0.9652, 0.9652, None)\n",
      "Total development loss: 3.079813778400421\n",
      "Development performance: (0.893, 0.893, 0.893, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 34/34 [00:05<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.180311804637313\n",
      "Training performance: (0.969125, 0.969125, 0.969125, None)\n",
      "Total development loss: 3.4475309252738953\n",
      "Development performance: (0.9032, 0.9032, 0.9032, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 34/34 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.066802374087274\n",
      "Training performance: (0.9724, 0.9724, 0.9724, None)\n",
      "Total development loss: 3.3667938113212585\n",
      "Development performance: (0.8906, 0.8906, 0.8906, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 34/34 [00:05<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.144497930072248\n",
      "Training performance: (0.971125, 0.971125, 0.971125, None)\n",
      "Total development loss: 4.0156333446502686\n",
      "Development performance: (0.8984, 0.8984, 0.8984, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 34/34 [00:05<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.9453052561730146\n",
      "Training performance: (0.9752, 0.9752, 0.9752, None)\n",
      "Total development loss: 3.80985164642334\n",
      "Development performance: (0.9056, 0.9056, 0.9056, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 34/34 [00:05<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.804198179859668\n",
      "Training performance: (0.979475, 0.979475, 0.979475, None)\n",
      "Total development loss: 4.335761606693268\n",
      "Development performance: (0.9074, 0.9074, 0.9074, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 34/34 [00:05<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.7166448272764683\n",
      "Training performance: (0.981825, 0.981825, 0.981825, None)\n",
      "Total development loss: 4.198552846908569\n",
      "Development performance: (0.898, 0.898, 0.898, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 34/34 [00:05<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.7574901669286191\n",
      "Training performance: (0.980025, 0.980025, 0.980025, None)\n",
      "Total development loss: 4.003529667854309\n",
      "Development performance: (0.8972, 0.8972, 0.8972, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 34/34 [00:05<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.9733840376138687\n",
      "Training performance: (0.9744, 0.9744, 0.9744, None)\n",
      "Total development loss: 3.9436761140823364\n",
      "Development performance: (0.8992, 0.8992, 0.8992, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 34/34 [00:05<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.8839443596079946\n",
      "Training performance: (0.977575, 0.977575, 0.977575, None)\n",
      "Total development loss: 4.159144043922424\n",
      "Development performance: (0.9008, 0.9008, 0.9008, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 34/34 [00:05<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.8635161574929953\n",
      "Training performance: (0.97775, 0.97775, 0.97775, None)\n",
      "Total development loss: 3.6663004755973816\n",
      "Development performance: (0.8846, 0.8846, 0.8846, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 34/34 [00:05<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.1511176330968738\n",
      "Training performance: (0.974775, 0.974775, 0.974775, None)\n",
      "Total development loss: 4.02007520198822\n",
      "Development performance: (0.8996, 0.8996, 0.8996, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 34/34 [00:05<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.4953044364228845\n",
      "Training performance: (0.96425, 0.96425, 0.96425, None)\n",
      "Total development loss: 3.825559973716736\n",
      "Development performance: (0.8938, 0.8938, 0.8938, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 34/34 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.9474646598100662\n",
      "Training performance: (0.97485, 0.97485, 0.97485, None)\n",
      "Total development loss: 4.2409462332725525\n",
      "Development performance: (0.9016, 0.9016, 0.9016, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 34/34 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.6268128887750208\n",
      "Training performance: (0.984225, 0.984225, 0.984225, None)\n",
      "Total development loss: 4.303069829940796\n",
      "Development performance: (0.9044, 0.9044, 0.9044, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 34/34 [00:04<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.498571053147316\n",
      "Training performance: (0.986925, 0.986925, 0.986925, None)\n",
      "Total development loss: 4.334118485450745\n",
      "Development performance: (0.8978, 0.8978, 0.8978, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 34/34 [00:04<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.5413916208781302\n",
      "Training performance: (0.984775, 0.984775, 0.984775, None)\n",
      "Total development loss: 4.792551338672638\n",
      "Development performance: (0.9058, 0.9058, 0.9058, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 34/34 [00:05<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.4276000503450632\n",
      "Training performance: (0.989125, 0.989125, 0.989125, None)\n",
      "Total development loss: 4.784068167209625\n",
      "Development performance: (0.9012, 0.9012, 0.9012, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 34/34 [00:05<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.338653520680964\n",
      "Training performance: (0.9913, 0.9913, 0.9913, None)\n",
      "Total development loss: 4.986112654209137\n",
      "Development performance: (0.9058, 0.9058, 0.9058, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 34/34 [00:05<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.3171830221544951\n",
      "Training performance: (0.992375, 0.992375, 0.992375, None)\n",
      "Total development loss: 5.21332311630249\n",
      "Development performance: (0.9032, 0.9032, 0.9032, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 34/34 [00:05<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.26099785626865923\n",
      "Training performance: (0.994, 0.994, 0.994, None)\n",
      "Total development loss: 5.142068266868591\n",
      "Development performance: (0.9004, 0.9004, 0.9004, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 34/34 [00:05<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.23425476835109293\n",
      "Training performance: (0.994425, 0.994425, 0.994425, None)\n",
      "Total development loss: 5.648679316043854\n",
      "Development performance: (0.9066, 0.9066, 0.9066, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 34/34 [00:05<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.26795629132539034\n",
      "Training performance: (0.992925, 0.992925, 0.992925, None)\n",
      "Total development loss: 4.911928117275238\n",
      "Development performance: (0.9052, 0.9052, 0.9052, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 34/34 [00:05<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.538727582199499\n",
      "Training performance: (0.987925, 0.987925, 0.987925, None)\n",
      "Total development loss: 4.385361731052399\n",
      "Development performance: (0.8928, 0.8928, 0.8928, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 34/34 [00:06<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.8276466813404113\n",
      "Training performance: (0.979475, 0.979475, 0.979475, None)\n",
      "Total development loss: 4.438836872577667\n",
      "Development performance: (0.8982, 0.8982, 0.8982, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 34/34 [00:05<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.095042744651437\n",
      "Training performance: (0.9592, 0.9592, 0.9592, None)\n",
      "Total development loss: 2.8738925457000732\n",
      "Development performance: (0.8316, 0.8316, 0.8316, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 34/34 [00:05<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 2.53189012221992\n",
      "Training performance: (0.9451, 0.9451, 0.9451, None)\n",
      "Total development loss: 3.2312557101249695\n",
      "Development performance: (0.888, 0.888, 0.888, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 34/34 [00:04<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 1.390462732873857\n",
      "Training performance: (0.96665, 0.96665, 0.96665, None)\n",
      "Total development loss: 3.648309290409088\n",
      "Development performance: (0.8944, 0.8944, 0.8944, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 34/34 [00:06<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.6803356981836259\n",
      "Training performance: (0.9818, 0.9818, 0.9818, None)\n",
      "Total development loss: 4.1179980635643005\n",
      "Development performance: (0.8994, 0.8994, 0.8994, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 34/34 [00:05<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.42001002188771963\n",
      "Training performance: (0.988125, 0.988125, 0.988125, None)\n",
      "Total development loss: 4.802418112754822\n",
      "Development performance: (0.9002, 0.9002, 0.9002, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 34/34 [00:05<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 0.46482461295090616\n",
      "Training performance: (0.98795, 0.98795, 0.98795, None)\n",
      "Total development loss: 4.5223482847213745\n",
      "Development performance: (0.9034, 0.9034, 0.9034, None)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "EMBEDDING_DIM = 300 #fasttext & word2vec & glove\n",
    "# EMBEDDING_DIM = 768 #bert\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = len(label_field.vocab)\n",
    "print(f\"Number of classes: {NUM_CLASSES} : {label_field.vocab.itos}\")\n",
    "MAX_EPOCHS = 70\n",
    "PATIENCE = 50\n",
    "OUTPUT_PATH = \"model_saves/bilstmtagger\"\n",
    "num_batches = math.ceil(len(train_data) / BATCH_SIZE)\n",
    "\n",
    "tagger = BiLSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE+2, NUM_CLASSES, embeddings=embedding_matrix)  # embeddings\n",
    "# tagger = BiLSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE+2, NUM_CLASSES)  # no embeddings\n",
    "\n",
    "train_f, dev_f = train(tagger.to(device), train_iter, val_iter, BATCH_SIZE, MAX_EPOCHS, \n",
    "                       num_batches, PATIENCE, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "df = pd.DataFrame({'epochs': range(0,len(train_f)), \n",
    "                  'train_f': train_f, \n",
    "                   'val_f': dev_f})\n",
    " \n",
    "# multiple line plot\n",
    "plt.plot('epochs', 'train_f', data=df, color='blue', linewidth=2)\n",
    "plt.plot('epochs', 'val_f', data=df, color='green', linewidth=2)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = \"model_saves/bilstmtagger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMTagger(\n",
       "  (embeddings): Embedding(6853, 300)\n",
       "  (lstm): LSTM(300, 256, bidirectional=True)\n",
       "  (dropout_layer): Dropout(p=0.5, inplace=False)\n",
       "  (hidden2tag): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = torch.load(OUTPUT_PATH)\n",
    "tagger.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-AC       0.61      0.64      0.62       270\n",
      "        I-LF       0.64      0.74      0.69       288\n",
      "        B-LF       0.53      0.53      0.53       150\n",
      "         B-O       0.96      0.94      0.95      4292\n",
      "\n",
      "    accuracy                           0.90      5000\n",
      "   macro avg       0.68      0.71      0.70      5000\n",
      "weighted avg       0.91      0.90      0.90      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = label_field.vocab.itos[2:]\n",
    "labels = sorted(labels, key=lambda x: x.split(\"-\")[-1])\n",
    "label_idxs = [label_field.vocab.stoi[l] for l in labels]\n",
    "\n",
    "test(tagger, test_iter, BATCH_SIZE, labels = label_idxs, target_names = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Back, Style\n",
    "\n",
    "def vizu(words, output, truth):\n",
    "    if isinstance(output, torch.Tensor):\n",
    "        output = output.squeeze().tolist()\n",
    "    col = {0: Back.GREEN, 1: Back.RED, 2: Back.BLACK, 3: Back.BLUE, 4: Back.MAGENTA}\n",
    "    colors1 = [col[i] for i in output]\n",
    "    colors2 = [col[i] for i in truth]\n",
    "    words = [word.replace(\"Ġ\", \"\") for word in words]\n",
    "    print(Style.RESET_ALL + \"Output:\")\n",
    "    for i, word in enumerate(words):\n",
    "        print(colors1[i] + word, end=\" \")\n",
    "    print(Style.RESET_ALL + \"\\nTruth:\")\n",
    "    for i, word in enumerate(words):\n",
    "        print(colors2[i] + word, end=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
