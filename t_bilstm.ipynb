{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antoine EDY\n",
    "# Natural Language Processing (COMM061) - Coursework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import nltk\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"surrey-nlp/PLOD-CW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT2ID: {'B-O': 0, 'B-AC': 1, 'PAD': 2, 'B-LF': 3, 'I-LF': 4}\n",
      "ID2TEXT: {0: 'B-O', 1: 'B-AC', 2: 'PAD', 3: 'B-LF', 4: 'I-LF'}\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1072 entries, 0 to 1071\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tokens     1072 non-null   object\n",
      " 1   labels     1072 non-null   object\n",
      " 2   ids        1072 non-null   object\n",
      " 3   sentences  1072 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 33.6+ KB\n"
     ]
    }
   ],
   "source": [
    "TEXT2ID = {\n",
    "    \"B-O\": 0,\n",
    "    \"B-AC\": 1,\n",
    "    \"PAD\": 2,\n",
    "    \"B-LF\": 3,\n",
    "    \"I-LF\": 4,\n",
    "}\n",
    "ID2TEXT = {v: k for k, v in TEXT2ID.items()}\n",
    "\n",
    "print(f\"TEXT2ID: {TEXT2ID}\\nID2TEXT: {ID2TEXT}\\n\")\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.drop(columns=['pos_tags'])\n",
    "    df = df.rename(columns={\"ner_tags\": \"labels\"})\n",
    "    df[\"ids\"] = df[\"labels\"].apply(lambda x: [TEXT2ID[i] for i in x])\n",
    "    df[\"sentences\"] = df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_dataset = preprocess(pd.DataFrame(dataset['train']))\n",
    "test_dataset = preprocess(pd.DataFrame(dataset['test']))\n",
    "val_dataset = preprocess(pd.DataFrame(dataset['validation']))\n",
    "\n",
    "train_dataset.info()\n",
    "\n",
    "\n",
    "# Here the exploration to add at the end of the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>ids</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[For, this, purpose, the, Gothenburg, Young, P...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>For this purpose the Gothenburg Young Persons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, following, physiological, traits, were, ...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>The following physiological traits were measur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Minor, H, antigen, alloimmune, responses, rea...</td>\n",
       "      <td>[B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...</td>\n",
       "      <td>Minor H antigen alloimmune responses readily o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[EPI, =, Echo, planar, imaging, .]</td>\n",
       "      <td>[B-AC, B-O, B-LF, I-LF, I-LF, B-O]</td>\n",
       "      <td>[1, 0, 3, 4, 4, 0]</td>\n",
       "      <td>EPI = Echo planar imaging .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Furthermore, ,, eNOS, -, derived, NO, S, -, n...</td>\n",
       "      <td>[B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Furthermore , eNOS - derived NO S - nitrosylat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [For, this, purpose, the, Gothenburg, Young, P...   \n",
       "1  [The, following, physiological, traits, were, ...   \n",
       "2  [Minor, H, antigen, alloimmune, responses, rea...   \n",
       "3                 [EPI, =, Echo, planar, imaging, .]   \n",
       "4  [Furthermore, ,, eNOS, -, derived, NO, S, -, n...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...   \n",
       "1  [B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...   \n",
       "2  [B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...   \n",
       "3                 [B-AC, B-O, B-LF, I-LF, I-LF, B-O]   \n",
       "4  [B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...   \n",
       "\n",
       "                                                 ids  \\\n",
       "0      [0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...   \n",
       "3                                 [1, 0, 3, 4, 4, 0]   \n",
       "4  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           sentences  \n",
       "0  For this purpose the Gothenburg Young Persons ...  \n",
       "1  The following physiological traits were measur...  \n",
       "2  Minor H antigen alloimmune responses readily o...  \n",
       "3                        EPI = Echo planar imaging .  \n",
       "4  Furthermore , eNOS - derived NO S - nitrosylat...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072\n",
      "126\n",
      "153\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "# None for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>ids</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[For, this, purpose, the, Gothenburg, Young, P...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>For this purpose the Gothenburg Young Persons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, following, physiological, traits, were, ...</td>\n",
       "      <td>[B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>The following physiological traits were measur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Minor, H, antigen, alloimmune, responses, rea...</td>\n",
       "      <td>[B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...</td>\n",
       "      <td>Minor H antigen alloimmune responses readily o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[EPI, =, Echo, planar, imaging, .]</td>\n",
       "      <td>[B-AC, B-O, B-LF, I-LF, I-LF, B-O]</td>\n",
       "      <td>[1, 0, 3, 4, 4, 0]</td>\n",
       "      <td>EPI = Echo planar imaging .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Furthermore, ,, eNOS, -, derived, NO, S, -, n...</td>\n",
       "      <td>[B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Furthermore , eNOS - derived NO S - nitrosylat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [For, this, purpose, the, Gothenburg, Young, P...   \n",
       "1  [The, following, physiological, traits, were, ...   \n",
       "2  [Minor, H, antigen, alloimmune, responses, rea...   \n",
       "3                 [EPI, =, Echo, planar, imaging, .]   \n",
       "4  [Furthermore, ,, eNOS, -, derived, NO, S, -, n...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [B-O, B-O, B-O, B-O, B-LF, I-LF, I-LF, I-LF, I...   \n",
       "1  [B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-LF, I-LF...   \n",
       "2  [B-O, B-AC, B-O, B-O, B-O, B-O, B-O, B-O, B-O,...   \n",
       "3                 [B-AC, B-O, B-LF, I-LF, I-LF, B-O]   \n",
       "4  [B-O, B-O, B-AC, B-O, B-O, B-AC, B-O, B-O, B-O...   \n",
       "\n",
       "                                                 ids  \\\n",
       "0      [0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 1, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, ...   \n",
       "3                                 [1, 0, 3, 4, 4, 0]   \n",
       "4  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           sentences  \n",
       "0  For this purpose the Gothenburg Young Persons ...  \n",
       "1  The following physiological traits were measur...  \n",
       "2  Minor H antigen alloimmune responses readily o...  \n",
       "3                        EPI = Echo planar imaging .  \n",
       "4  Furthermore , eNOS - derived NO S - nitrosylat...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': <torchtext.data.field.Field object at 0x177387730>, 'text': <torchtext.data.field.Field object at 0x177387790>}\n",
      "['For', 'this', 'purpose', 'the', 'Gothenburg', 'Young', 'Persons', 'Empowerment', 'Scale', '(', 'GYPES', ')', 'was', 'developed', '.']\n",
      "['B-O', 'B-O', 'B-O', 'B-O', 'B-LF', 'I-LF', 'I-LF', 'I-LF', 'I-LF', 'B-O', 'B-AC', 'B-O', 'B-O', 'B-O', 'B-O']\n",
      "Train: 1072\n",
      "Dev: 126\n",
      "Test: 153\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Field, Dataset, Example\n",
    "\n",
    "text_field = Field(sequential=True, tokenize=lambda x:x, include_lengths=True) # Default behaviour is to tokenize by splitting\n",
    "label_field = Field(sequential=True, tokenize=lambda x:x, is_target=True)\n",
    "\n",
    "fields = {\n",
    "    'sentences': ('text', text_field),\n",
    "    'ids': ('label', label_field)\n",
    "}\n",
    "\n",
    "def read_data(df):\n",
    "    examples = []\n",
    "    fields = {'sentence_labels': ('labels', label_field),\n",
    "              'sentence_tokens': ('text', text_field)}\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        tokens = df['tokens'][i]\n",
    "        labels = df['labels'][i]\n",
    "        \n",
    "        e = Example.fromdict({\"sentence_labels\": labels, \"sentence_tokens\": tokens},\n",
    "                             fields=fields)\n",
    "        examples.append(e)\n",
    "    \n",
    "    return Dataset(examples, fields=[('labels', label_field), ('text', text_field)])\n",
    "\n",
    "\n",
    "train_data = read_data(train_dataset)\n",
    "val_data = read_data(val_dataset)\n",
    "test_data = read_data(test_dataset)\n",
    "\n",
    "print(train_data.fields)\n",
    "print(train_data[0].text)\n",
    "print(train_data[0].labels)\n",
    "\n",
    "print(\"Train:\", len(train_data))\n",
    "print(\"Dev:\", len(val_data))\n",
    "print(\"Test:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 20000\n",
    "\n",
    "text_field.build_vocab(train_data, max_size=VOCAB_SIZE)\n",
    "label_field.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import BucketIterator\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_iter = BucketIterator(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                            sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "val_iter = BucketIterator(dataset=val_data, batch_size=BATCH_SIZE, \n",
    "                          sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "test_iter = BucketIterator(dataset=test_data, batch_size=BATCH_SIZE, \n",
    "                           sort_key=lambda x: len(x.text), sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained embeddings\n",
      "Initializing embedding matrix\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "EMBEDDING_PATH = \"/Users/antoineedy/Documents/MSc AI/Semester 2/NLP/Coursework/code/data/cc.en.300.vec\"\n",
    "\n",
    "\n",
    "def load_embeddings(path):\n",
    "    \"\"\" Load the FastText embeddings from the embedding file. \"\"\"\n",
    "    print(\"Loading pre-trained embeddings\")\n",
    "    \n",
    "    embeddings = {}\n",
    "    with open(path) as i:\n",
    "        for line in i:\n",
    "            if len(line) > 2: \n",
    "                line = line.strip().split()\n",
    "                word = line[0]\n",
    "                embedding = np.array(line[1:])\n",
    "                embeddings[word] = embedding\n",
    "    \n",
    "    return embeddings\n",
    "    \n",
    "\n",
    "def initialize_embeddings(embeddings, vocabulary):\n",
    "    \"\"\" Use the pre-trained embeddings to initialize an embedding matrix. \"\"\"\n",
    "    print(\"Initializing embedding matrix\")\n",
    "    embedding_size = len(embeddings[\".\"])\n",
    "    embedding_matrix = np.zeros((len(vocabulary), embedding_size), dtype=np.float32)\n",
    "                                \n",
    "    for idx, word in enumerate(vocabulary.itos): \n",
    "        if word in embeddings:\n",
    "            embedding_matrix[idx,:] = embeddings[word]\n",
    "            \n",
    "    return embedding_matrix\n",
    "\n",
    "embeddings = load_embeddings(EMBEDDING_PATH)\n",
    "embedding_matrix = initialize_embeddings(embeddings, text_field.vocab)\n",
    "embedding_matrix = torch.from_numpy(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class BiLSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, output_size, embeddings=None):\n",
    "        super(BiLSTMTagger, self).__init__()\n",
    "        \n",
    "        # 1. Embedding Layer\n",
    "        if embeddings is None:\n",
    "            self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        else:\n",
    "            self.embeddings = nn.Embedding.from_pretrained(embeddings)\n",
    "        \n",
    "        # 2. LSTM Layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, num_layers=1)\n",
    "        \n",
    "        # 3. Optional dropout layer\n",
    "        self.dropout_layer = nn.Dropout(p=0.5)\n",
    "\n",
    "        # 4. Dense Layer\n",
    "        self.hidden2tag = nn.Linear(2*hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, batch_text, batch_lengths):\n",
    "\n",
    "        embeddings = self.embeddings(batch_text)\n",
    "        \n",
    "        packed_seqs = pack_padded_sequence(embeddings, batch_lengths)\n",
    "        lstm_output, _ = self.lstm(packed_seqs)\n",
    "        lstm_output, _ = pad_packed_sequence(lstm_output)\n",
    "        lstm_output = self.dropout_layer(lstm_output)\n",
    "        \n",
    "        logits = self.hidden2tag(lstm_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 6: ['<unk>', '<pad>', 'B-O', 'I-LF', 'B-AC', 'B-LF']\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "def remove_predictions_for_masked_items(predicted_labels, correct_labels): \n",
    "\n",
    "    predicted_labels_without_mask = []\n",
    "    correct_labels_without_mask = []\n",
    "        \n",
    "    for p, c in zip(predicted_labels, correct_labels):\n",
    "        if c > 1:\n",
    "            predicted_labels_without_mask.append(p)\n",
    "            correct_labels_without_mask.append(c)\n",
    "            \n",
    "    return predicted_labels_without_mask, correct_labels_without_mask\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "NUM_CLASSES = len(label_field.vocab)\n",
    "print(f\"Number of classes: {NUM_CLASSES}: {label_field.vocab.itos}\")\n",
    "\n",
    "def train(model, train_iter, dev_iter, batch_size, max_epochs, num_batches, patience, output_path):\n",
    "    writer = SummaryWriter()\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=1)  # we mask the <pad> labels\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    train_f_score_history = []\n",
    "    dev_f_score_history = []\n",
    "    no_improvement = 0\n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        total_loss = 0\n",
    "        predictions, correct = [], []\n",
    "        for batch in tqdm(train_iter, total=num_batches, desc=f\"Epoch {epoch}\"):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            text_length, cur_batch_size = batch.text[0].shape\n",
    "            \n",
    "            pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size*text_length, NUM_CLASSES)\n",
    "            gold = batch.labels.to(device).view(cur_batch_size*text_length)\n",
    "            \n",
    "            loss = criterion(pred, gold)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, pred_indices = torch.max(pred, 1)\n",
    "            \n",
    "            predicted_labels = list(pred_indices.cpu().numpy())\n",
    "            correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "            \n",
    "            predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, \n",
    "                                                                                   correct_labels)\n",
    "            \n",
    "            predictions += predicted_labels\n",
    "            correct += correct_labels\n",
    "\n",
    "        train_scores = precision_recall_fscore_support(correct, predictions, average=\"micro\")\n",
    "        train_f_score_history.append(train_scores[2])\n",
    "            \n",
    "        print(\"Total training loss:\", total_loss)\n",
    "        print(\"Training performance:\", train_scores)\n",
    "\n",
    "        #tensorboard\n",
    "        writer.add_scalar('train/loss', total_loss, epoch)\n",
    "        writer.add_scalar('train/precision', train_scores[2], epoch)\n",
    "        \n",
    "        total_loss = 0\n",
    "        predictions, correct = [], []\n",
    "        for batch in dev_iter:\n",
    "\n",
    "            text_length, cur_batch_size = batch.text[0].shape\n",
    "\n",
    "            pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size * text_length, NUM_CLASSES)\n",
    "            gold = batch.labels.to(device).view(cur_batch_size * text_length)\n",
    "            loss = criterion(pred, gold)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, pred_indices = torch.max(pred, 1)\n",
    "            predicted_labels = list(pred_indices.cpu().numpy())\n",
    "            correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "            \n",
    "            predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, \n",
    "                                                                                   correct_labels)\n",
    "            \n",
    "            predictions += predicted_labels\n",
    "            correct += correct_labels\n",
    "\n",
    "        dev_scores = precision_recall_fscore_support(correct, predictions, average=\"micro\")\n",
    "            \n",
    "        print(\"Total development loss:\", total_loss)\n",
    "        print(\"Development performance:\", dev_scores)\n",
    "\n",
    "        writer.add_scalar('val/loss', total_loss, epoch)\n",
    "        writer.add_scalar('val/precision', dev_scores[2], epoch)\n",
    "        \n",
    "        dev_f = dev_scores[2]\n",
    "        if len(dev_f_score_history) > patience and dev_f < max(dev_f_score_history):\n",
    "            no_improvement += 1\n",
    "\n",
    "        elif len(dev_f_score_history) == 0 or dev_f > max(dev_f_score_history):\n",
    "            print(\"Saving model.\")\n",
    "            torch.save(model, output_path)\n",
    "            no_improvement = 0\n",
    "            \n",
    "        if no_improvement > patience:\n",
    "            print(\"Development F-score does not improve anymore. Stop training.\")\n",
    "            dev_f_score_history.append(dev_f)\n",
    "            break\n",
    "            \n",
    "        dev_f_score_history.append(dev_f)\n",
    "        \n",
    "    return train_f_score_history, dev_f_score_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_iter, batch_size, labels, target_names): \n",
    "    \n",
    "    total_loss = 0\n",
    "    predictions, correct = [], []\n",
    "    for batch in test_iter:\n",
    "\n",
    "        text_length, cur_batch_size = batch.text[0].shape\n",
    "\n",
    "        pred = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size * text_length, NUM_CLASSES)\n",
    "        gold = batch.labels.to(device).view(cur_batch_size * text_length)\n",
    "\n",
    "        _, pred_indices = torch.max(pred, 1)\n",
    "        predicted_labels = list(pred_indices.cpu().numpy())\n",
    "        correct_labels = list(batch.labels.view(cur_batch_size*text_length).numpy())\n",
    "\n",
    "        predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels, \n",
    "                                                                               correct_labels)\n",
    "\n",
    "        predictions += predicted_labels\n",
    "        correct += correct_labels\n",
    "    \n",
    "    print(classification_report(correct, predictions, labels=labels, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 6 : ['<unk>', '<pad>', 'B-O', 'I-LF', 'B-AC', 'B-LF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 34/34 [00:04<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 30.143182426691055\n",
      "Training performance: (0.805575, 0.805575, 0.805575, None)\n",
      "Total development loss: 2.1576485633850098\n",
      "Development performance: (0.8522, 0.8522, 0.8522, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 34/34 [00:04<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 16.690930128097534\n",
      "Training performance: (0.843475, 0.843475, 0.843475, None)\n",
      "Total development loss: 1.4980382025241852\n",
      "Development performance: (0.8812, 0.8812, 0.8812, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 34/34 [00:04<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 12.285599783062935\n",
      "Training performance: (0.877475, 0.877475, 0.877475, None)\n",
      "Total development loss: 1.282155305147171\n",
      "Development performance: (0.896, 0.896, 0.896, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 34/34 [00:04<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 10.497689425945282\n",
      "Training performance: (0.890125, 0.890125, 0.890125, None)\n",
      "Total development loss: 1.1927286982536316\n",
      "Development performance: (0.906, 0.906, 0.906, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 34/34 [00:04<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 9.451244205236435\n",
      "Training performance: (0.90065, 0.90065, 0.90065, None)\n",
      "Total development loss: 1.169287234544754\n",
      "Development performance: (0.9098, 0.9098, 0.9098, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 34/34 [00:06<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 8.752334594726562\n",
      "Training performance: (0.90755, 0.90755, 0.90755, None)\n",
      "Total development loss: 1.1330137848854065\n",
      "Development performance: (0.9082, 0.9082, 0.9082, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 34/34 [00:04<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 8.735570922493935\n",
      "Training performance: (0.903925, 0.903925, 0.903925, None)\n",
      "Total development loss: 1.0771616250276566\n",
      "Development performance: (0.9116, 0.9116, 0.9116, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 34/34 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 8.103202685713768\n",
      "Training performance: (0.910475, 0.910475, 0.910475, None)\n",
      "Total development loss: 1.0990051925182343\n",
      "Development performance: (0.9092, 0.9092, 0.9092, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 34/34 [00:04<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 7.830729052424431\n",
      "Training performance: (0.91585, 0.91585, 0.91585, None)\n",
      "Total development loss: 1.0823423564434052\n",
      "Development performance: (0.9154, 0.9154, 0.9154, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 34/34 [00:04<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 7.462786227464676\n",
      "Training performance: (0.918175, 0.918175, 0.918175, None)\n",
      "Total development loss: 1.0232262164354324\n",
      "Development performance: (0.92, 0.92, 0.92, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 34/34 [00:04<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 7.029855594038963\n",
      "Training performance: (0.923025, 0.923025, 0.923025, None)\n",
      "Total development loss: 1.0245590656995773\n",
      "Development performance: (0.9194, 0.9194, 0.9194, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 34/34 [00:04<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 6.562869355082512\n",
      "Training performance: (0.925225, 0.925225, 0.925225, None)\n",
      "Total development loss: 1.026151329278946\n",
      "Development performance: (0.919, 0.919, 0.919, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 34/34 [00:05<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 6.215134635567665\n",
      "Training performance: (0.93035, 0.93035, 0.93035, None)\n",
      "Total development loss: 0.9562297761440277\n",
      "Development performance: (0.9254, 0.9254, 0.9254, None)\n",
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 34/34 [00:05<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 5.9024370312690735\n",
      "Training performance: (0.933275, 0.933275, 0.933275, None)\n",
      "Total development loss: 1.0094927847385406\n",
      "Development performance: (0.925, 0.925, 0.925, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 34/34 [00:05<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 5.913231700658798\n",
      "Training performance: (0.931925, 0.931925, 0.931925, None)\n",
      "Total development loss: 1.0465619415044785\n",
      "Development performance: (0.9198, 0.9198, 0.9198, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 34/34 [00:05<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 5.385909162461758\n",
      "Training performance: (0.939525, 0.939525, 0.939525, None)\n",
      "Total development loss: 1.0624510943889618\n",
      "Development performance: (0.9164, 0.9164, 0.9164, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 34/34 [00:05<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 5.143693931400776\n",
      "Training performance: (0.9421, 0.9421, 0.9421, None)\n",
      "Total development loss: 0.9903170317411423\n",
      "Development performance: (0.919, 0.919, 0.919, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 34/34 [00:04<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 4.816845528781414\n",
      "Training performance: (0.94515, 0.94515, 0.94515, None)\n",
      "Total development loss: 1.0010725110769272\n",
      "Development performance: (0.9208, 0.9208, 0.9208, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 34/34 [00:05<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 4.523949585855007\n",
      "Training performance: (0.94755, 0.94755, 0.94755, None)\n",
      "Total development loss: 1.0918569415807724\n",
      "Development performance: (0.9176, 0.9176, 0.9176, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 34/34 [00:05<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 4.647179335355759\n",
      "Training performance: (0.946925, 0.946925, 0.946925, None)\n",
      "Total development loss: 1.0389296412467957\n",
      "Development performance: (0.9246, 0.9246, 0.9246, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 34/34 [00:05<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 4.354275405406952\n",
      "Training performance: (0.948975, 0.948975, 0.948975, None)\n",
      "Total development loss: 1.0421641767024994\n",
      "Development performance: (0.916, 0.916, 0.916, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 34/34 [00:05<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training loss: 3.7288612984120846\n",
      "Training performance: (0.958175, 0.958175, 0.958175, None)\n",
      "Total development loss: 1.1326871514320374\n",
      "Development performance: (0.9134, 0.9134, 0.9134, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22:  53%|█████▎    | 18/34 [00:03<00:03,  5.14it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;28mlen\u001b[39m(train_data) \u001b[38;5;241m/\u001b[39m BATCH_SIZE)\n\u001b[1;32m     12\u001b[0m tagger \u001b[38;5;241m=\u001b[39m BiLSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m, NUM_CLASSES, embeddings\u001b[38;5;241m=\u001b[39membedding_matrix)  \n\u001b[0;32m---> 14\u001b[0m train_f, dev_f \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtagger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 45\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_iter, dev_iter, batch_size, max_epochs, num_batches, patience, output_path)\u001b[0m\n\u001b[1;32m     41\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(pred, gold)\n\u001b[1;32m     43\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 45\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     48\u001b[0m _, pred_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(pred, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/MSc AI/Semester 2/NLP/Coursework/code/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MSc AI/Semester 2/NLP/Coursework/code/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = len(label_field.vocab)\n",
    "print(f\"Number of classes: {NUM_CLASSES} : {label_field.vocab.itos}\")\n",
    "MAX_EPOCHS = 50\n",
    "PATIENCE = 50\n",
    "OUTPUT_PATH = \"/tmp/bilstmtagger\"\n",
    "num_batches = math.ceil(len(train_data) / BATCH_SIZE)\n",
    "\n",
    "tagger = BiLSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE+2, NUM_CLASSES, embeddings=embedding_matrix)  \n",
    "\n",
    "train_f, dev_f = train(tagger.to(device), train_iter, val_iter, BATCH_SIZE, MAX_EPOCHS, \n",
    "                       num_batches, PATIENCE, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "df = pd.DataFrame({'epochs': range(0,len(train_f)), \n",
    "                  'train_f': train_f, \n",
    "                   'dev_f': dev_f})\n",
    " \n",
    "# multiple line plot\n",
    "plt.plot('epochs', 'train_f', data=df, color='blue', linewidth=2)\n",
    "plt.plot('epochs', 'dev_f', data=df, color='green', linewidth=2)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMTagger(\n",
       "  (embeddings): Embedding(9135, 300)\n",
       "  (lstm): LSTM(300, 256, bidirectional=True)\n",
       "  (dropout_layer): Dropout(p=0.5, inplace=False)\n",
       "  (hidden2tag): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = torch.load(OUTPUT_PATH)\n",
    "tagger.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-AC       0.77      0.58      0.66       270\n",
      "        I-LF       0.68      0.77      0.73       288\n",
      "        B-LF       0.61      0.57      0.59       150\n",
      "         B-O       0.95      0.96      0.96      4292\n",
      "\n",
      "    accuracy                           0.92      5000\n",
      "   macro avg       0.76      0.72      0.73      5000\n",
      "weighted avg       0.92      0.92      0.92      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = label_field.vocab.itos[2:]\n",
    "labels = sorted(labels, key=lambda x: x.split(\"-\")[-1])\n",
    "label_idxs = [label_field.vocab.stoi[l] for l in labels]\n",
    "\n",
    "test(tagger, test_iter, BATCH_SIZE, labels = label_idxs, target_names = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Back, Style\n",
    "\n",
    "def vizu(words, output, truth):\n",
    "    if isinstance(output, torch.Tensor):\n",
    "        output = output.squeeze().tolist()\n",
    "    col = {0: Back.BLACK, 1: Back.RED, 2: Back.GREEN, 3: Back.BLUE, 4: Back.MAGENTA}\n",
    "    colors1 = [col[i] for i in output]\n",
    "    colors2 = [col[i] for i in truth]\n",
    "    words = [word.replace(\"Ġ\", \"\") for word in words]\n",
    "    print(Style.RESET_ALL + \"Output:\")\n",
    "    for i, word in enumerate(words):\n",
    "        print(colors1[i] + word, end=\" \")\n",
    "    print(Style.RESET_ALL + \"\\nTruth:\")\n",
    "    for i, word in enumerate(words):\n",
    "        print(colors2[i] + word, end=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
