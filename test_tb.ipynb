{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard as tb\n",
    "tb.__version__\n",
    "import os\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tb_data(root_dir, sort_by=None):\n",
    "    \"\"\"Convert local TensorBoard data into Pandas DataFrame.\n",
    "    \n",
    "    Function takes the root directory path and recursively parses\n",
    "    all events data.    \n",
    "    If the `sort_by` value is provided then it will use that column\n",
    "    to sort values; typically `wall_time` or `step`.\n",
    "    \n",
    "    *Note* that the whole data is converted into a DataFrame.\n",
    "    Depending on the data size this might take a while. If it takes\n",
    "    too long then narrow it to some sub-directories.\n",
    "    \n",
    "    Paramters:\n",
    "        root_dir: (str) path to root dir with tensorboard data.\n",
    "        sort_by: (optional str) column name to sort by.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame with [wall_time, name, step, value] columns.\n",
    "    \n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "\n",
    "    def convert_tfevent(filepath):\n",
    "        return pd.DataFrame([\n",
    "            parse_tfevent(e) for e in summary_iterator(filepath) if len(e.summary.value)\n",
    "        ])\n",
    "\n",
    "    def parse_tfevent(tfevent):\n",
    "        return dict(\n",
    "            wall_time=tfevent.wall_time,\n",
    "            name=tfevent.summary.value[0].tag,\n",
    "            step=tfevent.step,\n",
    "            value=float(tfevent.summary.value[0].simple_value),\n",
    "        )\n",
    "    \n",
    "    columns_order = ['wall_time', 'name', 'step', 'value']\n",
    "    \n",
    "    out = []\n",
    "    for (root, _, filenames) in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if \"events.out.tfevents\" not in filename:\n",
    "                continue\n",
    "            file_full_path = os.path.join(root, filename)\n",
    "            out.append(convert_tfevent(file_full_path))\n",
    "    # Concatenate (and sort) all partial individual dataframes\n",
    "    all_df = pd.concat(out)[columns_order]\n",
    "    if sort_by is not None:\n",
    "        all_df = all_df.sort_values(sort_by)\n",
    "\n",
    "    dict_out = dict()\n",
    "    for name, group in all_df.groupby('name'):\n",
    "        dict_out[name] = group.reset_index(drop=True)\n",
    "        \n",
    "    return dict_out\n",
    "\n",
    "def all_df(path):\n",
    "    out = dict()\n",
    "    for folder in os.listdir(path):\n",
    "        p = os.path.join(path, folder)\n",
    "        out[folder] = convert_tb_data(p)\n",
    "    return out\n",
    "\n",
    "def do_it(path, isString = False):\n",
    "    to_get = ['eval/1_precision', 'eval/1_recall', 'eval/1_f1-score', 'eval/2_precision', 'eval/2_recall', 'eval/2_f1-score', 'eval/weighted avg_f1-score']\n",
    "    if isString:\n",
    "        to_get = ['test/B-AC_precision', 'test/B-AC_recall', 'test/B-AC_f1-score', 'test/B-LF_precision', 'test/B-LF_recall', 'test/B-LF_f1-score', 'test/weighted avg_f1-score']\n",
    "    all_dfs = all_df(path)\n",
    "    o = []\n",
    "    for key, value in all_dfs.items():\n",
    "        add_to_o = []\n",
    "        add_to_o.append(key)\n",
    "        vs = []\n",
    "        for k in to_get:\n",
    "            add_to_o.append(round(value[k].tail(1).value.values[0],3))\n",
    "        o.append(add_to_o)\n",
    "    out = deepcopy(o)\n",
    "    for i in range(len(o)):\n",
    "        for j in range(len(o[i])):\n",
    "            if isinstance(o[i][j], str):\n",
    "                print(o[i][j], end=' ')\n",
    "            else:\n",
    "                to_compare_to = [o[k][j] for k in range(len(o))]\n",
    "                if o[i][j] == max(to_compare_to):\n",
    "                    out[i][j] = \"\\\\\" + 'textbf{' + str(out[i][j]) + '0' * (5 - len(str(out[i][j]))) + '}'\n",
    "                else :\n",
    "                    out[i][j] = str(out[i][j]) + '0' * (5 - len(str(out[i][j])))\n",
    "                print('&', end=' ')\n",
    "                print(out[i][j], end=' ')\n",
    "        print('\\\\\\\\')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stanford & \\textbf{0.827} & 0.869 & 0.847 & \\textbf{0.842} & \\textbf{0.892} & \\textbf{0.866} & \\textbf{0.951} \\\\\n",
      "bert & 0.803 & \\textbf{0.920} & \\textbf{0.858} & 0.785 & 0.817 & 0.801 & 0.929 \\\\\n",
      "distiledgpt2 & 0.613 & 0.897 & 0.728 & 0.467 & 0.627 & 0.535 & 0.866 \\\\\n",
      "distilbert & 0.800 & 0.879 & 0.838 & 0.699 & 0.803 & 0.747 & 0.927 \\\\\n"
     ]
    }
   ],
   "source": [
    "do_it('runs/finetuned/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 & 0.741 & 0.865 & 0.798 & 0.708 & 0.830 & 0.764 & 0.921 \\\\\n",
      "16 & \\textbf{0.801} & \\textbf{0.867} & \\textbf{0.833} & \\textbf{0.761} & \\textbf{0.837} & \\textbf{0.797} & \\textbf{0.930} \\\\\n",
      "8 & 0.790 & \\textbf{0.867} & 0.826 & 0.755 & 0.810 & 0.781 & 0.928 \\\\\n"
     ]
    }
   ],
   "source": [
    "do_it('runs/batch_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-5 & 0.720 & 0.892 & 0.797 & 0.668 & \\textbf{0.841} & 0.744 & 0.917 \\\\\n",
      "2e-4 & 0.719 & \\textbf{0.893} & 0.797 & 0.710 & 0.737 & 0.723 & 0.913 \\\\\n",
      "2e-5 & \\textbf{0.801} & 0.867 & \\textbf{0.833} & \\textbf{0.761} & 0.837 & \\textbf{0.797} & \\textbf{0.930} \\\\\n"
     ]
    }
   ],
   "source": [
    "do_it('runs/lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec & 0.477 & 0.403 & 0.437 & 0.438 & 0.329 & 0.375 & 0.859 \\\\\n",
      "fasttext & \\textbf{0.743} & \\textbf{0.639} & \\textbf{0.687} & \\textbf{0.590} & \\textbf{0.530} & \\textbf{0.558} & \\textbf{0.907} \\\\\n",
      "glove & 0.505 & 0.608 & 0.552 & 0.565 & 0.523 & 0.544 & 0.899 \\\\\n"
     ]
    }
   ],
   "source": [
    "do_it('runs/vectorization', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hinge_loss & 0.514 & \\textbf{0.753} & 0.611 & 0.484 & \\textbf{0.617} & \\textbf{0.543} & 0.891 \\\\\n",
      "cross_entropy & \\textbf{0.572} & 0.696 & \\textbf{0.628} & \\textbf{0.551} & 0.503 & 0.526 & \\textbf{0.901} \\\\\n"
     ]
    }
   ],
   "source": [
    "do_it('runs/loss_functions', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weird_w & \\textbf{0.833} & 0.806 & 0.819 & \\textbf{0.762} & 0.699 & 0.729 & 0.925 \\\\\n",
      "big_w & 0.699 & \\textbf{0.918} & 0.794 & 0.711 & \\textbf{0.841} & 0.770 & 0.918 \\\\\n",
      "normal_w & 0.801 & 0.867 & \\textbf{0.833} & 0.761 & 0.837 & \\textbf{0.797} & \\textbf{0.930} \\\\\n",
      "no_w & 0.808 & 0.847 & 0.827 & 0.729 & 0.827 & 0.775 & 0.927 \\\\\n",
      "w & 0.786 & 0.872 & 0.827 & 0.741 & 0.820 & 0.778 & 0.929 \\\\\n"
     ]
    }
   ],
   "source": [
    "do_it('runs/weight_comp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdamW & \\textbf{0.694} & 0.646 & \\textbf{0.669} & \\textbf{0.593} & 0.490 & \\textbf{0.537} & \\textbf{0.913} \\\\\n",
      "sgd & 0.398 & \\textbf{0.878} & 0.547 & 0.450 & \\textbf{0.604} & 0.516 & 0.867 \\\\\n",
      "adam & 0.572 & 0.696 & 0.628 & 0.551 & 0.503 & 0.526 & 0.901 \\\\\n"
     ]
    }
   ],
   "source": [
    "do_it('runs/optimizer', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemmizer & 0.620 & 0.650 & 0.635 & 0.547 & 0.544 & 0.545 & 0.904 \\\\\n",
      "lemmatized & 0.715 & 0.658 & 0.685 & 0.567 & \\textbf{0.570} & 0.569 & \\textbf{0.911} \\\\\n",
      "nothing & \\textbf{0.743} & 0.639 & \\textbf{0.687} & 0.590 & 0.530 & 0.558 & 0.907 \\\\\n",
      "lowercase & 0.595 & \\textbf{0.677} & 0.633 & \\textbf{0.617} & 0.530 & \\textbf{0.570} & 0.908 \\\\\n"
     ]
    }
   ],
   "source": [
    "do_it('runs/preprocessing', True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
