{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'checkpoints/checkpoint-2000'\n",
    "#path = 'surrey-nlp/roberta-base-finetuned-abbr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from datasets import load_dataset\n",
    "datasets = load_dataset(\"surrey-nlp/PLOD-CW\")\n",
    "TEXT2ID = {\n",
    "    \"B-O\": 0,\n",
    "    \"B-AC\": 1,\n",
    "    \"B-LF\": 2,\n",
    "    \"I-LF\": 3,\n",
    "}\n",
    "datasets = datasets.map(lambda x: {\"ner_tags\": [TEXT2ID[tag] for tag in x[\"ner_tags\"]]})\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if True else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)\n",
    "from transformers import AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(path, num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = transformers.pipeline(\"ner\", model=model, tokenizer=tokenizer, ignore_labels=[])\n",
    "\n",
    "def choose(i=None):\n",
    "    if i is None:\n",
    "        i = torch.randint(0, len(datasets[\"test\"][\"tokens\"]), (1,)).item()\n",
    "    output = pipeline(\" \".join(datasets[\"test\"][\"tokens\"][i]))\n",
    "    words = datasets[\"test\"][\"tokens\"][i]\n",
    "\n",
    "    return words, output\n",
    "\n",
    "def choose_multiple(nb=5):\n",
    "    indices = torch.randint(0, len(datasets[\"test\"][\"tokens\"]), (nb,))\n",
    "    words = []\n",
    "    outputs = []\n",
    "    for i in indices:\n",
    "        w, o = choose(i)\n",
    "        words.append(w)\n",
    "        outputs.append(o)\n",
    "    return words, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Back, Style\n",
    "\n",
    "TEXT2ID = {\n",
    "    \"O\": 0,\n",
    "    \"B-AC\": 1,\n",
    "    \"B-LF\": 2,\n",
    "    \"I-LF\": 3,\n",
    "}\n",
    "\n",
    "def vizu(words, output, type=None):\n",
    "    sentence = \" \".join(words)\n",
    "    out_words = []\n",
    "    out_label = []\n",
    "    index = 1\n",
    "    for i in range(len(output)):\n",
    "        start = output[i]['start']\n",
    "        end = output[i]['end']\n",
    "        word = output[i]['word']\n",
    "        if type==1 and 'Ä ' in word: \n",
    "            out_words.append(' ')\n",
    "            out_label.append(0)\n",
    "            index += 1\n",
    "        elif type!=1 and word[0] != '#':\n",
    "            out_words.append(' ')\n",
    "            out_label.append(0)\n",
    "            index += 1\n",
    "        out_words.append(sentence[start:end])\n",
    "        if type==1:\n",
    "            #print(output[i]['entity'])\n",
    "            out_label.append(TEXT2ID[output[i]['entity']])\n",
    "        else:\n",
    "            out_label.append(int(output[i]['entity'][-1]))\n",
    "    col = {0: Back.BLACK, 1: Back.RED, 2: Back.GREEN, 3: Back.BLUE, 4: Back.MAGENTA}\n",
    "    for i in range(len(out_words)):\n",
    "        print(col[out_label[i]], end='')\n",
    "        print(out_words[i], end='')\n",
    "        print(Style.RESET_ALL, end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[40m \u001b[0m\u001b[42mBlood\u001b[0m\u001b[40m \u001b[0m\u001b[44mpressure\u001b[0m\u001b[40m \u001b[0m\u001b[40m(\u001b[0m\u001b[40m \u001b[0m\u001b[41mBP\u001b[0m\u001b[40m \u001b[0m\u001b[40m)\u001b[0m\u001b[40m \u001b[0m\u001b[40mwill\u001b[0m\u001b[40m \u001b[0m\u001b[40mbe\u001b[0m\u001b[40m \u001b[0m\u001b[40mcontrolled\u001b[0m\u001b[40m \u001b[0m\u001b[40mafter\u001b[0m\u001b[40m \u001b[0m\u001b[40meach\u001b[0m\u001b[40m \u001b[0m\u001b[40mvisit\u001b[0m\u001b[40m \u001b[0m\u001b[40m.\u001b[0m\n",
      "\u001b[40m \u001b[0m\u001b[40mIn\u001b[0m\u001b[40m \u001b[0m\u001b[40mDr\u001b[0m\u001b[40moso\u001b[0m\u001b[40mphila\u001b[0m\u001b[40m \u001b[0m\u001b[40m,\u001b[0m\u001b[40m \u001b[0m\u001b[40mthe\u001b[0m\u001b[40m \u001b[0m\u001b[42mfamily\u001b[0m\u001b[40m \u001b[0m\u001b[44mof\u001b[0m\u001b[40m \u001b[0m\u001b[44mgust\u001b[0m\u001b[44matory\u001b[0m\u001b[40m \u001b[0m\u001b[44mreceptors\u001b[0m\u001b[40m \u001b[0m\u001b[40m(\u001b[0m\u001b[40m \u001b[0m\u001b[41mGr\u001b[0m\u001b[41ms\u001b[0m\u001b[40m \u001b[0m\u001b[40m)\u001b[0m\u001b[40m \u001b[0m\u001b[40mis\u001b[0m\u001b[40m \u001b[0m\u001b[40mpredicted\u001b[0m\u001b[40m \u001b[0m\u001b[40mto\u001b[0m\u001b[40m \u001b[0m\u001b[40mconsist\u001b[0m\u001b[40m \u001b[0m\u001b[40mof\u001b[0m\u001b[40m \u001b[0m\u001b[40m68\u001b[0m\u001b[40m \u001b[0m\u001b[40mgenes\u001b[0m\u001b[40m \u001b[0m\u001b[40m[\u001b[0m\u001b[40m \u001b[0m\u001b[40m4\u001b[0m\u001b[40m \u001b[0m\u001b[40m]\u001b[0m\u001b[40m \u001b[0m\u001b[40m,\u001b[0m\u001b[40m \u001b[0m\u001b[40m[\u001b[0m\u001b[40m \u001b[0m\u001b[40m5\u001b[0m\u001b[40m \u001b[0m\u001b[40m]\u001b[0m\u001b[40m \u001b[0m\u001b[40m.\u001b[0m\n",
      "\u001b[40m \u001b[0m\u001b[40mInitially\u001b[0m\u001b[40m \u001b[0m\u001b[40m,\u001b[0m\u001b[40m \u001b[0m\u001b[40ma\u001b[0m\u001b[40m \u001b[0m\u001b[40mtotal\u001b[0m\u001b[40m \u001b[0m\u001b[40mof\u001b[0m\u001b[40m \u001b[0m\u001b[40m160\u001b[0m\u001b[40m \u001b[0m\u001b[40m.\u001b[0m\u001b[40m \u001b[0m\u001b[40m46\u001b[0m\u001b[40m \u001b[0m\u001b[40mmillion\u001b[0m\u001b[40m \u001b[0m\u001b[40mraw\u001b[0m\u001b[40m \u001b[0m\u001b[40mreads\u001b[0m\u001b[40m \u001b[0m\u001b[40mwere\u001b[0m\u001b[40m \u001b[0m\u001b[40mgenerated\u001b[0m\u001b[40m \u001b[0m\u001b[40mby\u001b[0m\u001b[40m \u001b[0m\u001b[40man\u001b[0m\u001b[40m \u001b[0m\u001b[40mIll\u001b[0m\u001b[40mumi\u001b[0m\u001b[40mna\u001b[0m\u001b[40m \u001b[0m\u001b[40mHiS\u001b[0m\u001b[40me\u001b[0m\u001b[40mq\u001b[0m\u001b[40m \u001b[0m\u001b[40m-\u001b[0m\u001b[40m \u001b[0m\u001b[40m2000\u001b[0m\u001b[40m \u001b[0m\u001b[40msystem\u001b[0m\u001b[40m \u001b[0m\u001b[40mfor\u001b[0m\u001b[40m \u001b[0m\u001b[40mall\u001b[0m\u001b[40m \u001b[0m\u001b[40mthe\u001b[0m\u001b[40m \u001b[0m\u001b[40msamples\u001b[0m\u001b[40m \u001b[0m\u001b[40m,\u001b[0m\u001b[40m \u001b[0m\u001b[40myielding\u001b[0m\u001b[40m \u001b[0m\u001b[40man\u001b[0m\u001b[40m \u001b[0m\u001b[40maverage\u001b[0m\u001b[40m \u001b[0m\u001b[40m12\u001b[0m\u001b[40m \u001b[0m\u001b[40m.\u001b[0m\u001b[40m \u001b[0m\u001b[40m77\u001b[0m\u001b[40m \u001b[0m\u001b[40mmillion\u001b[0m\u001b[40m \u001b[0m\u001b[40mclean\u001b[0m\u001b[40m \u001b[0m\u001b[40mreads\u001b[0m\u001b[40m \u001b[0m\u001b[40m.\u001b[0m\n",
      "\u001b[40m \u001b[0m\u001b[40mAbbreviation\u001b[0m\u001b[40ms\u001b[0m\u001b[40m \u001b[0m\u001b[40m:\u001b[0m\u001b[40m \u001b[0m\u001b[41mGEMS\u001b[0m\u001b[40m \u001b[0m\u001b[40m,\u001b[0m\u001b[40m \u001b[0m\u001b[42mGlobal\u001b[0m\u001b[40m \u001b[0m\u001b[44mEnter\u001b[0m\u001b[44mic\u001b[0m\u001b[40m \u001b[0m\u001b[44mMulti\u001b[0m\u001b[44mcent\u001b[0m\u001b[44mer\u001b[0m\u001b[40m \u001b[0m\u001b[44mStudy\u001b[0m\u001b[40m \u001b[0m\u001b[40m;\u001b[0m\u001b[40m \u001b[0m\u001b[41mVIP\u001b[0m\u001b[40m \u001b[0m\u001b[40m,\u001b[0m\u001b[40m \u001b[0m\u001b[42mvent\u001b[0m\u001b[42mila\u001b[0m\u001b[42mted\u001b[0m\u001b[40m \u001b[0m\u001b[44mimproved\u001b[0m\u001b[40m \u001b[0m\u001b[44mpit\u001b[0m\u001b[40m \u001b[0m\u001b[40m.\u001b[0m\n",
      "\u001b[40m \u001b[0m\u001b[40mIn\u001b[0m\u001b[40m \u001b[0m\u001b[40morder\u001b[0m\u001b[40m \u001b[0m\u001b[40mto\u001b[0m\u001b[40m \u001b[0m\u001b[40mdetermine\u001b[0m\u001b[40m \u001b[0m\u001b[40mthe\u001b[0m\u001b[40m \u001b[0m\u001b[40mrelationship\u001b[0m\u001b[40m \u001b[0m\u001b[40mbetween\u001b[0m\u001b[40m \u001b[0m\u001b[40mthese\u001b[0m\u001b[40m \u001b[0m\u001b[40mph\u001b[0m\u001b[40meno\u001b[0m\u001b[40mtype\u001b[0m\u001b[40ms\u001b[0m\u001b[40m \u001b[0m\u001b[40mand\u001b[0m\u001b[40m \u001b[0m\u001b[40mcellular\u001b[0m\u001b[40m \u001b[0m\u001b[40mtranscription\u001b[0m\u001b[40mal\u001b[0m\u001b[40m \u001b[0m\u001b[40mfeedback\u001b[0m\u001b[40m \u001b[0m\u001b[40mos\u001b[0m\u001b[40mci\u001b[0m\u001b[40mllation\u001b[0m\u001b[40m \u001b[0m\u001b[40m,\u001b[0m\u001b[40m \u001b[0m\u001b[42mpar\u001b[0m\u001b[40m \u001b[0m\u001b[44mdomain\u001b[0m\u001b[40m \u001b[0m\u001b[44mprotein\u001b[0m\u001b[40m \u001b[0m\u001b[44m1\u001b[0m\u001b[40m \u001b[0m\u001b[40m(\u001b[0m\u001b[40m \u001b[0m\u001b[41mPD\u001b[0m\u001b[41mP\u001b[0m\u001b[41m1\u001b[0m\u001b[40m \u001b[0m\u001b[40m)\u001b[0m\u001b[40m \u001b[0m\u001b[40mclock\u001b[0m\u001b[40m \u001b[0m\u001b[40mprotein\u001b[0m\u001b[40m \u001b[0m\u001b[40mlevels\u001b[0m\u001b[40m \u001b[0m\u001b[40mwere\u001b[0m\u001b[40m \u001b[0m\u001b[40mass\u001b[0m\u001b[40may\u001b[0m\u001b[40med\u001b[0m\u001b[40m \u001b[0m\u001b[40min\u001b[0m\u001b[40m \u001b[0m\u001b[40mthe\u001b[0m\u001b[40m \u001b[0m\u001b[41msL\u001b[0m\u001b[41mN\u001b[0m\u001b[41mV\u001b[0m\u001b[40m \u001b[0m\u001b[40m,\u001b[0m\u001b[40m \u001b[0m\u001b[42mdorsal\u001b[0m\u001b[40m \u001b[0m\u001b[44mlateral\u001b[0m\u001b[40m \u001b[0m\u001b[44mne\u001b[0m\u001b[44muron\u001b[0m\u001b[40m \u001b[0m\u001b[40m(\u001b[0m\u001b[40m \u001b[0m\u001b[41mL\u001b[0m\u001b[41mND\u001b[0m\u001b[40m \u001b[0m\u001b[40m)\u001b[0m\u001b[40m \u001b[0m\u001b[40m,\u001b[0m\u001b[40m \u001b[0m\u001b[42mdorsal\u001b[0m\u001b[40m \u001b[0m\u001b[44mne\u001b[0m\u001b[44muron\u001b[0m\u001b[40m \u001b[0m\u001b[40m(\u001b[0m\u001b[40m \u001b[0m\u001b[41mD\u001b[0m\u001b[41mN\u001b[0m\u001b[40m \u001b[0m\u001b[41m)\u001b[0m\u001b[40m \u001b[0m\u001b[41m1\u001b[0m\u001b[40m \u001b[0m\u001b[40m,\u001b[0m\u001b[40m \u001b[0m\u001b[40mand\u001b[0m\u001b[40m \u001b[0m\u001b[40mD\u001b[0m\u001b[40mN\u001b[0m\u001b[40m2\u001b[0m\u001b[40m \u001b[0m\u001b[40mneurons\u001b[0m\u001b[40m \u001b[0m\u001b[40mof\u001b[0m\u001b[40m \u001b[0m\u001b[40mflies\u001b[0m\u001b[40m \u001b[0m\u001b[40mexpressing\u001b[0m\u001b[40m \u001b[0m\u001b[40mmembrane\u001b[0m\u001b[40m \u001b[0m\u001b[40m-\u001b[0m\u001b[40m \u001b[0m\u001b[40mte\u001b[0m\u001b[40mther\u001b[0m\u001b[40med\u001b[0m\u001b[40m \u001b[0m\u001b[40mÎ´\u001b[0m\u001b[40m \u001b[0m\u001b[40m-\u001b[0m\u001b[40m \u001b[0m\u001b[41mACT\u001b[0m\u001b[41mX\u001b[0m\u001b[40m \u001b[0m\u001b[41m-\u001b[0m\u001b[40m \u001b[0m\u001b[41mH\u001b[0m\u001b[41mv\u001b[0m\u001b[41m1\u001b[0m\u001b[41ma\u001b[0m\u001b[40m \u001b[0m\u001b[40min\u001b[0m\u001b[40m \u001b[0m\u001b[40mthe\u001b[0m\u001b[40m \u001b[0m\u001b[41mL\u001b[0m\u001b[41mN\u001b[0m\u001b[41mVs\u001b[0m\u001b[40m \u001b[0m\u001b[40m.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "words, outputs = choose_multiple()\n",
    "for i in range(len(words)):\n",
    "    vizu(words[i], outputs[i], type=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
